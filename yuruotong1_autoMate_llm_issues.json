[
  {
    "issue_number": 124,
    "title": "macå¯åŠ¨æŠ¥é”™",
    "author": "sontianye",
    "state": "open",
    "created_at": "2025-03-31T09:40:37Z",
    "updated_at": "2025-06-12T04:04:07Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\npython main.py\nzsh: bus error  python main.py\n\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "èƒ½å±•ç¤ºä¸‹æ‰€æœ‰é—®é¢˜å—ï¼Ÿè¿™ä¸ªä¿¡æ¯å¤ªå°‘äº†"
      },
      {
        "user": "sontianye",
        "body": "import keyboard\nè¿˜æ˜¯è¿™ä¸ªçš„é—®é¢˜"
      },
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªé—®é¢˜å·²ç»æœ‰äººåœ¨ä¿®å¤äº†ï¼Œåº”è¯¥æ˜¯macä¸‹éœ€è¦ç®¡ç†å‘˜æƒé™"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 128,
    "title": "è¿è¡Œpython main pyæ‰“ä¸å¼€è½¯ä»¶",
    "author": "luffuy69",
    "state": "open",
    "created_at": "2025-04-08T14:35:53Z",
    "updated_at": "2025-06-06T03:01:14Z",
    "labels": [
      "bug"
    ],
    "body": "(base) PS C:\\Users\\è·¯é£> python main.py\nD:\\miniconda\\python.exe: can't open file 'C:\\\\Users\\\\è·¯é£\\\\main.py': [Errno 2] No such file or directory",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªåº”è¯¥ä¸æ˜¯ä»£ç é—®é¢˜å§ğŸ¤”"
      },
      {
        "user": "qingyuan0o0",
        "body": "![Image](https://github.com/user-attachments/assets/a89536ea-f0b4-4800-ab42-22f4c5db61b2)"
      },
      {
        "user": "Livermorest",
        "body": "\n\n> (base) PS C:\\Users\\è·¯é£> python main.py D:\\miniconda\\python.exe: can't open file 'C:\\Users\\è·¯é£\\main.py': [Errno 2] No such file or directory\n\nçœ‹çœ‹ä½ çš„C:\\Users\\è·¯é£\\  ç›®å½•ä¸‹æœ‰æ²¡æœ‰ main.py"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 133,
    "title": "æ”¯æŒDeepSeekæ¨¡å‹å—ï¼Ÿä¸ºå•¥å¿…é¡»æ˜¯Gpt4o",
    "author": "fxcfxc",
    "state": "closed",
    "created_at": "2025-04-17T07:26:44Z",
    "updated_at": "2025-06-06T03:00:26Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "å› ä¸ºè‡ªåŠ¨åŒ–æ§åˆ¶ç”µè„‘ï¼Œå¼ºä¾èµ–äºå¤šæ¨¡æ€èƒ½åŠ›ï¼ŒDeepSeekä¸æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ‰€ä»¥æ— æ³•å®Œæˆè¿™ä¸ªå·¥ä½œã€‚å¦å¤–ï¼ŒGPT4o æä¾›äº†å¤šæ¨¡æ€èƒ½åŠ›ã€ç»“æ„åŒ–è¾“å‡ºçš„å®Œæ•´èƒ½åŠ›ï¼Œè¿™ä¸ªèƒ½åŠ›åœ¨é¡¹ç›®å‰æœŸèƒ½å¤Ÿå¸®æˆ‘çœä¸‹å¤§é‡çš„å·¥ä½œé‡ï¼Œæˆ‘è¿˜æ²¡æœ‰åœ¨å›½å†…æ‰¾åˆ°åŒæ—¶æ”¯æŒè¿™ä¸¤è€…çš„æ¨¡å‹ã€‚"
      },
      {
        "user": "yuruotong1",
        "body": "ç°åœ¨æœ€é‡è¦çš„é—®é¢˜æ˜¯ï¼Œç›®å‰å¸‚é¢ä¸Šçš„å¤šæ¨¡æ€æ¨¡å‹å¯¹äº computer-use çš„æ”¯æŒéƒ½ä¸å¥½ï¼Œéœ€è¦è‡ªå·²è®­ç»ƒä¸€ä¸ªä¸“ç”¨åœºæ™¯çš„â€œå°æ¨¡å‹â€ï¼Œæˆ‘å·²ç»æœ‰äº†å¤§æ¦‚çš„æ€è·¯ï¼Œä½†æ˜¯å¯¹å·¥ç¨‹ã€ç®—æ³•èƒ½åŠ›ä¸Šæœ‰è¾ƒå¼ºçš„è¦æ±‚ï¼Œæˆ‘éœ€è¦å°çš„å›¢é˜Ÿæˆ–è€…èµ„é‡‘æ”¯æŒæ‰èƒ½æä¸‹å»ï¼Œç°åœ¨ä¸€æ–¹é¢åœ¨æ‰¾èµ„æºï¼Œå¦ä¸€æ–¹é¢åœ¨æµ·å¤–æ‰¾ä¸šåŠ¡ ã€‚"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 134,
    "title": "æ— æ³•æ‰“å¼€localhost:7888",
    "author": "printfInc",
    "state": "open",
    "created_at": "2025-04-26T10:18:03Z",
    "updated_at": "2025-06-06T03:00:15Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n![Image](https://github.com/user-attachments/assets/d2fea85f-d2e4-4b33-89de-42184aaa6954)\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ–°ç‰ˆæœ¬å·²ç»ä¸ç”¨ localhost:7888 äº†ï¼Œè¿è¡Œåå°±æ˜¯å¯æ“ä½œçš„ç•Œé¢"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 136,
    "title": "æ˜¯å¦è€ƒè™‘åŠ å…¥ä¸€ä¸‹Qwen2.5-VL",
    "author": "whisper-yev",
    "state": "open",
    "created_at": "2025-05-08T08:08:05Z",
    "updated_at": "2025-06-06T02:59:39Z",
    "labels": [
      "bug"
    ],
    "body": "è°ƒç”¨å›½å¤–çš„apiè¿˜æ˜¯ä¼šæ‹…å¿ƒæ•°æ®å®‰å…¨çš„é—®é¢˜ï¼Œå¸Œæœ›èƒ½æ¥å…¥å›½å†…çš„æ¨¡å‹å§\n",
    "comments": [
      {
        "user": "greenflute",
        "body": "being able to call local model would be the final solution."
      },
      {
        "user": "zz6zz666",
        "body": "å¯ä»¥å•Šï¼Œæˆ‘è¯•è¿‡äº†ï¼Œè¯·æ±‚æ˜¯æ²¡ä»»ä½•é—®é¢˜ï¼Œæ¯•ç«Ÿåƒé—®æ˜¯å…¼å®¹openAIçš„APIçš„\n\n![Image](https://github.com/user-attachments/assets/2638cbf5-d8c6-4b9b-9113-d6c12bc625cf)"
      },
      {
        "user": "yuruotong1",
        "body": "æœ€è¿‘æˆ‘åœ¨è€ƒè™‘å…¼å®¹ä¸€ä¸‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 137,
    "title": "TypeError: the JSON object must be str, bytes or bytearray, not list",
    "author": "zz6zz666",
    "state": "open",
    "created_at": "2025-05-30T04:37:13Z",
    "updated_at": "2025-06-06T02:59:07Z",
    "labels": [
      "bug"
    ],
    "body": "![Image](https://github.com/user-attachments/assets/f9c4070a-bb83-40df-9e4f-7e12db4426fd)\nä¸ºä»€ä¹ˆåœ¨è¿™ä¸€æ­¥ä¹‹åå‡ºé”™äº†\n\n![Image](https://github.com/user-attachments/assets/2cd64137-71b4-46ad-bbfe-ed394674821e)\n\n![Image](https://github.com/user-attachments/assets/097c6646-6d66-45d0-8131-399c8e2f6934)\n\nå®šä½åˆ°æ˜¯è¿™ä¸€è¡Œ",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "åœ¨æ¨¡å‹æ‰§è¡Œçš„ä¸­é—´ï¼Œç”¨æˆ·ä¸èƒ½ä¸»åŠ¨æé—®"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 138,
    "title": "è¾“å…¥æ ¼å¼é”™è¯¯",
    "author": "zz6zz666",
    "state": "open",
    "created_at": "2025-05-30T04:46:36Z",
    "updated_at": "2025-06-06T02:58:27Z",
    "labels": [
      "bug"
    ],
    "body": "![Image](https://github.com/user-attachments/assets/f856ce3d-6289-4277-a2b7-21436f2c7d86)",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ„Ÿè§‰åƒæ˜¯æ¨¡å‹åœ°å€ä¸å¤ªå¯¹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 135,
    "title": "æ˜¯å¦è€ƒè™‘å¢åŠ ä¸€ä¸‹gemma3-tools:27b",
    "author": "doutianye",
    "state": "open",
    "created_at": "2025-04-28T05:44:44Z",
    "updated_at": "2025-04-28T05:44:44Z",
    "labels": [
      "bug"
    ],
    "body": "ollamaéƒ¨ç½²äº†gemma3-tools:27bï¼Œå®ƒæ˜¯å¤šæ¨¡æ€ä¹Ÿæ”¯æŒtoolsï¼Œæ˜¯å¦è€ƒè™‘è¿™ä¸ªå¤§æ¨¡å‹é€‰é¡¹ã€‚",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 131,
    "title": "å¯ä»¥ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹å—ï¼Ÿ",
    "author": "Dou-Z",
    "state": "closed",
    "created_at": "2025-04-14T07:34:33Z",
    "updated_at": "2025-04-17T10:03:20Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æš‚æ—¶è¿˜ä¸èƒ½ç”¨ï¼Œåªèƒ½ç”¨ openai-gpt4o"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 132,
    "title": "mac m4å¯åŠ¨å¤±è´¥",
    "author": "AmarisWhite",
    "state": "closed",
    "created_at": "2025-04-14T08:45:24Z",
    "updated_at": "2025-04-17T02:39:03Z",
    "labels": [
      "bug"
    ],
    "body": "python main.py\nzsh: bus error  python main.py\n\n",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 126,
    "title": "åœ¨é«˜åˆ†è¾¨ç‡ä¸‹ï¼Œå±å¹•å…ƒç´ è¯†åˆ«ä¸å‡†ç¡®",
    "author": "freedomxie",
    "state": "open",
    "created_at": "2025-04-04T00:14:59Z",
    "updated_at": "2025-04-15T13:28:11Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n \"QHD\": Resolution(width=2560, height=1440),   # 16:9     \n \"3K\": Resolution(width=2880, height=1620),   # 16:9     \n \"4K\": Resolution(width=3840, height=2160),    # 16:9\n```\n\n## Description\nèƒ½å¦é€‚ä»¥ä¸Šåˆ†è¾¨ç‡\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æˆ‘æ„Ÿè§‰å¯èƒ½éœ€è¦å¯¹å›¾ç‰‡è¿›è¡Œç¼©æ”¾ï¼"
      },
      {
        "user": "yuruotong1",
        "body": "æˆ‘æ‰‹å¤´ç¡®å®æ²¡æœ‰è¿™ä¸ªåˆ†è¾¨ç‡çš„ç”µè„‘ï¼Œè¿™ä¸ªé—®é¢˜å¯èƒ½ç¨æ™šæ‰èƒ½è§£å†³ã€‚"
      },
      {
        "user": "greenflute",
        "body": "1. image scaling, in higher resolution, mac just need the origin image not the 2x, so i donâ€™t think it will cause scaling issue \n2. tested under 2014x1280, prompt is â€open terminal then cd to root and ls -lhaâ€œ, with previous executed ls in terminal, automate can correctly recognise the results thus considering the task is already finished. discard the logic issue here, automate can actually correctly recognise icons and text in terminal window. so i donâ€™t think higher resolution will cause problem. except when some old app was forced under higher resolution to maintain proper size using â€zoomâ€œ, which will definitely cause â€blurredâ€œ images, and that may interfere automateâ€™s recognising."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 129,
    "title": "å¸Œæœ›å¾—åˆ°å¤šæ˜¾ç¤ºå™¨çš„æ”¯æŒ",
    "author": "xaviershl",
    "state": "open",
    "created_at": "2025-04-11T08:45:43Z",
    "updated_at": "2025-04-15T13:27:21Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\nä½ å¥½!\næˆ‘é€šè¿‡æœ€æ–°ç‰ˆmain.exeè¿è¡Œå, é€‰æ‹©åœºæ™¯ç›®å‰åªèƒ½é€‰æ‹©ä¸»å±å¹•, æ— æ³•é€‰æ‹©å‰¯å±å¹•çš„å†…å®¹, å¯èƒ½å› ä¸ºä¸»å±å¹•åˆ†è¾¨ç‡æ˜¯2560*1440çš„åŸå› , è‡ªåŠ¨æ“ä½œä¹Ÿä¸å‡†ç¡®\næ„Ÿè°¢\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "å¥ˆä½•æˆ‘åªæœ‰ä¸€å°å°ç¬”è®°æœ¬ï¼Œè¿˜æ²¡æœ‰åŒå±(~_~ğŸ’§)"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 123,
    "title": "Must be Administrator?",
    "author": "greenflute",
    "state": "closed",
    "created_at": "2025-03-28T00:44:51Z",
    "updated_at": "2025-04-07T01:31:56Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: 0f9b9954b71d51123189de2c9c03705981868882\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n% python main.py\nCreating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/Users/~/Library/Application Support/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading Model from https://www.modelscope.cn to directory: weights/AI-ModelScope/OmniParser-v2.0\n2025-03-28 01:40:40,613 - modelscope - INFO - Target directory already exists, skipping creation.\nException in thread Thread-1 (listen):\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\nRegistered stop hotkey: alt+f3\n\n\nğŸš€ PyQt6 application launched\n    self.run()\n  File \"/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1012, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/Users/~/Sources/github.com_greenflute/yuruotong-autoMate/.venv/lib/python3.12/site-packages/keyboard/__init__.py\", line 294, in listen\n    _os_keyboard.listen(self.direct_callback)\n  File \"/Users/~/Sources/github.com_greenflute/yuruotong-autoMate/.venv/lib/python3.12/site-packages/keyboard/_darwinkeyboard.py\", line 430, in listen\n    raise OSError(\"Error 13 - Must be run as administrator\")\nOSError: Error 13 - Must be run as administrator\n```\n\n## Description\n\n\n### Current Behavior\nRunning â€python main.pyâ€œ under mac, as typical local main user (which does have admin right)\n\n### Expected Behavior\ntypical local main users are in group 80 (admin), this should not be an error\n",
    "comments": [
      {
        "user": "greenflute",
        "body": "so are we listening to the keyboard globally or just in our gui window? if not globally, we can switch to pynput or PyQt6â€™s keyPressEvent"
      },
      {
        "user": "yuruotong1",
        "body": "> so are we listening to the keyboard globally or just in our gui window? if not globally, we can switch to pynput or PyQt6â€™s\n\n I don't have a Mac computer at hand. Do I need administrator privileges to use pynput?\n\n"
      },
      {
        "user": "greenflute",
        "body": "> > so are we listening to the keyboard globally or just in our gui window? if not globally, we can switch to pynput or PyQt6â€™s\n> \n> I don't have a Mac computer at hand. Do I need administrator privileges to use pynput?\n\nwell the keyboard needs it, but pynput seems not, iâ€™ll give it a try."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 119,
    "title": "[BUG]",
    "author": "Xavier-777",
    "state": "closed",
    "created_at": "2025-03-24T08:01:13Z",
    "updated_at": "2025-04-07T01:31:41Z",
    "labels": [
      "bug"
    ],
    "body": "ä½¿ç”¨macå¯åŠ¨é¡¹ç›®ï¼Œç‚¹å‡» `Select Screen Region` æŒ‰é’®åï¼Œç³»ç»Ÿä¼šæŠ¥é”™ï¼ŒæŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼Œç„¶åç³»ç»Ÿè‡ªåŠ¨é€€å‡ºã€‚è¯·é—®æ˜¯ä»€ä¹ˆåŸå› å‘¢ï¼Œå¦‚è§£å†³ã€‚\n\n\n*** Terminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'NSWindow should only be instantiated on the main thread!'\n*** First throw call stack:\n(\n\t0   CoreFoundation                      0x00000001903ec300 __exceptionPreprocess + 176\n\t1   libobjc.A.dylib                     0x000000018fed2cd8 objc_exception_throw + 88\n\t2   CoreFoundation                      0x0000000190410994 _CFBundleGetValueForInfoKey + 0\n\t3   AppKit                              0x0000000193eb556c -[NSWindow _initContent:styleMask:backing:defer:contentView:] + 260\n\t4   AppKit                              0x0000000193eb545c -[NSWindow initWithContentRect:styleMask:backing:defer:] + 48\n\t5   libtk8.6.dylib                      0x000000030cf71ba4 TkMacOSXMakeRealWindowExist + 564\n\t6   libtk8.6.dylib                      0x000000030cf717f0 TkWmMapWindow + 76\n\t7   libtk8.6.dylib                      0x000000030cece588 MapFrame + 76\n\t8   libtcl8.6.dylib                     0x000000030d29b1a0 TclServiceIdle + 88\n\t9   libtcl8.6.dylib                     0x000000030d27b09c Tcl_DoOneEvent + 120\n\t10  libtk8.6.dylib                      0x000000030cf629c8 TkpInit + 800\n\t11  libtk8.6.dylib                      0x000000030cec6f20 Initialize + 2500\n\t12  _tkinter.cpython-312-darwin.so      0x000000016fdfe34c Tcl_AppInit + 92\n\t13  _tkinter.cpython-312-darwin.so      0x000000016fdfdfe0 Tkapp_New + 548\n\t14  _tkinter.cpython-312-darwin.so      0x000000016fdfddb8 _tkinter_create_impl + 268\n\t15  _tkinter.cpython-312-darwin.so      0x000000016fdfda38 _tkinter_create + 276\n\t16  python3.12                          0x0000000100acf3c0 cfunction_vectorcall_FASTCALL + 96\n\t17  python3.12                          0x0000000100bc1380 _PyEval_EvalFrameDefault + 189840\n\t18  python3.12                          0x0000000100b01654 slot_tp_init + 328\n\t19  python3.12                          0x0000000100af55e4 type_call + 148\n\t20  python3.12                          0x0000000100bc171c _PyEval_EvalFrameDefault + 190764\n\t21  python3.12                          0x0000000100b01654 slot_tp_init + 328\n\t22  python3.12                          0x0000000100af55e4 type_call + 148\n\t23  python3.12                          0x0000000100bc171c _PyEval_EvalFrameDefault + 190764\n\t24  python3.12                          0x0000000100be96a4 _PyObject_VectorcallTstate.4867 + 88\n\t25  python3.12                          0x0000000100be955c context_run + 104\n\t26  python3.12                          0x0000000100acf30c cfunction_vectorcall_FASTCALL_KEYWORDS + 92\n\t27  python3.12                          0x0000000100bc561c _PyEval_EvalFrameDefault + 206892\n\t28  python3.12                          0x0000000100a6c078 method_vectorcall + 368\n\t29  python3.12                          0x0000000100ccc1a0 thread_run + 80\n\t30  python3.12                          0x0000000100c4bc50 pythread_wrapper + 48\n\t31  libsystem_pthread.dylib             0x00000001902932e4 _pthread_start + 136\n\t32  libsystem_pthread.dylib             0x000000019028e0fc thread_start + 8\n)\nlibc++abi: terminating due to uncaught exception of type NSException\nzsh: abort      python main.py\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™å—ä»£ç æ­£åœ¨ä¿®æ”¹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 125,
    "title": "OSWorld Benchmark?",
    "author": "BradKML",
    "state": "closed",
    "created_at": "2025-04-03T03:44:10Z",
    "updated_at": "2025-04-07T01:31:23Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\nWould like to see this to be compared against Agent S2 and the others, since they are the FOSS SOTA https://github.com/simular-ai/Agent-S https://os-world.github.io/\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Your suggestion is very good!"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 127,
    "title": "on Mac M1 chip",
    "author": "Awesomepieman69",
    "state": "closed",
    "created_at": "2025-04-06T13:12:10Z",
    "updated_at": "2025-04-07T01:31:13Z",
    "labels": [
      "bug"
    ],
    "body": "\n## Error Message\nFatal Python error: Bus error\n\nCurrent thread 0x00000001f8ecb240 (most recent call first):\n  File \"/Users/pieman/enter/envs/automate/lib/python3.12/site-packages/keyboard/_darwinkeyboard.py\", line 134 in __init__\n  File \"/Users/pieman/enter/envs/automate/lib/python3.12/site-packages/keyboard/_darwinkeyboard.py\", line 204 in __init__\n  File \"/Users/pieman/enter/envs/automate/lib/python3.12/site-packages/keyboard/_darwinkeyboard.py\", line 404 in <module>\n  â€¦  \n  File \"/Users/pieman/autoMate/main.py\", line 1 in <module>\nBus error: 10\n## Description\n\n\n### Current Behavior\nWhen running python3 main.py in the automate conda environment, the application immediately crashes with a Bus error: 10. The stack trace shows the fault occurs inside the macOS-specific portion of the keyboard package (_darwinkeyboard.py).\n### Expected Behavior\n\n",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 121,
    "title": "è¿™ä¸ªè½¯ä»¶æ˜¯ä¸æ˜¯å¿…é¡»åœ¨çº¿ï¼Ÿ",
    "author": "xiaoxiongwn",
    "state": "closed",
    "created_at": "2025-03-27T14:32:47Z",
    "updated_at": "2025-03-31T23:07:04Z",
    "labels": [
      "bug"
    ],
    "body": "è¿™ä¸ªè½¯ä»¶è¿è¡Œæ—¶ï¼Œæ˜¯ä¸æ˜¯å¿…é¡»æœ‰äº’è”ç½‘ï¼Ÿåœ¨å±€åŸŸç½‘ä¸­æ˜¯ä¸å¯ä»¥è¿è¡Œçš„å§ã€‚",
    "comments": [
      {
        "user": "greenflute",
        "body": "å¦‚æœæœ‰æœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹ï¼Œåº”è¯¥å°±å¯ä»¥ä¸ç”¨"
      },
      {
        "user": "yuruotong1",
        "body": "ç›®å‰æ˜¯éœ€è¦è”ç½‘çš„ï¼Œç°åœ¨è¿™ä¸ªç‰ˆæœ¬åªæ”¯æŒ openai æ¨¡å‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 122,
    "title": "Packaging Version?",
    "author": "greenflute",
    "state": "closed",
    "created_at": "2025-03-28T00:31:51Z",
    "updated_at": "2025-03-28T12:11:40Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: 0f9b9954b71d51123189de2c9c03705981868882\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-core 0.1.23 requires packaging<24.0,>=23.2, but you have packaging 24.1 which is incompatible.\n```\n\n## Description\n\n\n### Current Behavior\nreport this error while running \"python install.py\"\n\n\n### Expected Behavior\nshould report no error\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æˆ‘ä»¬æ²¡æœ‰ç”¨åˆ° langChainï¼Œä½ å¯ä»¥ç”¨ conda åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒ"
      },
      {
        "user": "greenflute",
        "body": "great thanks, maybe it comes from the previous revision, iâ€™ll clean the venv and test again"
      },
      {
        "user": "greenflute",
        "body": "after cleaning up .venv, now there is no error messages any more, issue closed :)"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 82,
    "title": "åº“åŒ…é—®é¢˜æœ‰è°é‡åˆ°å—",
    "author": "OLpaye",
    "state": "closed",
    "created_at": "2025-03-12T09:57:35Z",
    "updated_at": "2025-03-27T07:01:05Z",
    "labels": [],
    "body": "![Image](https://github.com/user-attachments/assets/eeb0d9cd-246f-48f4-b58b-80634628b971)",
    "comments": [
      {
        "user": "OLpaye",
        "body": "(automate) D:\\Zhaowh\\Work Space\\3.Technical\\automateai>python main.py\nTraceback (most recent call last):\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\main.py\", line 5, in <module>\n    from gradio_ui import app\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\gradio_ui\\app.py\", line 17, in <module>\n    from gradio_ui.loop import (\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\gradio_ui\\loop.py\", line 16, in <module>\n    from gradio_ui.tools import ToolResult\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\gradio_ui\\tools\\__init__.py\", line 3, in <module>\n    from .computer import ComputerTool\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\gradio_ui\\tools\\computer.py\", line 6, in <module>\n    from util import tool\n  File \"D:\\Zhaowh\\Work Space\\3.Technical\\automateai\\util\\tool.py\", line 6, in <module>\n    import pyautogui\n  File \"C:\\Users\\Zhaowh\\.conda\\envs\\automate\\Lib\\site-packages\\pyautogui\\__init__.py\", line 542, in <module>\n    from . import _pyautogui_win as platformModule\nImportError: cannot import name '_pyautogui_win' from partially initialized module 'pyautogui' (most likely due to a circular import) (C:\\Users\\Zhaowh\\.conda\\envs\\automate\\Lib\\site-packages\\pyautogui\\__init__.py)\n\n(automate) D:\\Zhaowh\\Work Space\\3.Technical\\automateai>python\nPython 3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 17:20:38) [MSC v.1916 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pyautogui\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"C:\\Users\\Zhaowh\\.conda\\envs\\automate\\Lib\\site-packages\\pyautogui\\__init__.py\", line 542, in <module>\n    from . import _pyautogui_win as platformModule\nImportError: cannot import name '_pyautogui_win' from partially initialized module 'pyautogui' (most likely due to a circular import) (C:\\Users\\Zhaowh\\.conda\\envs\\automate\\Lib\\site-packages\\pyautogui\\__init__.py)\n>>>"
      },
      {
        "user": "yuruotong1",
        "body": "ç¨ç­‰æˆ‘ç²¾ç®€ä¸€ä¸‹ requirements"
      },
      {
        "user": "yuruotong1",
        "body": "@OLpaye å·²ç»æŠŠé‡æ„åçš„ä»£ç æ¨ä¸Šå»äº†ï¼å¯ä»¥æ›´æ–°ä¸‹çœ‹çœ‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 120,
    "title": "[BUG]",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2025-03-24T15:33:11Z",
    "updated_at": "2025-03-24T15:33:21Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 114,
    "title": "[BUG] æˆ‘çœ‹OmniParserå®šä½ä¼¼ä¹æ˜¯æ²¡é—®é¢˜çš„ï¼Œä¸çŸ¥é“æ˜¯é¼ æ ‡ç§»åŠ¨æœ‰é—®é¢˜å¯¼è‡´ç‚¹é”™äº†åœ°æ–¹ï¼Ÿ",
    "author": "Rosejacka",
    "state": "closed",
    "created_at": "2025-03-19T03:11:28Z",
    "updated_at": "2025-03-24T03:14:14Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "Rosejacka",
        "body": "å¹¶ä¸”æ„Ÿè§‰è€—æ—¶å¾ˆé•¿è¿™æ˜¯æ­£å¸¸çš„å—"
      },
      {
        "user": "yuruotong1",
        "body": "è€—æ—¶é•¿ï¼Œæœ‰ä¸¤éƒ¨åˆ†åŸå› ï¼š1ï¼‰omniparser æ‰“æ ‡æ—¶é—´é•¿ï¼Œè¿™ä¸ªå¯èƒ½æ˜¾å¡ä¸é€‚é… 2ï¼‰å¤§æ¨¡å‹è¿”å›æ—¶é—´é•¿ï¼Œè¿™ä¸ªæ²¡ç‰¹åˆ«å¥½çš„è§£å†³æ€è·¯ï¼Œé™¤éæˆ‘ä»¬è‡ªå·±è®­ç»ƒä¸€ä¸ªå¤§æ¨¡å‹"
      },
      {
        "user": "yuruotong1",
        "body": "ä½ çœ‹ä¸‹Gradioç•Œé¢AIçš„è¾“å‡ºå†…å®¹ï¼Œå®ƒä¼šå‘Šè¯‰ä½ ç‚¹å“ªä¸ªBoxIdï¼Œè¿™ä¸ªBoxIdåœ¨å›¾ç‰‡ä¸­çš„ä½ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 118,
    "title": "[BUG]",
    "author": "pigq",
    "state": "closed",
    "created_at": "2025-03-21T03:47:20Z",
    "updated_at": "2025-03-23T22:56:33Z",
    "labels": [
      "bug"
    ],
    "body": "![Image](https://github.com/user-attachments/assets/f6b20755-0216-4fe9-85a0-a528d5ccd0b8)\nè¿™ä½¿ç”¨main.exeæ–‡ä»¶ï¼Œæ— æ³•ä½¿ç”¨ï¼Œæ˜¯å¦æ˜¯vpnçš„é—®é¢˜",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ˜¯çš„ï¼Œè¯·å…³é—­ä»£ç†å·¥å…·ï¼"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 117,
    "title": "è¿™ä¸ªæœ€åä¸€æ­¥çš„æŠ¥é”™å¿«æŠŠæˆ‘æå´©æºƒäº†",
    "author": "hainiumoumou",
    "state": "closed",
    "created_at": "2025-03-20T17:39:38Z",
    "updated_at": "2025-03-22T04:20:28Z",
    "labels": [
      "bug"
    ],
    "body": "![Image](https://github.com/user-attachments/assets/8536cbd0-1d5b-4481-9c3f-2a325f6133eb)",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "çœ‹ä¸‹å‘½ä»¤è¡Œï¼Ÿ"
      },
      {
        "user": "hainiumoumou",
        "body": "> çœ‹ä¸‹å‘½ä»¤è¡Œï¼Ÿ\n*** Terminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'NSWindow should only be instantiated on the main thread!'\n*** First throw call stack:\n(\n 0   CoreFoundation                      0x00007ff80c346b8e __exceptionPreprocess + 242\n 1   libobjc.A.dylib                     0x00007ff80be2cf12 objc_exception_throw + 62\n 2   CoreFoundation                      0x00007ff80c3699f4 -[NSException raise] + 9\n 3   AppKit                              0x00007ff80fbb6126 -[NSWindow _initContent:styleMask:backing:defer:contentView:] + 1653\n 4   AppKit                              0x00007ff80fbb5aa9 -[NSWindow initWithContentRect:styleMask:backing:defer:] + 42\n 5   libtk8.6.dylib                      0x000000015305b040 TkMacOSXMakeRealWindowExist + 736\n 6   libtk8.6.dylib                      0x000000015305ab91 TkWmMapWindow + 81\n 7   libtk8.6.dylib                      0x0000000152fa8491 MapFrame + 65\n 8   libtcl8.6.dylib                     0x0000000153410446 TclServiceIdle + 134\n 9   libtcl8.6.dylib                     0x00000001533edfb1 Tcl_DoOneEvent + 385\n 10  libtk8.6.dylib                      0x000000015304aafe TkpInit + 766\n 11  libtk8.6.dylib                      0x0000000152fa0362 Initialize + 2610\n 12  _tkinter.cpython-312-darwin.so      0x000000015010271b Tcl_AppInit + 91\n 13  _tkinter.cpython-312-darwin.so      0x00000001501023f9 Tkapp_New + 585\n 14  _tkinter.cpython-312-darwin.so      0x000000015010219e _tkinter_create_impl + 222\n 15  _tkinter.cpython-312-darwin.so      0x0000000150101dfa _tkinter_create + 186\n 16  python3.12                          0x0000000100a6847a cfunction_vectorcall_FASTCALL + 106\n 17  python3.12                          0x0000000100b71aff _PyEval_EvalFrameDefault + 229071\n 18  python3.12                          0x0000000100a9d5c9 slot_tp_init + 313\n 19  python3.12                          0x0000000100a90c37 type_call + 135\n 20  python3.12                          0x0000000100b722af _PyEval_EvalFrameDefault + 231039\n 21  python3.12                          0x0000000100a9d5c9 slot_tp_init + 313\n 22  python3.12                          0x0000000100a90c37 type_call + 135\n 23  python3.12                          0x0000000100b722af _PyEval_EvalFrameDefault + 231039\n 24  python3.12                          0x0000000100b9f7c9 _PyObject_VectorcallTstate.4867 + 73\n 25  python3.12                          0x0000000100b9f6b6 context_run + 86\n 26  python3.12                          0x0000000100a683e2 cfunction_vectorcall_FASTCALL_KEYWORDS + 98\n 27  python3.12                          0x0000000100b76dab _PyEval_EvalFrameDefault + 250235\n 28  python3.12                          0x0000000100a013a0 method_vectorcall + 464\n 29  python3.12                          0x0000000100c95b01 thread_run + 81\n 30  python3.12                          0x0000000100c0fe34 pythread_wrapper + 36\n 31  libsystem_pthread.dylib             0x00007ff80c1f0253 _pthread_start + 99\n 32  libsystem_pthread.dylib             0x00007ff80c1ebbef thread_start + 15\n)\nlibc++abi: terminating due to uncaught exception of type NSException\nzsh: abort      python main.py\n(automate) a123123@123deMacBook-Air autoMate %"
      },
      {
        "user": "yuruotong1",
        "body": "å¥½åƒå­˜åœ¨ mac é€‚é…é—®é¢˜ @Gushroom "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 116,
    "title": "Mac MPS (Metal) Support?",
    "author": "GaleiqTesting",
    "state": "closed",
    "created_at": "2025-03-19T20:48:26Z",
    "updated_at": "2025-03-21T23:54:43Z",
    "labels": [
      "bug"
    ],
    "body": "\nHi I saw an earlier message about Mac.\n\nCould you tell me what LLM Models this project uses and reference the files I can edit to enable MPS support?\n\nIf Omniparser, here is a fix which worked for me to enable MPS support:\nhttps://github.com/microsoft/OmniParser/issues/224\n\nAnd any specific libraries that wouldn't work on Mac?\n\nI'm a Doctor and don't know much about coding. This software will help me significantly with document handling tasks.\n\nThanks.\n\n\n\n\n\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "hi, you could try  it now!  i'd update the logic, so it can run on Mac."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 103,
    "title": "å¯ä»¥éº»çƒ¦æ”¯æŒä¸€ä¸‹Azureçš„openAIå—",
    "author": "Rosejacka",
    "state": "closed",
    "created_at": "2025-03-17T04:07:56Z",
    "updated_at": "2025-03-21T02:50:45Z",
    "labels": [],
    "body": null,
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ç†è®ºä¸Šå·²ç»é€‚é…äº†ï¼Œä½ æ˜¯é‡åˆ°ä»€ä¹ˆé”™è¯¯äº†å—"
      },
      {
        "user": "Rosejacka",
        "body": "å¦‚ä½•åœ¨é¡µé¢é…ç½®å‘¢?æˆ‘å·²ç»æ­£ç¡®å¡«å†™äº†æˆ‘çš„url ä»¥åŠkeyä»¥åŠgpt4o"
      },
      {
        "user": "yuruotong1",
        "body": "æŠ¥ä»€ä¹ˆé”™å‘¢ï¼Ÿ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 89,
    "title": "Is it only supporting GPT-4 for now?",
    "author": "gavinju",
    "state": "closed",
    "created_at": "2025-03-13T21:01:44Z",
    "updated_at": "2025-03-21T02:41:55Z",
    "labels": [],
    "body": "Is it only supporting GPT-4 for now?\nWe hope to support more models, especially those that can be accessed through SiliconFlow.\n\ntks\n\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "We need the ability to multimodal and structured output, especially openai, which supports pydantic structured output, It could save us a lot of effort if other models with both capabilities are currently available. automate is still at a very early stage, and we're probably going to focus on multi-agent collaboration, Solve real user scenarios, and then wait until the project really solves everyone's problems before you think about compatibility adaptations, Otherwise only do toys do not do practical tools, then the project may not survive this year."
      },
      {
        "user": "Rosejacka",
        "body": "æ”¯æŒazureçš„openaiå˜›"
      },
      {
        "user": "yuruotong1",
        "body": "> æ”¯æŒazureçš„openaiå˜›\n\nè¿™ä¸ªè¿˜æ²¡æµ‹è¯•ï¼Œç†è®ºä¸Šæ˜¯æ”¯æŒçš„"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 109,
    "title": "[Feature Request]",
    "author": "devops724",
    "state": "closed",
    "created_at": "2025-03-18T06:45:17Z",
    "updated_at": "2025-03-20T18:05:04Z",
    "labels": [
      "bug"
    ],
    "body": " i serve local running VLM that provide openai api capability \nhow i can set local network endpoint , port , access key , model name...",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Local large models are not yet supported, so it is recommended to look at the list of large models listed in readme."
      },
      {
        "user": "devops724",
        "body": "but it can be as simply as add custom url token to openai capability urls \nmost engine like vllm support text/completion and same as openai api "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 107,
    "title": "autoMate Liinux Mint 22.1 Cinnamon - API ratelimit",
    "author": "Luci-Manus",
    "state": "closed",
    "created_at": "2025-03-18T02:35:51Z",
    "updated_at": "2025-03-19T17:52:08Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: Current\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\nFile \"/home/name/Downloads/opt/anaconda3/envs/automate/lib/python3.12/site-packages/openai/_base_client.py\", line 1061, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-1EdAY23eggNgX4Ej0UPb3d8c on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n\n```\n\n## Description\ngetting an api rate limit, maybe add a field that lets us delay the script or add api rate limit throttling so it continues to complete the task it just performs 1 entry per 20 seconds as the api entry mentions.\n\n### Current Behavior\nBroken\n\n### Expected Behavior\nThe thing to work without needing openai pro for chatgpt access\n\nOther:\n\nCan I just get this to use a local copy of ollama using a multimodel output model like gemma3 or llava or something? I tried sending the default URL to my ollama URL but couldn't get it working. \n\nMy goal is to get AutoMate and use ollama to be the eyes and hands of AutoMate which I will then use to operate LocalAI for me and it will pass the generated contents back to me via autoMate.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "First issue: I believe the current execution speed is already very slow, which is likely caused by your API being throttled due to speed limits from other usage scenarios. Many users have been widely reporting that autoMate's performance is significantly degraded.\n\nSecond issue: This concern has been raised by numerous users. Our team will prioritize considering the integration of Ollama in future updates to enable local deployment capabilities for autoMate."
      },
      {
        "user": "Luci-Manus",
        "body": "I'm trying to get openManus or autoMate working so i can use it to troubleshoot eachother and other ai models idk if that's dumb but i'm dumber than these ai lol i cannot get anything working beyond ollama interminal and localai (which i can't figure out how to shut off)\n"
      },
      {
        "user": "yuruotong1",
        "body": "Your idea is exceptional and has unlocked a fresh direction for our productâ€™s application! We deeply value innovative efforts like yoursâ€”please donâ€™t hesitate to reach out anytime challenges arise. Weâ€™re here to support you every step of the way!\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 105,
    "title": "Does it support Apple Silicon M series?",
    "author": "fylm",
    "state": "closed",
    "created_at": "2025-03-17T09:15:06Z",
    "updated_at": "2025-03-19T14:11:28Z",
    "labels": [
      "bug"
    ],
    "body": "Does it support Apple Silicon M series?",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Sorry, i doesn't have an M-series coMputer, but we use pure visual technology, which in theory can run on any device."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 113,
    "title": "è°ƒç”¨openai è¿”å›ç»“æœ jsonè§£æå¤±è´¥",
    "author": "ljtth",
    "state": "closed",
    "created_at": "2025-03-19T02:46:23Z",
    "updated_at": "2025-03-19T11:17:58Z",
    "labels": [
      "bug"
    ],
    "body": "æ„Ÿè°¢å¼€æº~\né‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œé¡¹ç›®æˆåŠŸå¯åŠ¨ï¼Œapiä¹Ÿé€šäº†ã€‚ä½†æ˜¯é€šäº†ä¹‹åçš„è¿”å›å€¼ä¼šæŠ¥jsonè§£æå¤±è´¥ï¼Œè¯·é—®æ˜¯ä¸æ˜¯å’Œå“ªä¸ªçš„ç‰ˆæœ¬å¯¼è‡´çš„é—®é¢˜ã€‚æ„Ÿè°¢å›å¤\n\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 712, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1574, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 710, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 704, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 687, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 848, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"D:\\Demo\\autoMate\\autoMate\\gradio_ui\\app.py\", line 137, in process_input\n    for _ in sampling_loop_sync(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Demo\\autoMate\\autoMate\\gradio_ui\\loop.py\", line 33, in sampling_loop_sync\n    task_plan_agent(messages=messages, parsed_screen_result=parsed_screen_result)\n  File \"D:\\Demo\\autoMate\\autoMate\\gradio_ui\\agent\\task_plan_agent.py\", line 20, in __call__\n    response = run(messages, user_prompt=system_prompt.format(screen_info=screen_info, action_list=str(Action)), response_format=TaskPlanResponse)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\xbrain\\core\\chat.py\", line 30, in run\n    chat_response = prepare_openai_tools(messages, user_prompt, response_format)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\xbrain\\core\\chat.py\", line 8, in prepare_openai_tools\n    chat_response = chat(messages, tools=[i[\"model\"] for i in xbrain_tool.tools], user_prompt=user_prompt, response_format=response_format)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\xbrain\\utils\\openai_utils.py\", line 16, in chat\n    response = client.beta.chat.completions.parse(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 156, in parse\n    return self._post(\n           ^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1280, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 957, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1063, in _request\n    return self._process_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py\", line 1162, in _process_response\n    return api_response.parse()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_response.py\", line 319, in parse\n    parsed = self._options.post_parser(parsed)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 150, in parser\n    return _parse_chat_completion(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 110, in parse_chat_completion\n    \"parsed\": maybe_parse_content(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 161, in maybe_parse_content\n    return _parse_content(response_format, message.content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 221, in _parse_content\n    return cast(ResponseFormatT, model_parse_json(response_format, content))\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\openai\\_compat.py\", line 169, in model_parse_json\n    return model.model_validate_json(data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Tools\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py\", line 597, in model_validate_json\n    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 1 validation error for TaskPlanResponse\n  Input should be an object [type=model_type, input_value=[{'reasoning': \"ç”¨æˆ·å¸Œ...è¾“å…¥'horldworld'\"]}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type",
    "comments": [
      {
        "user": "ljtth",
        "body": "pydantic                  2.8.2\npydantic_core             2.20.1\nopenai                    1.55.3\n\napiï¼šhttps://api.openai-next.com/v1/  \nmodel: gpt-4o"
      },
      {
        "user": "yuruotong1",
        "body": "å¯èƒ½ openai-next æœ‰é—®é¢˜ï¼Œå¯ä»¥å°è¯•ç”¨ä¸€ä¸‹é‡å¡"
      },
      {
        "user": "ljtth",
        "body": "ç¡®å®æ˜¯ openai-next æ˜¯æœ‰é—®é¢˜äº†ï¼Œæ¢äº†å¦å¤–ä¸€ä¸ªå°±å¥½äº†ã€‚openai-nextç™½å……å€¼äº†ï¼Œæ²¡æ³•ç”¨ã€‚æ‚¨èƒ½è”ç³»é‚£è¾¹ç»™é€€æ¬¾ä¸ã€‚ä»–é‚£ç½‘ç«™é‡Œé¢è¿ä¸ªå®¢æœéƒ½æ²¡æœ‰ï¼Œæ„Ÿè°¢"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 115,
    "title": "æ‰¾ä¸åˆ°openaiçš„åŒ…",
    "author": "A97139012",
    "state": "closed",
    "created_at": "2025-03-19T06:28:29Z",
    "updated_at": "2025-03-19T08:28:24Z",
    "labels": [
      "bug"
    ],
    "body": "\n## Error Message\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"E:\\secert_data\\automate\\autoMate\\omniserver.py\", line 14, in <module>\n[SERVER-ERR]     from util.omniparser import Omniparser\n[SERVER-ERR]   File \"E:\\secert_data\\automate\\autoMate\\util\\omniparser.py\", line 1, in <module>\n[SERVER-ERR]     from util.utils import get_som_labeled_img, get_caption_model_processor, get_yolo_model, check_ocr_box\n[SERVER-ERR]   File \"E:\\secert_data\\automate\\autoMate\\util\\utils.py\", line 11, in <module>\n[SERVER-ERR]     from openai import AzureOpenAI\n[SERVER-ERR] ModuleNotFoundError: No module named 'openai'\nTraceback (most recent call last):\n  File \"E:\\secert_data\\automate\\autoMate\\main.py\", line 78, in <module>\n    run()\n  File \"E:\\secert_data\\automate\\autoMate\\main.py\", line 55, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š1\n\n\n\n## Description\næˆ‘å·²ç»åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…äº†openaiï¼Œä½†æ˜¯è¿˜æ˜¯æ— æ³•æ‰¾åˆ°è¿™ä¸ªåŒ…ï¼Œä½†æ˜¯æˆ‘å•ç‹¬utils.pyæ˜¯å¯ä»¥è¿è¡Œçš„ï¼Œä½†æ˜¯å¦‚æœæˆ‘è¿è¡Œmain.pyå°±ä¼šæŠ¥é”™\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ä½ è¿™ä¸ªç‰ˆæœ¬çš„ä»£ç éå¸¸æ—§äº†ï¼Œå¯ä»¥æ‹‰ä¸€ä¸‹æœ€æ–°ä»£ç ï¼"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 108,
    "title": "[BUG] vlm_agent.pyæŠ¥äº†ä¸ªé”™",
    "author": "skydragron",
    "state": "closed",
    "created_at": "2025-03-18T05:50:47Z",
    "updated_at": "2025-03-19T07:12:16Z",
    "labels": [
      "bug"
    ],
    "body": "\\gradio_ui\\agent\\vlm_agent.py\", line 76, in __call__     vlm_response, token_usage = run_oai_interleaved(ï¼Œè¿è¡Œååœ¨ç½‘é¡µä¸­è¾“å…¥apikeyå†è¾“å…¥é—®é¢˜ï¼Œå‡ºç°å¦‚ä¸ŠæŠ¥é”™",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªæ˜¯å¾ˆæ—©çš„ä»£ç äº†ï¼Œè¾›è‹¦æ›´æ–°ä¸€ä¸‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 102,
    "title": "æµ‹è¯•ä¸æ˜¯å¾ˆæˆåŠŸï¼",
    "author": "Roxywusu",
    "state": "closed",
    "created_at": "2025-03-17T01:59:13Z",
    "updated_at": "2025-03-19T04:25:46Z",
    "labels": [],
    "body": null,
    "comments": [
      {
        "user": "yuruotong1",
        "body": "å¯ä»¥è¯¦ç»†æè¿°ä¸€ä¸‹ä½ çš„é—®é¢˜ï¼Œç”¨ä¸€ä¸‹æˆ‘æŒ‡å®šçš„API"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 110,
    "title": "[BUG]",
    "author": "skydragron",
    "state": "closed",
    "created_at": "2025-03-18T10:37:19Z",
    "updated_at": "2025-03-19T04:17:56Z",
    "labels": [
      "bug"
    ],
    "body": "è¿è¡Œpython mainåæŠ¥é”™\nModuleNotFoundError: No module named 'xbrain'ï¼Œä½†æ˜¯æˆ‘å®‰è£…äº†è¯¥æ¨¡å—ï¼Œ\næ‰§è¡Œpip show xbrainåï¼š\nName: xbrain\nVersion: 0.0.1\nSummary: Python library of standardized neural data analysis pipelines\nHome-page: https://github.com/doerlbh/xbrain\nAuthor: Baihan Lin\nAuthor-email: doerlbh@gmail.com\nLicense: GPLv3\nLocation: ...\\lib\\site-packages\\xbrain-0.0.1-py3.12.egg\nRequires: numpy, pandas\nRequired-by:\n\n\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "å»ºè®®æŒ‰ç…§ readme å®‰è£… requirementsï¼Œæ˜¯ pyxbrain è€Œä¸æ˜¯ xbrain"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 111,
    "title": "[BUG] ç¡…åŸºæµåŠ¨çš„apiæ˜¯ç”¨ä¸äº†å—",
    "author": "webwww123",
    "state": "closed",
    "created_at": "2025-03-18T12:53:55Z",
    "updated_at": "2025-03-19T04:17:50Z",
    "labels": [
      "bug"
    ],
    "body": "å¦‚é¢˜",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ”¯æŒçš„å¤§æ¨¡å‹å·²ç»åœ¨ readme ä¸­ä»‹ç»äº†"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 112,
    "title": "--",
    "author": "skydragron",
    "state": "closed",
    "created_at": "2025-03-19T01:59:33Z",
    "updated_at": "2025-03-19T03:20:48Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\n\n```\n\n## Description\n\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 106,
    "title": "è¿è¡Œä¹‹åä¸æŠ¥é”™ï¼Œlocalhost7888ä¹Ÿæ— æ³•è®¿é—®",
    "author": "qzltianxing",
    "state": "closed",
    "created_at": "2025-03-17T16:48:46Z",
    "updated_at": "2025-03-19T01:37:21Z",
    "labels": [
      "bug"
    ],
    "body": "## Version Information\n- Commit Hash: <!-- e.g. abc123def456 -->\n\n## Error Message\n<!-- Paste your error message in markdown -->\n```\nPS G:\\autoMate> python main.py\ncuda is_available:  True\nMPS is_available:  False\ncuda device_count 1\ncuda device_name NVIDIA GeForce RTX 2070 SUPER\nModel files already detected!\n```\n\n## Description\nè¿è¡Œåˆ°è¿™é‡Œå°±æ²¡ååº”äº†ï¼Œhttp://localhost:7888/ ä¹Ÿæ— æ³•è®¿é—®\n\n### Current Behavior\n<!-- Describe what actually happened -->\n\n### Expected Behavior\n<!-- Describe what you expected to happen -->\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ç¨ç­‰æˆ‘æ¥çœ‹çœ‹ï¼"
      },
      {
        "user": "yuruotong1",
        "body": "å¯ä»¥æ‹‰ä¸€ä¸‹æœ€æ–°çš„ä»£ç ï¼Œè¯•è¯•è¿˜æœ‰é—®é¢˜å—ï¼Ÿ"
      },
      {
        "user": "SkalaFrost",
        "body": "i got the same problem with lastest code base\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 104,
    "title": "OSError: We couldn't connect to 'https://huggingface.co' to load this file",
    "author": "damaomaom",
    "state": "closed",
    "created_at": "2025-03-17T06:40:20Z",
    "updated_at": "2025-03-18T02:17:46Z",
    "labels": [
      "bug"
    ],
    "body": "å·²ç»æ˜¯æœ€æ–°çš„ç¨‹åºåŒ…ï¼Œè¿˜æ˜¯å‡ºç°è¿™ä¸ªã€‚\n(automate) D:\\autoMate\\autoMate>python main.py\ncuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\nGPU driver is not compatible, please install the appropriate version of torch according to the readme!\nModel files already detected!\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000001CC9089DC40>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CC9089DC40>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n    response = _request_wrapper(\n               ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CC9089DC40>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: e11b73d6-9a22-41bb-aa19-2f12053c7470)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 342, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 862, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 969, in _hf_hub_download_to_cache_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\autoMate\\autoMate\\main.py\", line 19, in <module>\n    run()\n  File \"D:\\autoMate\\autoMate\\main.py\", line 15, in run\n    app.run()\n  File \"D:\\autoMate\\autoMate\\gradio_ui\\app.py\", line 320, in run\n    vision_agent = VisionAgent(yolo_model_path=os.path.join(MODEL_DIR, \"icon_detect\", \"model.pt\"),\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\autoMate\\autoMate\\gradio_ui\\agent\\vision_agent.py\", line 35, in __init__\n    self.caption_processor = AutoProcessor.from_pretrained(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line 305, in from_pretrained\n    config = AutoConfig.from_pretrained(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 1075, in from_pretrained\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 594, in get_config_dict\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 653, in _get_config_dict\n    resolved_config_file = cached_file(\n                           ^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 385, in cached_file\n    raise EnvironmentError(\nOSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like microsoft/Florence-2-base is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æˆ‘ä»¬å·²ç»æ‰¾åˆ°åŸå› ï¼Œäº†æ­£åœ¨ä¿®æ”¹ä»£ç "
      },
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªé—®é¢˜å·²ç»è§£å†³äº†ï¼Œå¯ä»¥çœ‹æœ€æ–°ä»£ç "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 97,
    "title": "æ— æ³•è¿æ¥åˆ°Hugging Faceçš„æœåŠ¡å™¨",
    "author": "damaomaom",
    "state": "closed",
    "created_at": "2025-03-15T02:09:15Z",
    "updated_at": "2025-03-17T04:51:20Z",
    "labels": [],
    "body": "(automate) D:\\autoMate\\autoMate-master>python main.py\ncuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\nGPU driver is not compatible, please install the appropriate version of torch according to the readme!\nModel files already detected!\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x00000133D476DC70>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000133D476DC70>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n    response = _request_wrapper(\n               ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000133D476DC70>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 2615a1f1-15ce-4520-aa35-74db35af4321)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 342, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 862, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 969, in _hf_hub_download_to_cache_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 20, in <module>\n    run()\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 16, in run\n    app.run()\n  File \"D:\\autoMate\\autoMate-master\\gradio_ui\\app.py\", line 283, in run\n    vision_agent = VisionAgent(yolo_model_path=os.path.join(MODEL_DIR, \"icon_detect\", \"model.pt\"),\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\autoMate\\autoMate-master\\gradio_ui\\agent\\vision_agent.py\", line 35, in __init__\n    self.caption_processor = AutoProcessor.from_pretrained(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line 305, in from_pretrained\n    config = AutoConfig.from_pretrained(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 1075, in from_pretrained\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 594, in get_config_dict\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 653, in _get_config_dict\n    resolved_config_file = cached_file(\n                           ^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 385, in cached_file\n    raise EnvironmentError(\nOSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like microsoft/Florence-2-base is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ˜¯æœ€æ–°ç‰ˆæœ¬ä»£ç å—ï¼Ÿæœ€æ–°ç‰ˆæœ¬ä»£ç å·²ç»ä¸ä» huggingface æ‹‰å–é•œåƒäº†"
      },
      {
        "user": "damaomaom",
        "body": "ä»Šå¤©åˆšä¸‹çš„ä»£ç ï¼Œæœ€æ–°çš„ä»£ç ã€‚\n\n(automate) D:\\autoMate\\autoMate-master>python main.py\nOMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\nOMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/."
      },
      {
        "user": "shao-ssq",
        "body": "> æ˜¯æœ€æ–°ç‰ˆæœ¬ä»£ç å—ï¼Ÿæœ€æ–°ç‰ˆæœ¬ä»£ç å·²ç»ä¸ä» huggingface æ‹‰å–é•œåƒäº†\n\næˆ‘ä¹Ÿé‡åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œä¼¼ä¹æ˜¯https://huggingface.co/ ä»Šå¤©æ²¡åŠæ³•è®¿é—®ï¼Œæˆ‘æ—©ä¸Šè¿˜å¯ä»¥ï¼Œåé¢æ‹‰å–äº†æœ€æ–°ä»£ç ï¼Œå°±å‡ºç°äº†ã€‚"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 100,
    "title": "ä¸æ”¯æŒWSLä¸Šçš„Ubuntu20.04ä¹ˆï¼Ÿ",
    "author": "linuaries",
    "state": "closed",
    "created_at": "2025-03-15T14:17:20Z",
    "updated_at": "2025-03-17T04:51:11Z",
    "labels": [],
    "body": "python main.py ä¹‹åä¸‹è½½å®Œæ‰€æœ‰æ¨¡å‹ï¼Œæœ€åè·³å‡ºè¿™ä¸ªæç¤ºã€‚\n\n[SERVER-OUT] \n[SERVER-OUT] ----------------------\n[SERVER-OUT] Error Message Summary:\n[SERVER-OUT] ----------------------\n[SERVER-OUT] FatalError: `Illegal instruction` is detected by the operating system.\n[SERVER-OUT]   [TimeInfo: *** Aborted at 1742047831 (unix time) try \"date -d @1742047831\" if you are using GNU date ***]\n[SERVER-OUT]   [SignalInfo: *** SIGILL (@0x7f506957260a) received by PID 247198 (TID 0x7f5290822740) from PID 1767319050 ***]\n[SERVER-OUT] \nç­‰å¾…æœåŠ¡å¯åŠ¨...\nTraceback (most recent call last):\n  File \"/home/aistudio/CVs/autoMate/main.py\", line 78, in <module>\n    run()\n  File \"/home/aistudio/CVs/autoMate/main.py\", line 55, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š-4",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ç›´æ¥åœ¨ windows ä¸Šå°±èƒ½è·‘ï¼Œè¿˜çœŸæ²¡è¯•è¿‡ WSL..."
      },
      {
        "user": "Gushroom",
        "body": "è¯·æ£€æŸ¥ä¸‹æ˜¯å¦å·²ç»æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬äº†ï¼Œæœ€è¿‘æ›´æ–°é¢‘ç‡æ¯”è¾ƒé«˜ï¼Œè¯·æŒç»­å…³æ³¨æœ€æ–°ä¿®å¤ï¼"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 101,
    "title": "License?",
    "author": "limcheekin",
    "state": "closed",
    "created_at": "2025-03-16T12:47:30Z",
    "updated_at": "2025-03-17T00:44:10Z",
    "labels": [],
    "body": "Thanks for sharing the code.\n\nAppreciate if you could add a LICENSE file to the repo.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Thank you very much for reminding me. I will add a licenseï¼"
      },
      {
        "user": "yuruotong1",
        "body": "> Thanks for sharing the code.\n> \n> Appreciate if you could add a LICENSE file to the repo.\n\nI have add an MIT liecense."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 98,
    "title": "æˆ‘åœ¨è¿è¡Œçš„æ—¶å€™å‡ºç°äº†æŠ¥é”™ï¼šTaskPlanResponse è§£æ JSON æ—¶å‡ºç°æ ¼å¼é”™è¯¯",
    "author": "shao-ssq",
    "state": "closed",
    "created_at": "2025-03-15T05:57:49Z",
    "updated_at": "2025-03-15T14:50:08Z",
    "labels": [],
    "body": "å…·ä½“é”™è¯¯æ˜¯ Invalid JSON: expected value at line 2 column 1ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿”å›çš„æ•°æ®ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚\n\næˆ‘ä½¿ç”¨äº†æœ€æ–°çš„ä»£ç å¹¶ä¸”é‡æ–°ç”³è¯·äº†OpenAI nextçš„keyã€‚\n\nTraceback (most recent call last):\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\blocks.py\", line 2103, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\utils.py\", line 735, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\utils.py\", line 729, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\utils.py\", line 712, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\gradio\\utils.py\", line 873, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"D:\\autoMate\\gradio_ui\\app.py\", line 113, in process_input\n    for _ in sampling_loop_sync(\n  File \"D:\\autoMate\\gradio_ui\\loop.py\", line 35, in sampling_loop_sync\n    plan_list = task_plan_agent(messages=messages, parsed_screen_result=parsed_screen_result)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\autoMate\\gradio_ui\\agent\\task_plan_agent.py\", line 18, in __call__\n    response = run(messages, user_prompt=system_prompt.format(screen_info=screen_info), response_format=TaskPlanResponse)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\xbrain\\core\\chat.py\", line 30, in run\n    chat_response = prepare_openai_tools(messages, user_prompt, response_format)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\xbrain\\core\\chat.py\", line 8, in prepare_openai_tools\n    chat_response = chat(messages, tools=[i[\"model\"] for i in xbrain_tool.tools], user_prompt=user_prompt, response_format=response_format)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\xbrain\\utils\\openai_utils.py\", line 16, in chat\n    response = client.beta.chat.completions.parse(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 156, in parse\n    return self._post(\n           ^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1280, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 957, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1063, in _request\n    return self._process_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1162, in _process_response\n    return api_response.parse()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_response.py\", line 319, in parse\n    parsed = self._options.post_parser(parsed)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 150, in parser\n    return _parse_chat_completion(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 110, in parse_chat_completion\n    \"parsed\": maybe_parse_content(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 161, in maybe_parse_content\n    return _parse_content(response_format, message.content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 221, in _parse_content\n    return cast(ResponseFormatT, model_parse_json(response_format, content))\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_compat.py\", line 169, in model_parse_json\n    return model.model_validate_json(data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\pydantic\\main.py\", line 656, in model_validate_json\n    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 1 validation error for TaskPlanResponse\n  Invalid JSON: expected value at line 2 column 1 [type=json_invalid, input_value='\\n> search(\"æ­¦æ±‰å¤©æ°”...åšå¥½å‡ºè¡Œå®‰æ’ã€‚ ', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/json_invalid",
    "comments": [
      {
        "user": "shao-ssq",
        "body": "api key æ˜¾ç¤ºå·²ç»æˆåŠŸæ¶ˆè´¹ï¼Œä½†æ˜¯è¿”å›çš„JSONä¼¼ä¹æ˜¯æœ‰é—®é¢˜çš„ã€‚"
      },
      {
        "user": "shao-ssq",
        "body": "å½“æˆ‘å°è¯•ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹ï¼šgpt-4.5-preview-2025-02-27\næŠ¥é”™ï¼š\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n    return self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1095, in _retry_request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"D:\\Miniconda3\\envs\\AutoMate\\Lib\\site-packages\\openai\\_base_client.py\", line 1061, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.InternalServerError: Error code: 500 - {'error': {'message': 'bad response status code 500 (request id: 2025031514080023726644529196622)', 'localized_message': 'Unknown error', 'type': 'upstream_error', 'param': '500', 'code': 'bad_response_status_code'}}"
      },
      {
        "user": "shao-ssq",
        "body": "æˆ‘çŒœæµ‹å¯èƒ½æ˜¯æœ€è¿‘ä¸€æ¬¡æ›´æ–°å¯¼è‡´çš„ï¼Œæ˜¨å¤©æˆ‘ç”¨ä½ çš„keyå¯ä»¥å®ç°çš„ï¼Œä»Šå¤©ä½ çš„keyå¤±æ•ˆäº†ï¼Œç„¶åæˆ‘é‡æ–°è´­ä¹°äº†keyï¼Œç„¶åæŠ¥é”™äº†ã€‚\n\næ–°æ¨¡å‹ gpt-4.5-preview-2025-02-27 æ˜¯æ²¡æœ‰è¯·æ±‚åˆ°ï¼Œæ²¡æœ‰æ¶ˆè´¹ã€‚\n\næˆ‘ä½¿ç”¨python SDK çš„è®¿é—® gpt-4.5-preview-2025-02-27 ä»»ç„¶æ˜¯æŠ¥é”™ï¼šopenai.InternalServerError: Error code: 500 - {'error': {'message': 'bad response status code 500 (request id: 2025031514564547055486425958814)', 'localized_message': 'Unknown error', 'type': 'upstream_error', 'param': '500', 'code': 'bad_response_status_code'}}\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=\"key\", base_url=\"https://api.openai-next.com/v1\")\n\ncompletion = client.chat.completions.create(\n    model=\"gpt-4.5-preview-2025-02-27\",\n    stream=False,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ]\n)\n\nprint(completion.choices[0].message)\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 93,
    "title": "urllib3\\connectionè¿æ¥ä¸ä¸Šï¼Ÿæ¨¡å‹çš„è¿è¡Œæ”¯æŒç¯å¢ƒå—ï¼Ÿ",
    "author": "fishergithub",
    "state": "closed",
    "created_at": "2025-03-14T08:56:30Z",
    "updated_at": "2025-03-15T14:49:45Z",
    "labels": [],
    "body": "æ¢¯å­æˆ‘æœ‰çš„ï¼Œèƒ½å¤Ÿç§‘å­¦ä¸Šç½‘ã€‚ä½†æˆ‘é¼“æ£äº†åŠå¤©æˆ‘è¿˜æ˜¯æ²¡è¿›å±•ï¼Œå°ç™½æ±‚å¤§ä½¬èµæ•™è¯¥æ€ä¹ˆç ´~\n\n(D:\\MyProjects\\conda_envs\\automate) D:\\MyProjects\\automate>python main.py\ncuda is_available:  True\nMPS is_available:  False\ncuda device_count 1\ncuda device_name NVIDIA GeForce RTX 4060 Laptop GPU\nModel files already detected!\nD:\\MyProjects\\automate\\gradio_ui\\app.py:296: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n  chatbot = gr.Chatbot(\nTraceback (most recent call last):\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "é¦–å…ˆï¼Œå»ºè®®æ›´æ–°ä¸ºæœ€æ–°çš„ä»£ç ï¼Œçœ‹ä»£ç æŠ¥é”™ç›®å‰è¿˜æ˜¯ä¸Šä¸€ä¸ªç‰ˆæœ¬çš„å†…å®¹ã€‚å…¶æ¬¡ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬éªŒè¯è¿‡çš„æ¨¡å‹ï¼Œreadme æœ‰ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢ä¼šä¸æ–­è¿­ä»£å…¼å®¹çš„å‚å•†ï¼"
      },
      {
        "user": "fishergithub",
        "body": "> é¦–å…ˆï¼Œå»ºè®®æ›´æ–°ä¸ºæœ€æ–°çš„ä»£ç ï¼Œçœ‹ä»£ç æŠ¥é”™ç›®å‰è¿˜æ˜¯ä¸Šä¸€ä¸ªç‰ˆæœ¬çš„å†…å®¹ã€‚å…¶æ¬¡ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬éªŒè¯è¿‡çš„æ¨¡å‹ï¼Œreadme æœ‰ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢ä¼šä¸æ–­è¿­ä»£å…¼å®¹çš„å‚å•†ï¼\n\nå¥½çš„ï¼Œæˆ‘å·²æŒ‰ç…§æœ€æ–°ç‰ˆçš„æ›´æ–°äº†ã€‚ç°åœ¨ä¼¼ä¹è¿˜æ˜¯å¡åœ¨connectionçš„é—®é¢˜è€¶ï¼Ÿ\n(D:\\MyProjects\\conda_envs\\automate) D:\\MyProjects\\automate>python main.py\ncuda is_available:  True\nMPS is_available:  False\ncuda device_count 1\ncuda device_name NVIDIA GeForce RTX 4060 Laptop GPU\nModel files already detected!\nTraceback (most recent call last):\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\MyProjects\\conda_envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nå¦å¤–ï¼Œå…¼å®¹å‚å•†çš„æ¨¡å‹æˆ‘æ˜ç™½äº†ï¼Œç›®å‰æ”¯æŒçš„æ˜¯openai~æ„Ÿè°¢å›ç­”~ï¼"
      },
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªæŠ¥é”™ä¸å…¨ï¼Œ connection æ˜¯è¦è¿å“ªé‡Œå‘¢ï¼Ÿå¦å¤–å»ºè®®ç”¨ markdown åŒ…è£¹ä¸€ä¸‹ä½ çš„æŠ¥é”™ä¿¡æ¯ï¼Œè¿™æ ·æ›´å®¹æ˜“è®©äººçœ‹æ‡‚!"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 99,
    "title": "å…³äºsystem prompt çš„æé—®",
    "author": "LeeOrange-is-me",
    "state": "closed",
    "created_at": "2025-03-15T06:42:09Z",
    "updated_at": "2025-03-15T14:23:30Z",
    "labels": [],
    "body": "ä½œè€…ä¹‹å‰çš„promptæˆ‘è®°å¾—æ˜¯è‹±æ–‡ï¼Œä¸ºä»€ä¹ˆæ¢æˆä¸­æ–‡äº†ï¼Ÿä½œè€…æ˜¯åŸºäºä»€ä¹ˆæ ·å­çš„è€ƒé‡å†™ä¸­æ–‡çš„system prompt?\nä½œè€…æ˜¯å¯¹system prompt åšäº†ä¸€äº›æ¢ç©¶å—ï¼Ÿ\n\nä½œè€…ç›®å‰æœ‰æ²¡æœ‰åœ¨å½“å‰system prompt ä¸Šé¢çš„æˆåŠŸçš„ä¾‹å­å‘¢ï¼Ÿ",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "> ä½œè€…ä¹‹å‰çš„promptæˆ‘è®°å¾—æ˜¯è‹±æ–‡ï¼Œä¸ºä»€ä¹ˆæ¢æˆä¸­æ–‡äº†ï¼Ÿä½œè€…æ˜¯åŸºäºä»€ä¹ˆæ ·å­çš„è€ƒé‡å†™ä¸­æ–‡çš„system prompt?\n\nä¹‹å‰çš„ä»£ç æ˜¯omniparserçš„æç¤ºè¯ï¼Œä½†æ€»ä½“æ¯”è¾ƒç®€å•ï¼Œç”±äºæ–°ç‰ˆAgentæ”¹åŠ¨è¾ƒå¤§ï¼Œå‰æœŸå‡†å¤‡å…ˆç”¨ä¸­æ–‡æ‰€ç¤ºè¯è¿‡æ¸¡ï¼Œåé¢å¾…ç¨³å®šåå†è½¬ä¸ºè‹±æ–‡æç¤ºè¯ã€‚æ¡ˆä¾‹çš„è¯æˆ‘æœ€è¿‘å½•å‡ ä¸ªå‘å‡ºæ¥ã€‚"
      },
      {
        "user": "yuruotong1",
        "body": "> ä½œè€…ä¹‹å‰çš„promptæˆ‘è®°å¾—æ˜¯è‹±æ–‡ï¼Œä¸ºä»€ä¹ˆæ¢æˆä¸­æ–‡äº†ï¼Ÿä½œè€…æ˜¯åŸºäºä»€ä¹ˆæ ·å­çš„è€ƒé‡å†™ä¸­æ–‡çš„system prompt? ä½œè€…æ˜¯å¯¹system prompt åšäº†ä¸€äº›æ¢ç©¶å—ï¼Ÿ\n> \n> ä½œè€…ç›®å‰æœ‰æ²¡æœ‰åœ¨å½“å‰system prompt ä¸Šé¢çš„æˆåŠŸçš„ä¾‹å­å‘¢ï¼Ÿ\n\næˆ‘åˆšæ‰æ›´æ–°äº†ä¸€ä¸ªè§†é¢‘ï¼Œå…³äºè‡ªåŠ¨åŒ–é€šè¿‡å¾®ä¿¡å¥½å‹çš„ä¾‹å­"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 96,
    "title": "æˆ‘æˆåŠŸéƒ¨ç½²äº†ï¼Œä½†æ˜¯æˆ‘åœ¨æ‰§è¡Œçš„æ—¶å€™é‡åˆ°çš„äº†ï¼šæ— æ•ˆçš„ä»¤ç‰Œ , 'type': 'shell_api_error'}}",
    "author": "shao-ssq",
    "state": "closed",
    "created_at": "2025-03-14T11:58:38Z",
    "updated_at": "2025-03-14T12:58:02Z",
    "labels": [],
    "body": "æˆ‘çš„ç¯å¢ƒï¼š\ngpt-4o-2024-11-20\nhttps://api.openai-next.com/v1\næˆ‘çš„ key ç¡®å®šæ˜¯æ²¡é”™çš„ï¼Œå¹¶ä¸”æ˜¯å¯ä»¥è®¿é—® GPT 4oï¼Œä½™é¢å……è¶³ã€‚\nwindows CMD & powershell\n\n\næˆ‘å‘é€ send åï¼Œæ§åˆ¶å°è¾“å‡ºäº†ï¼šopenai.AuthenticationError: Error code: 401 - {'error': {'message': '[proj]æ— æ•ˆçš„ä»¤ç‰Œ (request id: 2025031419475264762428894645609)', 'type': 'shell_api_error'}}\n\n\nå…¨éƒ¨æ—¥å¿—ï¼š\nTraceback (most recent call last):\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\blocks.py\", line 2103, in process_api\n    result = await self.call_function(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n    prediction = await utils.async_iteration(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 735, in async_iteration\n    return await anext(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 729, in __anext__\n    return await anyio.to_thread.run_sync(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n    return await future\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n    result = context.run(func, *args)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 712, in run_sync_iterator_async\n    return next(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 873, in gen_wrapper\n    response = next(iterator)\n  File \"D:\\autoMate\\gradio_ui\\app.py\", line 113, in process_input\n    for _ in sampling_loop_sync(\n  File \"D:\\autoMate\\gradio_ui\\loop.py\", line 35, in sampling_loop_sync\n    plan_list = task_plan_agent(messages=messages, parsed_screen_result=parsed_screen_result)\n  File \"D:\\autoMate\\gradio_ui\\agent\\task_plan_agent.py\", line 18, in __call__\n    response = run(messages, user_prompt=system_prompt.format(screen_info=screen_info), response_format=TaskPlanResponse)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\core\\chat.py\", line 30, in run\n    chat_response = prepare_openai_tools(messages, user_prompt, response_format)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\core\\chat.py\", line 8, in prepare_openai_tools\n    chat_response = chat(messages, tools=[i[\"model\"] for i in xbrain_tool.tools], user_prompt=user_prompt, response_format=response_format)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\utils\\openai_utils.py\", line 16, in chat\n    response = client.beta.chat.completions.parse(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 156, in parse\n    return self._post(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 1280, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 957, in request\n    return self._request(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 1061, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': '[proj]æ— æ•ˆçš„ä»¤ç‰Œ (request id: 2025031419512898553700535924396)', 'type': 'shell_api_error'}}",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ„Ÿè§‰åƒæ˜¯æµè§ˆå™¨è¿‡æœŸäº†ï¼Œä½ åˆ·æ–°ä¸€ä¸‹æµè§ˆå™¨ç•Œé¢ï¼Œç„¶åå†å¤åˆ¶ä¸€ä¸‹ä»¤ç‰Œåˆ°æµè§ˆå™¨ä¸­é‡æ–°è¾“å…¥ä¸€ä¸‹ã€‚"
      },
      {
        "user": "shao-ssq",
        "body": "> æ„Ÿè§‰åƒæ˜¯æµè§ˆå™¨è¿‡æœŸäº†ï¼Œä½ åˆ·æ–°ä¸€ä¸‹æµè§ˆå™¨ç•Œé¢ï¼Œç„¶åå†å¤åˆ¶ä¸€ä¸‹ä»¤ç‰Œåˆ°æµè§ˆå™¨ä¸­é‡æ–°è¾“å…¥ä¸€ä¸‹ã€‚\n\næˆ‘ä½¿ç”¨æ— ç—•æ–¹å¼ï¼Œä½†æ˜¯å¤±è´¥äº†ã€‚æˆ‘çš„keyæ˜¯128 ä½çš„ã€‚"
      },
      {
        "user": "shao-ssq",
        "body": "> æ„Ÿè§‰åƒæ˜¯æµè§ˆå™¨è¿‡æœŸäº†ï¼Œä½ åˆ·æ–°ä¸€ä¸‹æµè§ˆå™¨ç•Œé¢ï¼Œç„¶åå†å¤åˆ¶ä¸€ä¸‹ä»¤ç‰Œåˆ°æµè§ˆå™¨ä¸­é‡æ–°è¾“å…¥ä¸€ä¸‹ã€‚\n\nå¦å¤–ï¼Œæˆ‘æ‰ç”¨ä¸­è½¬çš„æ–¹å¼ï¼ŒæŠ¥é”™ï¼šAttributeError: 'str' object has no attribute 'choices'\n\n````\nTraceback (most recent call last):\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\blocks.py\", line 2103, in process_api\n    result = await self.call_function(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n    prediction = await utils.async_iteration(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 735, in async_iteration\n    return await anext(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 729, in __anext__\n    return await anyio.to_thread.run_sync(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n    return await future\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n    result = context.run(func, *args)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 712, in run_sync_iterator_async\n    return next(iterator)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\gradio\\utils.py\", line 873, in gen_wrapper\n    response = next(iterator)\n  File \"D:\\autoMate\\gradio_ui\\app.py\", line 113, in process_input\n    for _ in sampling_loop_sync(\n  File \"D:\\autoMate\\gradio_ui\\loop.py\", line 35, in sampling_loop_sync\n    plan_list = task_plan_agent(messages=messages, parsed_screen_result=parsed_screen_result)\n  File \"D:\\autoMate\\gradio_ui\\agent\\task_plan_agent.py\", line 18, in __call__\n    response = run(messages, user_prompt=system_prompt.format(screen_info=screen_info), response_format=TaskPlanResponse)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\core\\chat.py\", line 30, in run\n    chat_response = prepare_openai_tools(messages, user_prompt, response_format)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\core\\chat.py\", line 8, in prepare_openai_tools\n    chat_response = chat(messages, tools=[i[\"model\"] for i in xbrain_tool.tools], user_prompt=user_prompt, response_format=response_format)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\xbrain\\utils\\openai_utils.py\", line 16, in chat\n    response = client.beta.chat.completions.parse(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 156, in parse\n    return self._post(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 1280, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 957, in request\n    return self._request(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 1063, in _request\n    return self._process_response(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_base_client.py\", line 1162, in _process_response\n    return api_response.parse()\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\_response.py\", line 319, in parse\n    parsed = self._options.post_parser(parsed)\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 150, in parser\n    return _parse_chat_completion(\n  File \"D:\\Miniconda3\\envs\\AutoMate\\lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 70, in parse_chat_completion\n    for choice in chat_completion.choices:\nAttributeError: 'str' object has no attribute 'choices'\nin sampling_loop_sync, model: gpt-4o-2024-11-20\n```"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 94,
    "title": "æ”¯æŒmacå˜›",
    "author": "wxl1779766474",
    "state": "closed",
    "created_at": "2025-03-14T10:48:08Z",
    "updated_at": "2025-03-14T12:14:06Z",
    "labels": [],
    "body": null,
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ”¯æŒçš„"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 88,
    "title": "hmmm..... this model's url doesn't appear to be valid?",
    "author": "weisk",
    "state": "closed",
    "created_at": "2025-03-13T18:45:26Z",
    "updated_at": "2025-03-14T12:13:24Z",
    "labels": [],
    "body": "in [this commit](https://github.com/yuruotong1/autoMate/commit/23331aaa67c75e66ddccbc096eb0bacc38815bc7#diff-4303b0bda0cedc61d2f19bc7148d039b7c82738f78e52df01b1ccafa2b80b11bR3),\n\nthis url was introduced for the openainext model api, which appears to be a phising site...\n\ncloudflare prevents me from accessing it, also this is reported by virustotal:\n\n![Image](https://github.com/user-attachments/assets/4061201e-106c-4da7-b4de-b5c1862c5643)",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "You can also use openai's official gpt 4o interface directly!"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 87,
    "title": "æ—¶å¸¸sentitive words detected",
    "author": "YXuan66",
    "state": "closed",
    "created_at": "2025-03-13T13:00:09Z",
    "updated_at": "2025-03-14T12:13:11Z",
    "labels": [],
    "body": "æˆ‘æ›´æ¢äº†https://api.moleapi.com/v1ä½œä¸ºbaseurlè°ƒç”¨gpt4oï¼Œä½†æ˜¯ç»å¸¸openai.BadRequestError: Error code: 400 - {'error': {'message': 'sensitive words: 8964,8964 (request id: 20250313205909537876276OGDih6VW)', 'type': 'mole_api_error', 'param': '', 'code': 'sensitive_words_detected'}}",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªæ˜æ˜¾æ˜¯è¿™ä¸ªç½‘ç«™é¢å¤–åŠ çš„é™åˆ¶ï¼Œå®ƒé™åˆ¶äº†ä¸€äº›æ•æ„Ÿè¯æé—®ï¼Œä¹Ÿå¯ä»¥æ¢ä¸‹æˆ‘ä»¬æ¨èçš„ä»£ç†ç«™"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 90,
    "title": "åŠŸèƒ½æ‰§è¡Œå¦‚ä½•æé«˜å‡†ç¡®åº¦",
    "author": "llk2014",
    "state": "closed",
    "created_at": "2025-03-14T03:46:44Z",
    "updated_at": "2025-03-14T12:13:04Z",
    "labels": [],
    "body": "çœ‹äº†ä¸€åœˆissueå‘ç°æ²¡æœ‰äººé—®ç›¸å…³é—®é¢˜ï¼Œä¸çŸ¥é“å¤§å®¶çš„è¿è¡Œæƒ…å†µå¦‚ä½•\n\næˆ‘ç»™å‡ºçš„promptæ˜¯ï¼šåœ¨å½“å‰æµè§ˆå™¨æ‰“å¼€douyin.com\n\nè¯•äº†ç™¾ç‚¼ä¸Šæ‰€æœ‰æ¨¡å‹ï¼Œéƒ½æ²¡æœ‰æˆåŠŸæ‰“å¼€æŠ–éŸ³\nèµ°å¾—æœ€è¿œçš„æ˜¯deepseek-v3ï¼Œä»–åœ¨è¯†åˆ«æµè§ˆå™¨ã€æ‰¾åˆ°åœ°å€æ è¿™ä¸€æ­¥å¡ä½äº†ï¼Œåå¤çš„æ‰“å¼€æµè§ˆå™¨ï¼Œçœ‹èµ·æ¥ä»–ä¸è®¤è¯†æµè§ˆå™¨é•¿ä»€ä¹ˆæ ·\nå°è¯•äº†ç¤ºä¾‹çš„åˆ txtçš„promptï¼Œä¹Ÿæ²¡æœ‰æˆåŠŸï¼Œåœåœ¨äº†å³é”®èœå•ï¼Œç‚¹å‡»åˆ é™¤è¿™ä¸€æ­¥\n\nä¸€ä¸ªæœ€å¸¸è§çš„é—®é¢˜æ˜¯ï¼š\npydantic_core._pydantic_core.ValidationError: 1 validation error for TaskRunAgentResponse\n  Input should be an object [type=model_type, input_value=1.0, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type\nå¶å‘æ€§çš„ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯å›½å†…å¤§æ¨¡å‹çš„é—®é¢˜ï¼Œgpt-4oæ˜¯å¦ä¸å­˜åœ¨è¿™ä¸ªé—®é¢˜\n\næˆ‘çš„é—®é¢˜æ˜¯ï¼šå¦‚ä½•æé«˜åŠŸèƒ½å‡†ç¡®åº¦\næ˜¯å¦ä¸å±å¹•åˆ†è¾¨ç‡ï¼Œå›¾æ ‡å¤§å°ï¼Œæ˜¾ç¤ºå™¨å…ƒç´ æ•°é‡æœ‰å…³ç³»ã€‚ã€‚ã€‚",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "é—®é¢˜ä¸€ï¼šè·‘ä¸‹æ¥æ„Ÿè§‰omniparserçš„æ‰“æ ‡ä¼°è®¡åªæœ‰30%å·¦å³çš„å‡†ç¡®ç‡ï¼Œå¦‚æœè¦å®ç°ç²¾å‡†è¯†åˆ«ç›®å‰æ˜¯ä¸å¯èƒ½çš„ï¼Œè¿™åº”è¯¥æ˜¯computer useç±»å·¥å…·çš„é€šç—…ï¼Œåˆ†æä¸‹æ¥æœ‰ä¸¤ä¸ªè§£å†³æ–¹æ¡ˆï¼ˆ1ï¼‰é€šè¿‡ä¼˜åŒ–æç¤ºè¯å¢åŠ å¤šagentè§„åˆ’èƒ½åŠ›ï¼ˆ2ï¼‰æ¥å…¥æ›´å¥½çš„å¤šæ¨¡æ€å¤§æ¨¡æ€ã€‚ä½†æ„Ÿè§‰ç›®å‰ä¸¤ç§æ–¹æ³•éƒ½ ä¸ä¼šè§£å†³æ ¹æœ¬é—®é¢˜ï¼Œæˆ‘ä»¬ä¹Ÿåœ¨ç§¯æçš„å¯»æ‰¾æ›´ä¼˜çš„æ–¹æ¡ˆï¼›\né—®é¢˜äºŒï¼š`1 validation error ` è¿™ä¸ªé—®é¢˜åº”è¯¥æ˜¯è¾“å‡ºçš„å†…å®¹ä¸æ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼Œreadmeæœ‰æä¾›ä¸€ä»½å·²ç»æµ‹è¯•é€šè¿‡çš„å¤§æ¨¡å‹å‚å•†çš„æ¸…å•ï¼Œè¿™å—è¿˜åœ¨é€æ¸é€‚é…ä¸­ã€‚"
      },
      {
        "user": "Rosejacka",
        "body": "æˆ‘çš„å»ºè®®æ˜¯ä½ ä»¬æ£€æŸ¥omniparserçš„ocrè®¾ç½®æ˜¯å¦åŠ ä¸Šäº†ä¸­æ–‡ï¼Œä»–çš„å‚æ•°é»˜è®¤è®¾ç½®æ˜¯è‹±æ–‡ï¼Œå¯¼è‡´ä¸­æ–‡è¯†åˆ«ç‡å¾ˆå·®"
      },
      {
        "user": "yuruotong1",
        "body": "> æˆ‘çš„å»ºè®®æ˜¯ä½ ä»¬æ£€æŸ¥omniparserçš„ocrè®¾ç½®æ˜¯å¦åŠ ä¸Šäº†ä¸­æ–‡ï¼Œä»–çš„å‚æ•°é»˜è®¤è®¾ç½®æ˜¯è‹±æ–‡ï¼Œå¯¼è‡´ä¸­æ–‡è¯†åˆ«ç‡å¾ˆå·®\n\nautoMateå·²ç»åŠ ä¸Šäº†ä¸­æ–‡è¯†åˆ«"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 81,
    "title": "è¿™ä¸ªå¯ä»¥è°ƒç”¨è‡ªå·±çš„æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹å—ï¼Ÿ",
    "author": "djfch",
    "state": "closed",
    "created_at": "2025-03-12T09:16:26Z",
    "updated_at": "2025-03-14T09:59:27Z",
    "labels": [],
    "body": null,
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ˜¯æƒ³æ¥ollamaå—ï¼Ÿ"
      },
      {
        "user": "Zephyr69",
        "body": "åŒé—®ï¼Œå»ºè®®æ¥å…¥xinferenceçš„æ¨ç†api"
      },
      {
        "user": "yuruotong1",
        "body": "ç›®å‰æš‚æ—¶åªæµ‹è¯•äº† `https://api.openai-next.com` çš„æ¥å£ï¼Œå› ä¸ºä»£ç ä¸­ç”¨äº†ç»“æ„åŒ–è¾“å‡ºå’Œå¤šæ¨¡æ€èƒ½åŠ›ï¼Œæœ¬åœ°æ¨¡å‹å¯èƒ½ä¸å…¼å®¹çš„æƒ…å†µæ¯”è¾ƒå¤šï¼Œç°é˜¶æ®µä¸»è¦æ˜¯ä¿®å¤bugå’Œå®Œå–„ä½¿ç”¨åœºæ™¯ï¼Œä¸è¿‡å…¼å®¹æœ¬åœ°æ¨¡å‹æˆ‘ä»¬åé¢ä¼šé€æ­¥ä¼˜åŒ–çš„ã€‚"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 92,
    "title": "åº•åº§ç”¨çš„æ˜¯OmniParserï¼Ÿ",
    "author": "Rosejacka",
    "state": "closed",
    "created_at": "2025-03-14T07:36:11Z",
    "updated_at": "2025-03-14T09:41:46Z",
    "labels": [],
    "body": "åº•åº§ç”¨çš„æ˜¯OmniParserï¼Ÿ",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ˜¯çš„ï¼Œæ‰“æ ‡æ¨¡å‹ç”¨çš„æ˜¯OmniParserçš„æ¨¡å‹ã€‚"
      },
      {
        "user": "Rosejacka",
        "body": "æ”¯ä¸æ”¯æŒazureçš„gptå‘€ï¼Ÿ"
      },
      {
        "user": "Rosejacka",
        "body": "æˆ‘æœ‰ä¸ªé—®é¢˜å“ˆï¼ŒOmniParseræ¡†æ¶é»˜è®¤çš„éœ€è¦è¿™æ ·æ”¹reader = easyocr.Reader(ã€'en'ã€‘)æ”¹æˆreader = easyocr.Reader(ã€'ch_sim','en'ã€‘)ï¼Œæ‰ä¼šæ”¯æŒä¸­æ–‡çš„è¯†åˆ«ï¼Œåœ¨ä½ è¿™é‡Œèƒ½æ”¹ä¹ˆï¼Ÿ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 61,
    "title": "MacBookæµ‹è¯•äº†ä¸‹ï¼Œåˆ†è¾¨ç‡ä¸å¯¹ä»€ä¹ˆæƒ…å†µ",
    "author": "qauzy",
    "state": "closed",
    "created_at": "2025-03-07T02:55:00Z",
    "updated_at": "2025-03-13T23:28:16Z",
    "labels": [],
    "body": "MacBookæµ‹è¯•äº†ä¸‹ï¼Œåˆ†è¾¨ç‡ä¸å¯¹ä»€ä¹ˆæƒ…å†µ",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ„Ÿè°¢åé¦ˆï¼Œè¯·é—®æ˜¯å®šä½ä¸å‡†ç¡®å—"
      },
      {
        "user": "qauzy",
        "body": "> æ„Ÿè°¢åé¦ˆï¼Œè¯·é—®æ˜¯å®šä½ä¸å‡†ç¡®å—\næ˜¯çš„ï¼Œæ¯”å¦‚å±å¹•åˆ†è¾¨ç‡æ˜¯2kï¼Œç„¶åæˆªå›¾å¤§å°æ—¶4kï¼Œç„¶åä»–å®šä½çš„æ—¶å€™å°±è¶…å‡ºå±å¹•äº†"
      },
      {
        "user": "Gushroom",
        "body": "> > æ„Ÿè°¢åé¦ˆï¼Œè¯·é—®æ˜¯å®šä½ä¸å‡†ç¡®å—\n> > æ˜¯çš„ï¼Œæ¯”å¦‚å±å¹•åˆ†è¾¨ç‡æ˜¯2kï¼Œç„¶åæˆªå›¾å¤§å°æ—¶4kï¼Œç„¶åä»–å®šä½çš„æ—¶å€™å°±è¶…å‡ºå±å¹•äº†\n\næ²¡èƒ½å¤ç°è¿™ä¸ªé—®é¢˜ï¼Œèƒ½è¯¦ç»†è¯´ä¸‹é…ç½®å—ï¼Ÿå®šä½è¶…å‡ºå±å¹•æ˜¯æ€ä¹ˆå‘ç°çš„å‘¢ï¼Ÿ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 86,
    "title": "APIkeyä»å“ªé‡Œè·å–",
    "author": "skydragron",
    "state": "closed",
    "created_at": "2025-03-13T10:03:27Z",
    "updated_at": "2025-03-13T23:28:05Z",
    "labels": [],
    "body": "APIkeyä»å“ªé‡Œè·å–",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æˆ‘ä»¬å…¬å¸ƒäº†ä¸€ä¸ªå·²ç»æµ‹è¯•è¿‡çš„å¤§æ¨¡å‹åˆ—è¡¨ï¼Œå¯ä»¥å‚è€ƒè¿™ä¸ªåˆ—è¡¨ï¼š\nhttps://github.com/yuruotong1/autoMate/blob/master/SUPPORT_MODEL.md"
      },
      {
        "user": "zhangxiaokai007",
        "body": "ä¸èƒ½ç”¨qwen2.5vlä¹ˆï¼Ÿï¼Ÿï¼Ÿ"
      },
      {
        "user": "yuruotong1",
        "body": "qwen2.5vlä¸æ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼Œä¹‹å‰å‡ ä¸ªç‰ˆæœ¬ï¼Œå¤§æ¨¡å‹è¿”å›çš„å¾ˆå¤šæ¬¡æ“ä½œéƒ½å¡åœ¨äº†è¿”å›å†…å®¹éç»“æ„åŒ–ä¸Šï¼è¿™å—æˆ‘ä»¬ç”¨äº†å¾ˆå¤šçš„æ—¶é—´å»ä¿®ä¿®BUGï¼Œç°åœ¨å¤šæ¨¡æ€+ç»“æ„åŒ–åªæœ‰ openai çš„ gpt4oã€o3miniã€‚ä¸è¿‡æˆ‘ä»¬ä¼šæ—¶åˆ»å…³æ³¨å›½å†…çš„æ¨¡å‹å‚å•†ï¼Œå°½å¿«é€‚é…ã€‚"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 80,
    "title": "æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡º",
    "author": "damaomaom",
    "state": "closed",
    "created_at": "2025-03-12T08:24:24Z",
    "updated_at": "2025-03-13T23:27:52Z",
    "labels": [],
    "body": "(automate) D:\\autoMate\\autoMate-master>python main.py\ncuda is_available: False\nMPS is_available: False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] [2025-03-12 15:16:04,245] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n[SERVER-ERR] sock = connection.create_connection(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n[SERVER-ERR] raise err\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n[SERVER-ERR] sock.connect(sa)\n[SERVER-ERR] TimeoutError: timed out\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n[SERVER-ERR] response = self._make_request(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n[SERVER-ERR] raise new_e\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n[SERVER-ERR] self._validate_conn(conn)\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n[SERVER-ERR] conn.connect()\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n[SERVER-ERR] self.sock = sock = self._new_conn()\n[SERVER-ERR] ^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n[SERVER-ERR] raise ConnectTimeoutError(\n[SERVER-ERR] urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n[SERVER-ERR] resp = conn.urlopen(\n[SERVER-ERR] ^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n[SERVER-ERR] retries = retries.increment(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n[SERVER-ERR] raise MaxRetryError(_pool, url, reason) from reason # type: ignore[arg-type]\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n[SERVER-ERR]\n[SERVER-ERR] During handling of the above exception, another exception occurred:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n[SERVER-ERR] metadata = get_hf_file_metadata(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_validators.py\", line 114, in _inner_fn\n[SERVER-ERR] return fn(*args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n[SERVER-ERR] r = _request_wrapper(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n[SERVER-ERR] response = _request_wrapper(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n[SERVER-ERR] response = get_session().request(method=method, url=url, **params)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n[SERVER-ERR] resp = self.send(prep, **send_kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n[SERVER-ERR] r = adapter.send(request, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_http.py\", line 96, in send\n[SERVER-ERR] return super().send(request, *args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n[SERVER-ERR] raise ConnectTimeout(e, request=request)\n[SERVER-ERR] requests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 60ba7c86-ef24-4a9f-9382-58851c6f21b3)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 342, in cached_file\n[SERVER-ERR] resolved_file = hf_hub_download(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_validators.py\", line 114, in _inner_fn\n[SERVER-ERR] return fn(*args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 862, in hf_hub_download\n[SERVER-ERR] return _hf_hub_download_to_cache_dir(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 969, in _hf_hub_download_to_cache_dir\n[SERVER-ERR] _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n[SERVER-ERR] raise LocalEntryNotFoundError(\n[SERVER-ERR] huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\omniserver.py\", line 32, in\n[SERVER-ERR] omniparser = Omniparser(config)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\util\\omniparser.py\", line 12, in init\n[SERVER-ERR] self.caption_model_processor = get_caption_model_processor(model_name=config['caption_model_name'], model_name_or_path=config['caption_model_path'], device=device)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\util\\utils.py\", line 63, in get_caption_model_processor\n[SERVER-ERR] processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base\", trust_remote_code=True)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line 305, in from_pretrained\n[SERVER-ERR] config = AutoConfig.from_pretrained(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 1075, in from_pretrained\n[SERVER-ERR] config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 594, in get_config_dict\n[SERVER-ERR] config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 653, in _get_config_dict\n[SERVER-ERR] resolved_config_file = cached_file(\n[SERVER-ERR] ^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 385, in cached_file\n[SERVER-ERR] raise EnvironmentError(\n[SERVER-ERR] OSError: We couldn't connect to 'https://huggingface.co/' to load this file, couldn't find it in the cached files and it looks like microsoft/Florence-2-base is not the path to a directory containing a file named config.json.\n[SERVER-ERR] Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\nTraceback (most recent call last):\nFile \"D:\\autoMate\\autoMate-master\\main.py\", line 78, in\nrun()\nFile \"D:\\autoMate\\autoMate-master\\main.py\", line 55, in run\nraise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š1",
    "comments": [
      {
        "user": "ansemz",
        "body": "ä½ è¿™ä¸ªæ˜¯å› ä¸ºåœ¨å›½å†…ç¯å¢ƒï¼Œæ²¡æ³•ä¸‹è½½hfä¸Šçš„æ¨¡å‹ã€‚ç»™shellé…ç½®ä¸€ä¸ªç§‘å­¦ä¸Šç½‘çš„ä»£ç†åº”è¯¥å°±å¯ä»¥äº†ã€‚"
      },
      {
        "user": "damaomaom",
        "body": "æš‚æ—¶æ²¡æœ‰éƒ¨ç½²åˆ° æœåŠ¡å™¨ä¸Šé¢ï¼Œæ²¡æœ‰å›ºå®šIPåœ°å€ã€‚è¿™ä¸ªShellå¦‚ä½•é…ç½®ä»£ç†ï¼Ÿ"
      },
      {
        "user": "yuruotong1",
        "body": "æˆ‘è¿™é‡ŒåŠ ä¸€ä¸ªé’ˆå¯¹å›½å†…çš„é•œåƒåœ°å€å§ï¼Œè¿™æ ·ä½ å°±ä¸ç”¨åŠ¨äº†"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 79,
    "title": "écondaç¯å¢ƒè¿è¡ŒæŠ¥No module named 'fastapi'çš„è§£å†³åŠæ³•",
    "author": "ansemz",
    "state": "closed",
    "created_at": "2025-03-12T06:23:35Z",
    "updated_at": "2025-03-13T23:27:41Z",
    "labels": [],
    "body": "æˆ‘æœ¬äººæ²¡æœ‰ç”¨condaï¼Œä½¿ç”¨uvå’Œvenvéƒ½æ— æ³•æ‰§è¡ŒæˆåŠŸã€‚æŠ¥é”™å¦‚ä¸‹ï¼š\n```\ncuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\uv\\autoMate1\\omniserver.py\", line 8, in <module>\n[SERVER-ERR]     from fastapi import FastAPI\n[SERVER-ERR] ModuleNotFoundError: No module named 'fastapi'\nTraceback (most recent call last):\n  File \"D:\\uv\\autoMate1\\main.py\", line 78, in <module>\n    run()\n  File \"D:\\uv\\autoMate1\\main.py\", line 55, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š1\n```\nåº”è¯¥æ˜¯ç”±äºsubprocesså¯åŠ¨çš„pythonå…¶å®ä¸æ˜¯venvä¸­çš„pythonï¼Œæ‰€ä»¥æ‰¾ä¸åˆ°fastapiã€‚æŠŠmain.pyä¿®æ”¹ä¸€ä¸‹å°±å¯ä»¥äº†ã€‚\n```\n1   + import sys\n22 -         [\"python\", \"./omniserver.py\"],\n22 +        [sys.executable, \"./omniserver.py\"],\n```\n\nä¾›å’Œæˆ‘ä¸€æ ·çš„æ–°æ‰‹å‚è€ƒ\n\n\nupdate 1ï¼š\nåˆå‘ç°ä¸€ä¸ªæ–‡ä»¶gradio_ui/tools/computer.pyç›´æ¥è°ƒç”¨çš„pythonã€‚åŒæ ·ä¿®æ”¹ä¸€ä¸‹\n```\n1   + import sys\n224 -                 [\"python\", \"-c\", \"import pyautogui; print(pyautogui.size())\"]\n224 +                 [sys.executable, \"-c\", \"import pyautogui; print(pyautogui.size())\"]\n```\nè¿™æ ·å°±å¯ä»¥äº†ã€‚\n\nbtwï¼šcpuè·‘ç¡®å®çœŸçš„æ…¢\n",
    "comments": [
      {
        "user": "damaomaom",
        "body": "è€å¸ˆï¼Œæˆ‘æ˜¯condaç¯å¢ƒ  ä¹ŸæŠ¥ä¸Šé¢çš„é”™è¯¯ã€‚æŒ‰ç…§æ‚¨çš„ä¿®æ”¹äº† main.pyæ–‡ä»¶ ä½†æ˜¯è¿˜æ˜¯ä¸è¡Œã€‚\n\n(automate) D:\\autoMate\\autoMate-master>python main.py\ncuda is_available: False\nMPS is_available: False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] [2025-03-12 15:16:04,245] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n[SERVER-ERR] sock = connection.create_connection(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n[SERVER-ERR] raise err\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n[SERVER-ERR] sock.connect(sa)\n[SERVER-ERR] TimeoutError: timed out\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n[SERVER-ERR] response = self._make_request(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n[SERVER-ERR] raise new_e\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n[SERVER-ERR] self._validate_conn(conn)\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n[SERVER-ERR] conn.connect()\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n[SERVER-ERR] self.sock = sock = self._new_conn()\n[SERVER-ERR] ^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n[SERVER-ERR] raise ConnectTimeoutError(\n[SERVER-ERR] urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n[SERVER-ERR] resp = conn.urlopen(\n[SERVER-ERR] ^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n[SERVER-ERR] retries = retries.increment(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n[SERVER-ERR] raise MaxRetryError(_pool, url, reason) from reason # type: ignore[arg-type]\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n[SERVER-ERR]\n[SERVER-ERR] During handling of the above exception, another exception occurred:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n[SERVER-ERR] metadata = get_hf_file_metadata(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_validators.py\", line 114, in _inner_fn\n[SERVER-ERR] return fn(*args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n[SERVER-ERR] r = _request_wrapper(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n[SERVER-ERR] response = _request_wrapper(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n[SERVER-ERR] response = get_session().request(method=method, url=url, **params)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n[SERVER-ERR] resp = self.send(prep, **send_kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n[SERVER-ERR] r = adapter.send(request, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_http.py\", line 96, in send\n[SERVER-ERR] return super().send(request, *args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n[SERVER-ERR] raise ConnectTimeout(e, request=request)\n[SERVER-ERR] requests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 60ba7c86-ef24-4a9f-9382-58851c6f21b3)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 342, in cached_file\n[SERVER-ERR] resolved_file = hf_hub_download(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils_validators.py\", line 114, in _inner_fn\n[SERVER-ERR] return fn(*args, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 862, in hf_hub_download\n[SERVER-ERR] return _hf_hub_download_to_cache_dir(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 969, in _hf_hub_download_to_cache_dir\n[SERVER-ERR] _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n[SERVER-ERR] raise LocalEntryNotFoundError(\n[SERVER-ERR] huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\omniserver.py\", line 32, in\n[SERVER-ERR] omniparser = Omniparser(config)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\util\\omniparser.py\", line 12, in init\n[SERVER-ERR] self.caption_model_processor = get_caption_model_processor(model_name=config['caption_model_name'], model_name_or_path=config['caption_model_path'], device=device)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\autoMate\\autoMate-master\\util\\utils.py\", line 63, in get_caption_model_processor\n[SERVER-ERR] processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base\", trust_remote_code=True)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line 305, in from_pretrained\n[SERVER-ERR] config = AutoConfig.from_pretrained(\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 1075, in from_pretrained\n[SERVER-ERR] config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 594, in get_config_dict\n[SERVER-ERR] config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 653, in _get_config_dict\n[SERVER-ERR] resolved_config_file = cached_file(\n[SERVER-ERR] ^^^^^^^^^^^^\n[SERVER-ERR] File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 385, in cached_file\n[SERVER-ERR] raise EnvironmentError(\n[SERVER-ERR] OSError: We couldn't connect to 'https://huggingface.co/' to load this file, couldn't find it in the cached files and it looks like microsoft/Florence-2-base is not the path to a directory containing a file named config.json.\n[SERVER-ERR] Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\nTraceback (most recent call last):\nFile \"D:\\autoMate\\autoMate-master\\main.py\", line 78, in\nrun()\nFile \"D:\\autoMate\\autoMate-master\\main.py\", line 55, in run\nraise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š1"
      },
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªåº”è¯¥æ˜¯ç½‘ç»œé—®é¢˜ï¼Œæ¨¡å‹æ²¡ä¸‹è½½ä¸‹æ¥ï¼Œç¨ç­‰æˆ‘ä¸‹ä¸ªç‰ˆæœ¬æ›´æ–°ä¸€ä¸ªå›½å†…é•œåƒï¼"
      },
      {
        "user": "yuruotong1",
        "body": "ä»£ç å·²ç»æ›´æ–°å®Œäº†ï¼Œå¯ä»¥å†è¯•ä¸€ä¸‹ @ansemz  @damaomaom "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 77,
    "title": "ä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚è¿™æ˜¯ç¼ºå°‘å“ªä¸ªæ–‡ä»¶å‘¢",
    "author": "54clz",
    "state": "closed",
    "created_at": "2025-03-12T02:26:40Z",
    "updated_at": "2025-03-13T23:27:29Z",
    "labels": [],
    "body": "(automate) D:\\autoMate>python main.py\ncuda is_available:  True\nMPS is_available:  False\ncuda device_count 1\ncuda device_name NVIDIA GeForce RTX 4070 Ti SUPER\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nOmniparseræœåŠ¡å¯åŠ¨æˆåŠŸ...\nC:\\ProgramData\\miniconda3\\envs\\automate\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n  warnings.warn(\nä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚\n* Running on local URL:  http://0.0.0.0:7888\nTraceback (most recent call last):\n  File \"D:\\autoMate\\main.py\", line 78, in <module>\n    run()\n  File \"D:\\autoMate\\main.py\", line 59, in run\n    app.run()\n  File \"D:\\autoMate\\gradio_ui\\app.py\", line 318, in run\n    demo.launch(server_name=\"0.0.0.0\", server_port=7888)\n  File \"C:\\ProgramData\\miniconda3\\envs\\automate\\Lib\\site-packages\\gradio\\blocks.py\", line 2620, in launch\n    raise ValueError(\nValueError: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "å¯ä»¥å°è¯•åœ¨å¯åŠ¨çš„ä»£ç åŠ ä¸Šè¿™ä¸ªï¼š\n`demo.launch(server_name=\"0.0.0.0\", server_port=7888, share=True)`"
      },
      {
        "user": "yuruotong1",
        "body": "ä»£ç å·²ç»æ›´æ–°äº†ï¼Œå¯ä»¥å†è¯•ä¸€ä¸‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 72,
    "title": "Error in `Computer.py`",
    "author": "LeeOrange-is-me",
    "state": "closed",
    "created_at": "2025-03-11T08:09:08Z",
    "updated_at": "2025-03-13T23:27:18Z",
    "labels": [],
    "body": "``` APL\n  File \"[][][]\\autoMate\\gradio_ui\\tools\\computer.py\", line 202, in screenshot\n    screenshot = self.padding_image(screenshot)\n                                    ^^^^^^^^^^\nUnboundLocalError: cannot access local variable 'screenshot' where it is not associated with a value\n\n```\n\nWe can find that in `\\autoMate\\gradio_ui\\tools\\computer.py`. In line 3, we see the `screenshot` firstly, but WHERE is it first defined?\n\n``` Python\nasync def screenshot(self):\n        if not hasattr(self, 'target_dimension'):\n            screenshot = self.padding_image(screenshot)\n            self.target_dimension = MAX_SCALING_TARGETS[\"WXGA\"]\n        width, height = self.target_dimension[\"width\"], self.target_dimension[\"height\"]\n        screenshot, path = get_screenshot(resize=True, target_width=width, target_height=height)\n        time.sleep(0.7) # avoid async error as actions take time to complete\n        return ToolResult(base64_image=base64.b64encode(path.read_bytes()).decode())\n```\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "I think this is a bug, and I'm refactoring this part of the code, thanks for the issue."
      },
      {
        "user": "yuruotong1",
        "body": "The code has been updated, you can try it again. @LeeOrange-is-me "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 70,
    "title": "æ‰§è¡ŒæŠ¥é”™ ä¸€ç›´è¶…æ—¶",
    "author": "damaomaom",
    "state": "closed",
    "created_at": "2025-03-11T06:28:41Z",
    "updated_at": "2025-03-13T11:43:11Z",
    "labels": [],
    "body": "cuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\næœªæ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œéœ€è¦ä¸‹è½½ 6 ä¸ªæ–‡ä»¶\næ­£åœ¨ä¸‹è½½: icon_detect/train_args.yaml (å°è¯• 1/3)\n[SERVER-ERR] [2025-03-11 14:13:13,527] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n[SERVER-ERR] [2025-03-11 14:13:13,529] [ WARNING] easyocr.py:251 - Downloading detection model, please wait. This may take several minutes depending upon your network connection.\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000022555C13590>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022555C13590>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n    response = _request_wrapper(\n               ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022555C13590>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 9123285a-634f-4da2-b8df-dca0c2d2c582)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Scripts\\huggingface-cli.exe\\__main__.py\", line 7, in <module>\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\huggingface_cli.py\", line 57, in main\n    service.run()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 153, in run\n    print(self._download())  # Print path to downloaded files\n          ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 166, in _download\n    return hf_hub_download(\n           ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 842, in hf_hub_download\n    return _hf_hub_download_to_local_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1091, in _hf_hub_download_to_local_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\nä¸‹è½½å¤±è´¥: icon_detect/train_args.yamlï¼Œæ­£åœ¨é‡è¯•...\næ­£åœ¨ä¸‹è½½: icon_detect/train_args.yaml (å°è¯• 2/3)\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000001F637553770>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001F637553770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n    response = _request_wrapper(\n               ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001F637553770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: e4d13bb2-e913-42ba-9de3-809927ee782b)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Scripts\\huggingface-cli.exe\\__main__.py\", line 7, in <module>\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\huggingface_cli.py\", line 57, in main\n    service.run()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 153, in run\n    print(self._download())  # Print path to downloaded files\n          ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 166, in _download\n    return hf_hub_download(\n           ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 842, in hf_hub_download\n    return _hf_hub_download_to_local_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1091, in _hf_hub_download_to_local_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\nä¸‹è½½å¤±è´¥: icon_detect/train_args.yamlï¼Œæ­£åœ¨é‡è¯•...\næ­£åœ¨ä¸‹è½½: icon_detect/train_args.yaml (å°è¯• 3/3)\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 1344, in do_open\n[SERVER-ERR]     h.request(req.get_method(), req.selector, req.data, headers,\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1319, in request\n[SERVER-ERR]     self._send_request(method, url, body, headers, encode_chunked)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1365, in _send_request\n[SERVER-ERR]     self.endheaders(body, encode_chunked=encode_chunked)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1314, in endheaders\n[SERVER-ERR]     self._send_output(message_body, encode_chunked=encode_chunked)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1074, in _send_output\n[SERVER-ERR]     self.send(msg)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1018, in send\n[SERVER-ERR]     self.connect()\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 1453, in connect\n[SERVER-ERR]     super().connect()\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\http\\client.py\", line 984, in connect\n[SERVER-ERR]     self.sock = self._create_connection(\n[SERVER-ERR]                 ^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\socket.py\", line 852, in create_connection\n[SERVER-ERR]     raise exceptions[0]\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\socket.py\", line 837, in create_connection\n[SERVER-ERR]     sock.connect(sa)\n[SERVER-ERR] TimeoutError: [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚\n[SERVER-ERR]\n[SERVER-ERR] During handling of the above exception, another exception occurred:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\omniserver.py\", line 14, in <module>\n[SERVER-ERR]     from util.omniparser import Omniparser\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\util\\omniparser.py\", line 1, in <module>\n[SERVER-ERR]     from util.utils import get_som_labeled_img, get_caption_model_processor, get_yolo_model, check_ocr_box\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\util\\utils.py\", line 22, in <module>\n[SERVER-ERR]     reader = easyocr.Reader(['en', 'ch_sim'])\n[SERVER-ERR]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\easyocr\\easyocr.py\", line 92, in __init__\n[SERVER-ERR]     detector_path = self.getDetectorPath(detect_network)\n[SERVER-ERR]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\easyocr\\easyocr.py\", line 253, in getDetectorPath\n[SERVER-ERR]     download_and_unzip(self.detection_models[self.detect_network]['url'], self.detection_models[self.detect_network]['filename'], self.model_storage_directory, self.verbose)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\easyocr\\utils.py\", line 628, in download_and_unzip\n[SERVER-ERR]     urlretrieve(url, zip_path, reporthook=reporthook)\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 240, in urlretrieve\n[SERVER-ERR]     with contextlib.closing(urlopen(url, data)) as fp:\n[SERVER-ERR]                             ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 215, in urlopen\n[SERVER-ERR]     return opener.open(url, data, timeout)\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 515, in open\n[SERVER-ERR]     response = self._open(req, data)\n[SERVER-ERR]                ^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 532, in _open\n[SERVER-ERR]     result = self._call_chain(self.handle_open, protocol, protocol +\n[SERVER-ERR]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 492, in _call_chain\n[SERVER-ERR]     result = func(*args)\n[SERVER-ERR]              ^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 1392, in https_open\n[SERVER-ERR]     return self.do_open(http.client.HTTPSConnection, req,\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\urllib\\request.py\", line 1347, in do_open\n[SERVER-ERR]     raise URLError(err)\n[SERVER-ERR] urllib.error.URLError: <urlopen error [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚>\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n    raise err\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002A4901A2CC0>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002A4901A2CC0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n    response = _request_wrapper(\n               ^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/OmniParser-v2.0/resolve/main/icon_detect/train_args.yaml (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002A4901A2CC0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 8d67034e-37bd-43f0-9918-44c16caff6c7)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Scripts\\huggingface-cli.exe\\__main__.py\", line 7, in <module>\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\huggingface_cli.py\", line 57, in main\n    service.run()\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 153, in run\n    print(self._download())  # Print path to downloaded files\n          ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\commands\\download.py\", line 166, in _download\n    return hf_hub_download(\n           ^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 842, in hf_hub_download\n    return _hf_hub_download_to_local_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1091, in _hf_hub_download_to_local_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\nä¸‹è½½å¤±è´¥: icon_detect/train_args.yamlï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°\nTraceback (most recent call last):\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 78, in <module>\n    run()\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 44, in run\n    download_weights.download()\n  File \"D:\\autoMate\\autoMate-master\\util\\download_weights.py\", line 45, in download\n    subprocess.run(cmd, check=True)\n  File \"D:\\Users\\admin\\anaconda3\\envs\\automate\\Lib\\subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['huggingface-cli', 'download', 'microsoft/OmniParser-v2.0', 'icon_detect/train_args.yaml', '--local-dir', 'weights']' returned non-zero exit status 1.",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™æ˜¯æ¨¡å‹æ–‡ä»¶ä¸‹è½½å¤±è´¥äº†ï¼Œæˆ‘æŠŠæ¨¡å‹æ–‡ä»¶æ”¾ç™¾åº¦ç½‘ç›˜äº†ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½ï¼š\n\né“¾æ¥: https://pan.baidu.com/s/1Tj8sZZK9_QI7whZV93vb0w?pwd=dyeu æå–ç : dyeu"
      },
      {
        "user": "damaomaom",
        "body": "(automate) D:\\autoMate\\autoMate-master>python main.py\ncuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] [2025-03-12 15:16:04,245] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n[SERVER-ERR]     sock = connection.create_connection(\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n[SERVER-ERR]     raise err\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n[SERVER-ERR]     sock.connect(sa)\n[SERVER-ERR] TimeoutError: timed out\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n[SERVER-ERR]     response = self._make_request(\n[SERVER-ERR]                ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n[SERVER-ERR]     raise new_e\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n[SERVER-ERR]     self._validate_conn(conn)\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n[SERVER-ERR]     conn.connect()\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 704, in connect\n[SERVER-ERR]     self.sock = sock = self._new_conn()\n[SERVER-ERR]                        ^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connection.py\", line 207, in _new_conn\n[SERVER-ERR]     raise ConnectTimeoutError(\n[SERVER-ERR] urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n[SERVER-ERR]     resp = conn.urlopen(\n[SERVER-ERR]            ^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n[SERVER-ERR]     retries = retries.increment(\n[SERVER-ERR]               ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n[SERVER-ERR]     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[SERVER-ERR]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR] urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\n[SERVER-ERR]\n[SERVER-ERR] During handling of the above exception, another exception occurred:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1376, in _get_metadata_or_catch_error\n[SERVER-ERR]     metadata = get_hf_file_metadata(\n[SERVER-ERR]                ^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n[SERVER-ERR]     return fn(*args, **kwargs)\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1296, in get_hf_file_metadata\n[SERVER-ERR]     r = _request_wrapper(\n[SERVER-ERR]         ^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 280, in _request_wrapper\n[SERVER-ERR]     response = _request_wrapper(\n[SERVER-ERR]                ^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 303, in _request_wrapper\n[SERVER-ERR]     response = get_session().request(method=method, url=url, **params)\n[SERVER-ERR]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n[SERVER-ERR]     resp = self.send(prep, **send_kwargs)\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n[SERVER-ERR]     r = adapter.send(request, **kwargs)\n[SERVER-ERR]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n[SERVER-ERR]     return super().send(request, *args, **kwargs)\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 688, in send\n[SERVER-ERR]     raise ConnectTimeout(e, request=request)\n[SERVER-ERR] requests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/Florence-2-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D549783770>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 60ba7c86-ef24-4a9f-9382-58851c6f21b3)')\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 342, in cached_file\n[SERVER-ERR]     resolved_file = hf_hub_download(\n[SERVER-ERR]                     ^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n[SERVER-ERR]     return fn(*args, **kwargs)\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 862, in hf_hub_download\n[SERVER-ERR]     return _hf_hub_download_to_cache_dir(\n[SERVER-ERR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 969, in _hf_hub_download_to_cache_dir\n[SERVER-ERR]     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1489, in _raise_on_head_call_error\n[SERVER-ERR]     raise LocalEntryNotFoundError(\n[SERVER-ERR] huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n[SERVER-ERR]\n[SERVER-ERR] The above exception was the direct cause of the following exception:\n[SERVER-ERR]\n[SERVER-ERR] Traceback (most recent call last):\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\omniserver.py\", line 32, in <module>\n[SERVER-ERR]     omniparser = Omniparser(config)\n[SERVER-ERR]                  ^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\util\\omniparser.py\", line 12, in __init__\n[SERVER-ERR]     self.caption_model_processor = get_caption_model_processor(model_name=config['caption_model_name'], model_name_or_path=config['caption_model_path'], device=device)\n[SERVER-ERR]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\autoMate\\autoMate-master\\util\\utils.py\", line 63, in get_caption_model_processor\n[SERVER-ERR]     processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base\", trust_remote_code=True)\n[SERVER-ERR]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line 305, in from_pretrained\n[SERVER-ERR]     config = AutoConfig.from_pretrained(\n[SERVER-ERR]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 1075, in from_pretrained\n[SERVER-ERR]     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR]                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 594, in get_config_dict\n[SERVER-ERR]     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n[SERVER-ERR]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\configuration_utils.py\", line 653, in _get_config_dict\n[SERVER-ERR]     resolved_config_file = cached_file(\n[SERVER-ERR]                            ^^^^^^^^^^^^\n[SERVER-ERR]   File \"D:\\anaconda3\\envs\\automate\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 385, in cached_file\n[SERVER-ERR]     raise EnvironmentError(\n[SERVER-ERR] OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like microsoft/Florence-2-base is not the path to a directory containing a file named config.json.\n[SERVER-ERR] Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\nTraceback (most recent call last):\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 78, in <module>\n    run()\n  File \"D:\\autoMate\\autoMate-master\\main.py\", line 55, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š1"
      },
      {
        "user": "yuruotong1",
        "body": "åˆšæ‰é‡æ„äº†ä»£ç ï¼Œå·²ç»å–æ¶ˆäº†æœåŠ¡ï¼Œå¯ä»¥å†è¯•ä¸€ä¸‹ @damaomaom "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 78,
    "title": "è¯·é—®ä¸ºä½•ä¼šæŠ¥10054çš„ï¼Ÿæˆ‘é…ç½®çš„æ˜¯deepseekæ¨¡å‹",
    "author": "jim-cuizhikun",
    "state": "closed",
    "created_at": "2025-03-12T03:38:18Z",
    "updated_at": "2025-03-13T11:06:15Z",
    "labels": [],
    "body": "E:\\PycharmProjects\\autoMate-master\\.venv\\Scripts\\python.exe E:\\PycharmProjects\\autoMate-master\\main.py \ncuda is_available:  False\nMPS is_available:  False\ncuda device_count 0\næ˜¾å¡é©±åŠ¨ä¸é€‚é…ï¼Œè¯·æ ¹æ®readmeå®‰è£…åˆé€‚ç‰ˆæœ¬çš„ torchï¼\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] [2025-03-12 11:30:41,236] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From é¦ƒæ† v4.50é¦ƒæ†Ÿ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n[SERVER-ERR]   - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n[SERVER-ERR]   - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n[SERVER-ERR]   - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n[SERVER-OUT] Server initialized!\n[SERVER-ERR] INFO:     Will watch for changes in these directories: ['E:\\\\PycharmProjects\\\\autoMate-master']\n[SERVER-ERR] INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n[SERVER-ERR] INFO:     Started reloader process [16728] using StatReload\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] [2025-03-12 11:32:05,977] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-ERR] Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From é¦ƒæ† v4.50é¦ƒæ†Ÿ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n[SERVER-ERR]   - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n[SERVER-ERR]   - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n[SERVER-ERR]   - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n[SERVER-OUT] Server initialized!\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n[SERVER-OUT] Server initialized!\n[SERVER-ERR] INFO:     Started server process [16964]\n[SERVER-ERR] INFO:     Waiting for application startup.\n[SERVER-ERR] INFO:     Application startup complete.\n[SERVER-OUT] INFO:     127.0.0.1:54932 - \"GET /probe/ HTTP/1.1\" 200 OK\nOmniparseræœåŠ¡å¯åŠ¨æˆåŠŸ...\nE:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n  warnings.warn(\n* Running on local URL:  http://0.0.0.0:7888\n\nTo create a public link, set `share=True` in `launch()`.\nin sampling_loop_sync, model: deepseek-chat\nscreen size: 2880, 1800\nStart the message loop. User messages: [{'role': <Sender.USER: 'user'>, 'content': [TextBlock(citations=None, text='æ‰“å¼€edgeæµè§ˆå™¨', type='text')]}]\n[SERVER-OUT] start parsing...\n[SERVER-OUT] image size: (2880, 1800)\n[SERVER-OUT] \n[SERVER-OUT] 0: 800x1280 72 icons, 1250.1ms\n[SERVER-OUT] Speed: 69.8ms preprocess, 1250.1ms inference, 28.2ms postprocess per image at shape (1, 3, 800, 1280)\n[SERVER-OUT] len(filtered_boxes): 91 38\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connection.py\", line 516, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 1430, in getresponse\n    response.begin()\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 331, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 292, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\socket.py\", line 720, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nConnectionResetError: [WinError 10054] è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 474, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\util\\util.py\", line 38, in reraise\n    raise value.with_traceback(tb)\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connection.py\", line 516, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 1430, in getresponse\n    response.begin()\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 331, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 292, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\socket.py\", line 720, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚', None, 10054, None))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2044, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1603, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 728, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 722, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 705, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 866, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\app.py\", line 176, in process_input\n    for loop_msg in sampling_loop_sync(\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\loop.py\", line 59, in sampling_loop_sync\n    parsed_screen = omniparser_client()\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\agent\\llm_utils\\omniparserclient.py\", line 18, in __call__\n    response = requests.post(self.url, json={\"base64_image\": image_base64})\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\api.py\", line 115, in post\n    return request(\"post\", url, data=data, json=json, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\adapters.py\", line 682, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚', None, 10054, None))\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ç›®å‰ deepseek åœ¨å¤šè½®å¯¹è¯ä¸­è¿˜æœ‰äº›é—®é¢˜ï¼Œæˆ‘ä»¬æœ€è¿‘ä¼šæ¨ä¸€ä¸ªæ–°ç‰ˆæœ¬ï¼Œæ–°ç‰ˆæœ¬ä¼šå…ˆæ”¯æŒ openaiï¼Œè€ƒè™‘åˆ°å›½å†…å¤§å®¶è®¿é—®ä¸äº† openaiï¼Œ æˆ‘ä»¬ä¹Ÿä¼šæ¨èä¸€ä¸ªä¸ç”¨ç¿»å¢™ä¹Ÿèƒ½ç”¨çš„ä»£ç†ç«™"
      },
      {
        "user": "jim-cuizhikun",
        "body": "é¦–å…ˆï¼Œéå¸¸æ„Ÿè°¢æ‚¨çš„å›å¤ï¼ŒæœŸå¾…æ–°ç‰ˆæœ¬çš„å‘å¸ƒï¼\nå…¶æ¬¡ï¼Œæˆ‘é€šè¿‡VPNå¯ä»¥è®¿é—®openaiï¼Œé€šè¿‡OmniToolé…ç½®äº†gpt-4oï¼Œä¾ç„¶æŠ¥é”™10054ã€‚è€Œä¸”æˆ‘ä¹Ÿæ²¡æœ‰å¤šæ¬¡å¯¹è¯ï¼Œåªæ˜¯å‘å‡ºä¸€ä¸ªæŒ‡ä»¤ï¼Œä¾‹å¦‚â€œä½ èƒ½ä»‹ç»ä¸€ä¸‹å—ï¼Ÿâ€ï¼Œå°±10054äº†ã€‚\n\nin sampling_loop_sync, model: gpt-4o\nscreen size: 2880, 1800\nStart the message loop. User messages: [{'role': <Sender.USER: 'user'>, 'content': [TextBlock(citations=None, text='ä»‹ç»ä¸€ä¸‹ï¼Ÿ', type='text')]}]\n[SERVER-OUT] start parsing...\n[SERVER-OUT] image size: (2880, 1800)\n[SERVER-OUT] \n[SERVER-OUT] 0: 800x1280 71 icons, 1902.2ms\n[SERVER-OUT] Speed: 77.4ms preprocess, 1902.2ms inference, 36.1ms postprocess per image at shape (1, 3, 800, 1280)\n[SERVER-OUT] len(filtered_boxes): 89 41\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connection.py\", line 516, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 1430, in getresponse\n    response.begin()\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 331, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 292, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\socket.py\", line 720, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nConnectionResetError: [WinError 10054] è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 474, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\util\\util.py\", line 38, in reraise\n    raise value.with_traceback(tb)\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\urllib3\\connection.py\", line 516, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 1430, in getresponse\n    response.begin()\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 331, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\http\\client.py\", line 292, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\envs\\py312\\Lib\\socket.py\", line 720, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚', None, 10054, None))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2044, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1603, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 728, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 722, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 705, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 866, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\app.py\", line 176, in process_input\n    for loop_msg in sampling_loop_sync(\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\loop.py\", line 59, in sampling_loop_sync\n    parsed_screen = omniparser_client()\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\gradio_ui\\agent\\llm_utils\\omniparserclient.py\", line 18, in __call__\n    response = requests.post(self.url, json={\"base64_image\": image_base64})\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\api.py\", line 115, in post\n    return request(\"post\", url, data=data, json=json, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\PycharmProjects\\autoMate-master\\.venv\\Lib\\site-packages\\requests\\adapters.py\", line 682, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'è¿œç¨‹ä¸»æœºå¼ºè¿«å…³é—­äº†ä¸€ä¸ªç°æœ‰çš„è¿æ¥ã€‚', None, 10054, None))\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 68,
    "title": "autoMate>pip install -r requirements.txt rise error",
    "author": "paulownia99",
    "state": "closed",
    "created_at": "2025-03-10T06:54:05Z",
    "updated_at": "2025-03-13T09:32:40Z",
    "labels": [],
    "body": "  Getting requirements to build wheel ... done\n  Installing backend dependencies ... done\n  Preparing metadata (pyproject.toml) ... error\n  error: subprocess-exited-with-error\n\n  Ã— Preparing metadata (pyproject.toml) did not run successfully.\n  â”‚ exit code: 1\n  â•°â”€> [21 lines of output]\n      + C:\\Users\\FCMA\\.conda\\envs\\automate\\python.exe C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\\vendored-meson\\meson\\meson.py setup C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346 C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\\.mesonpy-p_meg130 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\\.mesonpy-p_meg130\\meson-python-native-file.ini\n      The Meson build system\n      Version: 1.2.99\n      Source dir: C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\n      Build dir: C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\\.mesonpy-p_meg130\n      Build type: native build\n      Project name: NumPy\n      Project version: 1.26.4\n      WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n\n      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n      The following exception(s) were encountered:\n      Running `icl \"\"` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `cl /?` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `cc --version` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `gcc --version` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `clang --version` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `clang-cl /?` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n      Running `pgcc --version` gave \"[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚\"\n\n      A full log can be found at C:\\Users\\FCMA\\AppData\\Local\\Temp\\pip-install-z02mouyb\\numpy_a5ffa25f14bc4620850f07394f64c346\\.mesonpy-p_meg130\\meson-logs\\meson-log.txt\n\nwhy vs?",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "You're encountering a compilation error when trying to install NumPy. The core problem is that the installation process cannot find any compatible C compiler (icl, cl, cc, gcc, clang, etc.) required to build NumPy's components.\n\nSince you appear to be using Anaconda, the simplest solution is to install NumPy using conda:\n\n```bash\nconda install numpy\n```"
      },
      {
        "user": "Zhanghao-19970918",
        "body": "ç›´æ¥ç”¨condaå®‰è£…å§"
      },
      {
        "user": "yuruotong1",
        "body": "The code has been updated, you can try it again."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 69,
    "title": "Illegal instruction",
    "author": "chan-yuu",
    "state": "closed",
    "created_at": "2025-03-10T18:47:39Z",
    "updated_at": "2025-03-13T09:31:00Z",
    "labels": [],
    "body": "```\nStart the message loop. User messages: [{'role': <Sender.USER: 'user'>, 'content': [TextBlock(citations=None, text='å¸®æˆ‘åœ¨ä¸»ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªpythonæ–‡ä»¶', type='text')]}]\n[SERVER-OUT] start parsing...\n[SERVER-OUT] image size: (5120, 1600)\n[SERVER-OUT] \n[SERVER-OUT] 0: 416x1280 300 icons, 25.9ms\n[SERVER-OUT] Speed: 2.2ms preprocess, 25.9ms inference, 153.2ms postprocess per image at shape (1, 3, 416, 1280)\n[SERVER-OUT] len(filtered_boxes): 739 553\n[SERVER-OUT] time to get parsed content: 0.5575861930847168\n[SERVER-OUT] time: 7.074315309524536\n[SERVER-OUT] INFO:     127.0.0.1:47630 - \"POST /parse/ HTTP/1.1\" 200 OK\nomniparser latency: 7.074315309524536\n_render_message: -- Step 1: --\nError, llm response: b''\nTraceback (most recent call last):\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/requests/models.py\", line 974, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/blocks.py\", line 2044, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/blocks.py\", line 1603, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/utils.py\", line 728, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/utils.py\", line 722, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/anyio/to_thread.py\", line 33, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/utils.py\", line 705, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/utils.py\", line 866, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"/home/cyun/agent_version_check/Agent/autoMate/gradio_ui/app.py\", line 176, in process_input\n    for loop_msg in sampling_loop_sync(\n  File \"/home/cyun/agent_version_check/Agent/autoMate/gradio_ui/loop.py\", line 60, in sampling_loop_sync\n    tools_use_needed, vlm_response_json = actor(messages=messages, parsed_screen=parsed_screen)\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/agent_version_check/Agent/autoMate/gradio_ui/agent/vlm_agent.py\", line 76, in __call__\n    vlm_response, token_usage = run_oai_interleaved(\n                                ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cyun/agent_version_check/Agent/autoMate/gradio_ui/agent/llm_utils/oaiclient.py\", line 65, in run_oai_interleaved\n    return response.json()\n           ^^^^^^^^^^^^^^^\n  File \"/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/requests/models.py\", line 978, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n/home/cyun/anaconda3/envs/automate/lib/python3.12/site-packages/gradio/blocks.py:1777: UserWarning: A function (stop_app) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n    Output components:\n        []\n    Output values returned:\n        [\"App stopped\"]\n  warnings.warn(\n```\nè¯·é—®è¿™æ˜¯ä»€ä¹ˆé—®é¢˜",
    "comments": [
      {
        "user": "chan-yuu",
        "body": "![Image](https://github.com/user-attachments/assets/f496e50a-56ca-44aa-8203-552ada6e2ec9)"
      },
      {
        "user": "yuruotong1",
        "body": "çœ‹æŠ¥é”™ï¼Œå¤§æ¨¡å‹æ²¡æœ‰è¿”å›å†…å®¹ã€‚æ„Ÿè§‰æ˜¯å¤§æ¨¡å‹é‚£è¾¹çš„é—®é¢˜"
      },
      {
        "user": "yuruotong1",
        "body": "ä»Šå¤©é‡æ„äº†ä»£ç ï¼Œå¯ä»¥å†è¯•ä¸€ä¸‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 74,
    "title": "Model Support Open router",
    "author": "bhupesh-sf",
    "state": "closed",
    "created_at": "2025-03-11T12:39:54Z",
    "updated_at": "2025-03-13T09:30:08Z",
    "labels": [],
    "body": "Hey, I just went through the model support file and it lists only deepseek & alibaba, I already have open router can't we use that and also what about local models??",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Thanks for introducing a great tool like open router, the readme model list needs to be updated. Because our current code (refactored version) uses structured output and multimodal support features, according to our tests, Currently better support is the openai model. So the refactored version (expected in the next week) will give priority to openai's 4o model, We want to wait for other models to update this capability before we become compatible."
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 75,
    "title": "what is the hardware requirements ?",
    "author": "cn-knight",
    "state": "closed",
    "created_at": "2025-03-11T13:02:56Z",
    "updated_at": "2025-03-13T09:29:20Z",
    "labels": [],
    "body": "GPU 4G OK ?",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "Of course, my computer is 4g of video memory, marking a picture average of about 10s, However, it's important to note that the cuda version is compatible with the torch, which I've covered in readme."
      },
      {
        "user": "cn-knight",
        "body": "> Of course, my computer is 4g of video memory, marking a picture average of about 10s, However, it's important to note that the cuda version is compatible with the torch, which I've covered in readme.\n\nmany thanks"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 76,
    "title": "website config",
    "author": "sharkskin",
    "state": "closed",
    "created_at": "2025-03-11T15:06:03Z",
    "updated_at": "2025-03-13T09:29:13Z",
    "labels": [],
    "body": "How to enable external access? Where to set \"share=true\"ï¼Ÿ\n\nThank you!",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "You can try adding this to the startup code:\ndemo.launch(server_name=\"0.0.0.0\", server_port=7888, share=True)\n\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 85,
    "title": "default base url",
    "author": "cn-knight",
    "state": "closed",
    "created_at": "2025-03-13T08:26:35Z",
    "updated_at": "2025-03-13T09:24:54Z",
    "labels": [],
    "body": "è™½ç„¶è¯´ä»¥è‡ªå·±çš„placeholderä¸ºå‡†ï¼Œé‚£ä¸ªé»˜è®¤å€¼\"https://api.openai-next.com/v1\"ä¸ºä»€ä¹ˆä¸ç”¨æ­£ç¡®çš„å‘¢ï¼Œè¿™ä¸ªurlæµ‹ä¸é€šopenaiï¼Œæ”¹æˆhttps://api.openai.com/v1æ‰é€šäº†\n\n\n                with gr.Column():\n                    base_url = gr.Textbox(\n                        label=\"Base URL\",\n                        value=\"https://api.openai-next.com/v1\",\n                        placeholder=\"è¾“å…¥åŸºç¡€ URL\",\n                        interactive=True",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¿™ä¸ªæ˜¯ä»£ç†ç«™çš„åœ°å€ï¼Œå›½å†…å¤§å¤šæ•°äººæ— æ³•ç”¨openaiçš„ï¼Œæ‰€ä»¥æˆ‘æ”¾äº†ä»£ç†ç«™ã€‚ä¸è¿‡ä½ è¿™æ˜¯éå¸¸å¥½çš„å»ºè®®ï¼Œæˆ‘å‡†å¤‡æ”¹å›å»äº†"
      },
      {
        "user": "yuruotong1",
        "body": "ä»£ç å·²ç»ä¿®æ”¹äº†ï¼Œè¾›è‹¦æ›´æ–°ä¸€ä¸‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 84,
    "title": "è¿™ä¸ªåŠŸèƒ½èƒ½åœ¨linuxä¸Šç©å—",
    "author": "llk2014",
    "state": "closed",
    "created_at": "2025-03-13T06:21:16Z",
    "updated_at": "2025-03-13T07:59:35Z",
    "labels": [],
    "body": "å¦‚é¢˜",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ç›®å‰åœ¨windowså’Œmacä¸Šæµ‹è¯•è¿‡éƒ½æ˜¯å¯ä»¥çš„ï¼Œæˆ‘ä¼°è®¡ linux åº”è¯¥æ˜¯æ²¡é—®é¢˜"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 83,
    "title": "æœåŠ¡å¯åŠ¨æŠ¥é”™",
    "author": "mrzzao",
    "state": "closed",
    "created_at": "2025-03-12T10:22:43Z",
    "updated_at": "2025-03-13T05:53:53Z",
    "labels": [],
    "body": "python main.py \ncuda is_available:  True\nMPS is_available:  False\ncuda device_count 1\ncuda device_name NVIDIA GeForce RTX 4090\nå·²ç»æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ï¼\nå¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œå› ä¸ºåŠ è½½æ¨¡å‹çœŸçš„è¶…çº§æ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼\nç­‰å¾…æœåŠ¡å¯åŠ¨...\n\n[SERVER-OUT] --------------------------------------\n[SERVER-OUT] 0   paddle_infer::Predictor::Predictor(paddle::AnalysisConfig const&)\n[SERVER-OUT] 1   std::unique_ptr<paddle::PaddlePredictor, std::default_delete<paddle::PaddlePredictor> > paddle::CreatePaddlePredictor<paddle::AnalysisConfig, (paddle::PaddleEngineKind)2>(paddle::AnalysisConfig const&)\n[SERVER-OUT] 2   paddle::AnalysisPredictor::Init(std::shared_ptr<paddle::framework::Scope> const&, std::shared_ptr<paddle::framework::ProgramDesc> const&)\n[SERVER-OUT] 3   paddle::AnalysisPredictor::PrepareProgram(std::shared_ptr<paddle::framework::ProgramDesc> const&)\n[SERVER-OUT] 4   paddle::AnalysisPredictor::OptimizeInferenceProgram()\n[SERVER-OUT] 5   paddle::inference::analysis::Analyzer::RunAnalysis(paddle::inference::analysis::Argument*)\n[SERVER-OUT] 6   paddle::inference::analysis::IrAnalysisPass::RunImpl(paddle::inference::analysis::Argument*)\n[SERVER-OUT] 7   paddle::inference::analysis::IRPassManager::Apply(std::unique_ptr<paddle::framework::ir::Graph, std::default_delete<paddle::framework::ir::Graph> >)\n[SERVER-OUT] 8   paddle::framework::ir::Pass::Apply(paddle::framework::ir::Graph*) const\n[SERVER-OUT] 9   paddle::framework::ir::SelfAttentionFusePass::ApplyImpl(paddle::framework::ir::Graph*) const\n[SERVER-OUT] 10  paddle::framework::ir::GraphPatternDetector::operator()(paddle::framework::ir::Graph*, std::function<void (std::map<paddle::framework::ir::PDNode*, paddle::framework::ir::Node*, paddle::framework::ir::GraphPatternDetector::PDNodeCompare, std::allocator<std::pair<paddle::framework::ir::PDNode* const, paddle::framework::ir::Node*> > > const&, paddle::framework::ir::Graph*)>)\n[SERVER-OUT] \n[SERVER-OUT] ----------------------\n[SERVER-OUT] Error Message Summary:\n[SERVER-OUT] ----------------------\n[SERVER-OUT] FatalError: `Illegal instruction` is detected by the operating system.\n[SERVER-OUT]   [TimeInfo: *** Aborted at 1741774642 (unix time) try \"date -d @1741774642\" if you are using GNU date ***]\n[SERVER-OUT]   [SignalInfo: *** SIGILL (@0x7f8ef188860a) received by PID 17822 (TID 0x7f90047e8740) from PID 18446744073466840586 ***]\n[SERVER-OUT] \nTraceback (most recent call last):\n  File \"/root/autoMate/main.py\", line 79, in <module>\n    run()\n  File \"/root/autoMate/main.py\", line 56, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š{server_process.returncode}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼š-4\n\næ˜¾å¡ï¼š4090\né©±åŠ¨ç‰ˆæœ¬ï¼š565.57.01\ncudaç‰ˆæœ¬ï¼š12.2\nç³»ç»Ÿï¼š22.04.5 LTS\nå†…æ ¸ç‰ˆæœ¬ï¼š5.15.0-134-generic\nç”±äºæœºå™¨æ²¡æ³•è”ç½‘ï¼Œè°ƒæ•´äº†è„šæœ¬æ¨¡å‹æ–‡ä»¶æ˜¯åœ¨é­”å¡”ä¸‹è½½çš„ï¼Œå…¶ä»–çš„æ²¡å˜ã€‚",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æˆ‘å‡†å¤‡æŠŠæœåŠ¡åˆ äº†ï¼Œè¿™ä¸ªæœåŠ¡å¥½å¤šäººæŠ¥é”™"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 64,
    "title": "æ‰§è¡ŒæŠ¥é”™",
    "author": "hope-ghost",
    "state": "closed",
    "created_at": "2025-03-08T03:14:40Z",
    "updated_at": "2025-03-11T07:45:43Z",
    "labels": [],
    "body": "å¡«å…¥é¡¹ï¼š\nModelï¼šdeepseek-chat  \nBase URLï¼šhttps://api.deepseek.com/v1\nN most recent screenshotsï¼š2\nAPI Keyï¼šå·²å¡«ï¼Œä¸”æ˜¯ä»å®˜ç½‘è·å–\næµ‹è¯•è¯­å¥ï¼šå¸®æˆ‘æ‰“å¼€Bç«™å¹¶åˆ·å‡ ä¸ªç§‘æŠ€å‘è§†é¢‘ï¼Œå¹¶ä¸€é”®3è¿\nç½‘ç»œæƒ…å†µï¼šæ— VPNï¼Œä½¿ç”¨å›½å†…ç½‘ç»œ\napiè¿æ¥æƒ…å†µï¼šä½¿ç”¨pythonå·²é€šè¿‡å®˜ç½‘çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œè¿æ¥æ­£å¸¸\næŠ¥é”™ï¼š\nTraceback (most recent call last):\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\models.py\", line 974, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\queueing.py\", line 715, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\blocks.py\", line 2044, in process_api\n    result = await self.call_function(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\blocks.py\", line 1603, in call_function\n    prediction = await utils.async_iteration(iterator)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\utils.py\", line 728, in async_iteration\n    return await anext(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\utils.py\", line 722, in __anext__\n    return await anyio.to_thread.run_sync(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\utils.py\", line 705, in run_sync_iterator_async\n    return next(iterator)\n           ^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\gradio\\utils.py\", line 866, in gen_wrapper\n    response = next(iterator)\n               ^^^^^^^^^^^^^^\n  File \"E:\\AI\\autoMate\\gradio_ui\\app.py\", line 176, in process_input\n    for loop_msg in sampling_loop_sync(\n  File \"E:\\AI\\autoMate\\gradio_ui\\loop.py\", line 60, in sampling_loop_sync\n    tools_use_needed, vlm_response_json = actor(messages=messages, parsed_screen=parsed_screen)\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\AI\\autoMate\\gradio_ui\\agent\\vlm_agent.py\", line 79, in __call__\n    vlm_response, token_usage = run_oai_interleaved(\n                                ^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\AI\\autoMate\\gradio_ui\\agent\\llm_utils\\oaiclient.py\", line 61, in run_oai_interleaved\n    print(f\"Error in interleaved openAI: {e}. This may due to your invalid API key. Please check the response: {response.json()} \")\n                                                                                                                ^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\models.py\", line 978, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)",
    "comments": [
      {
        "user": "Gushroom",
        "body": "æŠ¥é”™ä¹‹å‰çš„logæœ‰å—ï¼Ÿè¿™ä¸ªé—®é¢˜å¤§æ¦‚ç‡æ˜¯LLMè¿”å›çš„ç­”æ¡ˆæ²¡æœ‰ç¬¦åˆæ ¼å¼åŒ–è¦æ±‚"
      },
      {
        "user": "hope-ghost",
        "body": "ä¸å¥½æ„æ€ï¼Œä¼¼ä¹å¹¶æ²¡æœ‰ç”Ÿæˆlogæ–‡ä»¶"
      },
      {
        "user": "Gushroom",
        "body": "ä¸æ˜¯logæ–‡ä»¶ terminalä¼šå†™å½“å‰æ­¥éª¤ çœ‹ä¸€ä¸‹åœ¨æŠ¥é”™ä¿¡æ¯ä¹‹å‰æ˜¯ä¸æ˜¯å·²ç»æ”¶åˆ°äº†Deepseekçš„å›å¤ï¼Ÿ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 67,
    "title": "æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼Œé€€å‡ºä»£ç ï¼š1",
    "author": "YXuan66",
    "state": "closed",
    "created_at": "2025-03-10T05:42:07Z",
    "updated_at": "2025-03-10T06:03:17Z",
    "labels": [],
    "body": "[SERVER-OUT] Progress: |--------------------------------------------------| 2.0% Complete\n[SERVER-OUT] Progress: |--------------------------------------------------| 2.0% Complete\n[SERVER-OUT] Progress: |--------------------------------------------------| 2.0% Complete\n[SERVER-OUT] Progress: |--------------------------------------------------| 2.0% Completeç­‰å¾…æœåŠ¡å¯åŠ¨...\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\Desktop\\autoMate\\main.py\", line 89, in <module>\n    run()\n  File \"C:\\Users\\Administrator\\Desktop\\autoMate\\main.py\", line 54, in run\n    raise RuntimeError(f\"æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼Œé€€å‡ºä»£ç ï¼š{server_process.returncode}\\né”™è¯¯ä¿¡æ¯ï¼š{stderr_output}\")\nRuntimeError: æœåŠ¡å™¨è¿›ç¨‹æŠ¥é”™é€€å‡ºï¼Œé€€å‡ºä»£ç ï¼š1\né”™è¯¯ä¿¡æ¯ï¼š\nI have changed some code to detect the error but failed",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 63,
    "title": "æ±‚å¤§ä½¬åšä¸ªä¸€é”®åŒ…~",
    "author": "aimarxjg",
    "state": "closed",
    "created_at": "2025-03-08T02:07:11Z",
    "updated_at": "2025-03-09T01:16:07Z",
    "labels": [
      "enhancement"
    ],
    "body": "å…å»éƒ¨ç½²çš„éº»çƒ¦ï¼Œè°¢è°¢",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ”¶åˆ°ï¼Œæˆ‘ä»¬æš‚æ—¶å…ˆä¸“æ³¨äº bug fixï¼Œåé¢ä¼šè€ƒè™‘æ¨å‡ºä¸€é”®éƒ¨ç½²åŒ…"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 54,
    "title": "éœ€è¦çš„ç”µè„‘é…ç½®è¦æ±‚é«˜å—ï¼Ÿ",
    "author": "chenchenno11",
    "state": "closed",
    "created_at": "2025-03-06T10:58:52Z",
    "updated_at": "2025-03-08T06:06:32Z",
    "labels": [],
    "body": "æˆ‘æƒ³åœ¨è™šæ‹Ÿæœºä¸Šè¿è¡Œï¼Œä½†æ˜¯æ€•ä¸è¡Œå•Šï¼Œæœ€ä½é…ç½®è¦æ±‚æœ‰å—",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æœ‰ä¸ª 2g æ˜¾å­˜çš„æ˜¾å¡å°±èƒ½è·‘ï¼Œå…¶ä»–æ²¡å•¥è¦æ±‚"
      },
      {
        "user": "chenchenno11",
        "body": "å¯ä»¥ç”¨è¿™ä¸ªè§£å†³cfçš„turnsliteé—®é¢˜å—ï¼ŒæŠ˜è…¾äº†å¥½å‡ å¤©æ²¡è§£å†³ï¼Œå‘ç°è¿™ä¸ªé¡¹ç›®å¯èƒ½æ˜¯ä¸ªæ–¹æ³•ã€‚"
      },
      {
        "user": "yuruotong1",
        "body": "> å¯ä»¥ç”¨è¿™ä¸ªè§£å†³cfçš„turnsliteé—®é¢˜å—ï¼ŒæŠ˜è…¾äº†å¥½å‡ å¤©æ²¡è§£å†³ï¼Œå‘ç°è¿™ä¸ªé¡¹ç›®å¯èƒ½æ˜¯ä¸ªæ–¹æ³•ã€‚\n\nè¯·é—®turnsliteæ˜¯ä»€ä¹ˆé—®é¢˜å‘€"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 56,
    "title": "åœ¨æ‰“å°å‡ºâ€å¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œçº¦40så·¦å³ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼â€œåæŠ¥é”™",
    "author": "hope-ghost",
    "state": "closed",
    "created_at": "2025-03-07T01:10:24Z",
    "updated_at": "2025-03-08T06:04:58Z",
    "labels": [],
    "body": "åœ¨æ‰“å°å‡ºâ€å¯åŠ¨OmniserveræœåŠ¡ä¸­ï¼Œçº¦40så·¦å³ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼â€œåæŠ¥é”™ï¼š\nTraceback (most recent call last):\n  File \"E:\\AI\\autoMate\\main.py\", line 47, in <module>\n    run()\n  File \"E:\\AI\\autoMate\\main.py\", line 38, in run\n    raise RuntimeError(\"Server process terminated unexpectedly\")\nRuntimeError: Server process terminated unexpectedly\nå·²æ£€æŸ¥ç«¯å£å ç”¨ï¼Œå·²é‡è£…è¿‡pytorchï¼Œå·²é‡é…ç½®è¿‡requirement.txtï¼Œé—®é¢˜æ²¡æœ‰è§£å†³",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "è¯·æ›´æ–°ä¸€ä¸‹æœ€æ–°çš„ç‰ˆæœ¬ï¼Œåˆšæ‰æ¨é€äº†ï¼"
      },
      {
        "user": "hope-ghost",
        "body": "> è¯·æ›´æ–°ä¸€ä¸‹æœ€æ–°çš„ç‰ˆæœ¬ï¼Œåˆšæ‰æ¨é€äº†ï¼\n\nç°åœ¨å˜æˆäº†Traceback (most recent call last):\n  File \"E:\\AI\\autoMate\\main.py\", line 74, in <module>\n    run()\n  File \"E:\\AI\\autoMate\\main.py\", line 34, in run\n    res = requests.get(\"http://127.0.0.1:8000/probe/\")\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\api.py\", line 73, in get\n    return request(\"get\", url, params=params, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /probe/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C099733020>: Failed to establish a new connection: [WinError 10061] ç”±äºç›®æ ‡è®¡ç®—æœºç§¯ææ‹’ç»ï¼Œæ— æ³•è¿æ¥ã€‚'))\nå·²å°è¯•æ‰‹æ®µï¼š\nVPNå·²å…³\næ³¨å†Œè¡¨ä¸­Internet settingä¸­çš„ProxyEnableä¿®æ”¹ä¸º0\né˜²ç«å¢™å·²å…³\nå·²æ£€æŸ¥ç«¯å£å ç”¨\né—®é¢˜æ²¡æœ‰è§£å†³"
      },
      {
        "user": "yuruotong1",
        "body": "> > è¯·æ›´æ–°ä¸€ä¸‹æœ€æ–°çš„ç‰ˆæœ¬ï¼Œåˆšæ‰æ¨é€äº†ï¼\n> \n> ç°åœ¨å˜æˆäº†Traceback (most recent call last): File \"E:\\AI\\autoMate\\main.py\", line 74, in run() File \"E:\\AI\\autoMate\\main.py\", line 34, in run res = requests.get(\"http://127.0.0.1:8000/probe/\") ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\api.py\", line 73, in get return request(\"get\", url, params=params, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\api.py\", line 59, in request return session.request(method=method, url=url, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request resp = self.send(prep, **send_kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send r = adapter.send(request, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"E:\\Anaconda3\\envs\\automate\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send raise ConnectionError(e, request=request) requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /probe/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001C099733020>: Failed to establish a new connection: [WinError 10061] ç”±äºç›®æ ‡è®¡ç®—æœºç§¯ææ‹’ç»ï¼Œæ— æ³•è¿æ¥ã€‚')) å·²å°è¯•æ‰‹æ®µï¼š VPNå·²å…³ æ³¨å†Œè¡¨ä¸­Internet settingä¸­çš„ProxyEnableä¿®æ”¹ä¸º0 é˜²ç«å¢™å·²å…³ å·²æ£€æŸ¥ç«¯å£å ç”¨ é—®é¢˜æ²¡æœ‰è§£å†³\n\näº†è§£äº†ï¼Œè¿™ä¸ªé—®é¢˜åˆšåˆšä¿®å¤äº†ï¼Œè¾›è‹¦å†æ›´æ–°ä¸€ä¸‹ä»£ç "
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 10,
    "title": "ğŸ‘‘ [éœ€æ±‚]åŠ å…¥è¿æ¥ä¸åŒä»£ç å—çš„åŠŸèƒ½ã€‚",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T23:35:19Z",
    "updated_at": "2025-03-03T09:41:25Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 11,
    "title": "ğŸ‘‘ [éœ€æ±‚]å»ºç«‹å…±äº«ä»£ç åŠŸèƒ½ï¼Œå¯æœç´¢ã€ä¸‹è½½ã€æ›´æ–°å…¶ä»–äººå…±äº«çš„ä»£ç å—",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T23:36:55Z",
    "updated_at": "2025-03-03T09:41:19Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 12,
    "title": "ğŸ‘‘ [éœ€æ±‚]é™¤ç¬¬ä¸€æ¬¡ç”Ÿæˆçš„ä»£ç å¤–ï¼Œæ— æ³•è‡ªåŠ¨æ›´æ–°ä»£ç å—ï¼Œåœ¨æ™ºå­å¯¹è¯æ¡†ä¸­åŠ å…¥æ›´æ–°æŒ‰é’®æˆ–è€…è‡ªåŠ¨æ›´æ–°ï¼",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T23:46:53Z",
    "updated_at": "2025-03-03T09:41:13Z",
    "labels": [
      "enhancement"
    ],
    "body": "è½¯ä»¶ç¬¬ä¸€æ¬¡æ˜¯è‡ªåŠ¨æŠŠä»£ç æ”¾å…¥ä»£ç åŒºï¼Œåé¢ä¿®æ”¹çš„ä»£ç å®ƒä¸ä¼šè‡ªåŠ¨æ›´æ–°åˆ°ä»£ç åŒºï¼Œæ‰€ä»¥èƒ½è‡ªåŠ¨æ›´æ–°ï¼Œæˆ–èƒ½æ‰‹åŠ¨æ›´æ–°ä¿®æ”¹åçš„ä»£ç åˆ°ä»£ç åŒºï¼Œæ•ˆç‡ä¼šé«˜å¥½å¤šã€‚",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 15,
    "title": "ğŸ‘‘ [éœ€æ±‚]pythonæ‰§è¡Œå™¨æ”¯æŒç”¨æˆ·ä¸»åŠ¨æ‰©å±•ç¬¬ä¸‰æ–¹ä¾èµ–",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-09T13:35:25Z",
    "updated_at": "2025-03-03T09:41:08Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 17,
    "title": "ğŸ‘‘ [éœ€æ±‚]æ–‡æ¡£ä¸­å¢åŠ å›½äº§å¤§æ¨¡å‹çš„ä½¿ç”¨ç¤ºèŒƒ",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T10:20:58Z",
    "updated_at": "2025-03-03T09:41:03Z",
    "labels": [
      "documentation"
    ],
    "body": "<img width=\"582\" alt=\"68097a4d60a2c96b0bfe7d535cf6560c_\" src=\"https://github.com/yuruotong1/autoMate/assets/31992251/52a0e89e-edd8-4ab0-b670-dfc303c72574\">",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 16,
    "title": "ğŸ‘‘ [éœ€æ±‚]æœç´¢ç•Œé¢â€œç‚¹å‡»é…ç½®â€œä¿®æ”¹ä¸ºâ€œç‚¹å‡»é…ç½® AI APIâ€",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T10:20:04Z",
    "updated_at": "2025-03-03T09:40:58Z",
    "labels": [
      "enhancement"
    ],
    "body": "<img width=\"626\" alt=\"cf7c320eb7523bea0b2b7fc4291d842f_\" src=\"https://github.com/yuruotong1/autoMate/assets/31992251/e65f51d8-74a1-4e47-84a1-7b0aec6f68e3\">",
    "comments": [
      {
        "user": "HelloBojack",
        "body": "@yuruotong1 https://github.com/yuruotong1/autoMate/pull/39 Thank you for merge! This issue can close~"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 21,
    "title": "ğŸ‘‘ [éœ€æ±‚]é£ä¹¦æ–‡æ¡£ä¸­å¢åŠ Ollamaçš„ä½¿ç”¨æŒ‡å—",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T11:37:58Z",
    "updated_at": "2025-03-03T09:40:50Z",
    "labels": [
      "documentation"
    ],
    "body": "rt",
    "comments": [
      {
        "user": "Lvan826199",
        "body": "æ–‡æ¡£å·²æ·»åŠ ï¼šhttps://o0h3vqpeoxs.feishu.cn/docx/QMmYdhjvood5wpxDWcscGVWYnCQ"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 22,
    "title": "ğŸ‘‘ [éœ€æ±‚]åŠ å…¥æ—¥å¿—ä½“ç³»ï¼Œå¯ä»¥åœ¨é¡µé¢å¯¼å‡ºæ—¥å¿—ï¼Œæ–¹ä¾¿æ’æŸ¥é”™è¯¯",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T13:30:39Z",
    "updated_at": "2025-03-03T09:40:39Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 23,
    "title": "ğŸ‘‘ [éœ€æ±‚]è‡ªåŠ¨æ›´æ–°çš„åŒ…ä½¿ç”¨githubä¸ç¨³å®šï¼Œæ”¹åˆ°giteeæˆ–è€…å…¶ä»–ä»“åº“ ",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T15:09:52Z",
    "updated_at": "2025-03-03T09:40:34Z",
    "labels": [
      "enhancement"
    ],
    "body": "![947f5d911b63c31788aa33fc9795fd8](https://github.com/yuruotong1/autoMate/assets/31992251/992772a5-1cc3-4ac6-ae0c-8fa9d4367c6d)",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 26,
    "title": "ğŸ‘‘ [Feature Request]ä» Flask è¿ç§»åˆ° FastAPI",
    "author": "linkedlist771",
    "state": "closed",
    "created_at": "2024-07-11T05:18:33Z",
    "updated_at": "2025-03-03T09:40:27Z",
    "labels": [
      "enhancement"
    ],
    "body": "\r\n\r\n### ğŸ¥° éœ€æ±‚æè¿°\r\n\r\nå°†ç°æœ‰çš„ Flask åç«¯è¿ç§»åˆ° FastAPI æ¡†æ¶ã€‚è¿™ä¸ªå˜æ›´çš„ç›®çš„æ˜¯åˆ©ç”¨ FastAPI çš„ä¼˜åŠ¿,å¦‚:\r\n- æ›´å¿«çš„æ€§èƒ½\r\n- è‡ªåŠ¨ API æ–‡æ¡£ç”Ÿæˆ\r\n- æ›´å¼ºå¤§çš„ç±»å‹æç¤ºå’ŒéªŒè¯\r\n- å¼‚æ­¥æ”¯æŒ\r\n- ç°ä»£åŒ–çš„ Python è¯­æ³•\r\n\r\n### ğŸ§ è§£å†³æ–¹æ¡ˆ\r\n\r\n1. è¯„ä¼°å½“å‰ Flask åº”ç”¨ç»“æ„\r\n2. è®¾è®¡ FastAPI è¿ç§»è®¡åˆ’\r\n3. é€æ­¥å°† Flask è·¯ç”±è½¬æ¢ä¸º FastAPI è·¯å¾„æ“ä½œ\r\n4. åˆ©ç”¨ Pydantic æ¨¡å‹è¿›è¡Œæ•°æ®éªŒè¯\r\n5. å®ç°ä¾èµ–æ³¨å…¥ç³»ç»Ÿ\r\n6. é…ç½® FastAPI çš„å¼‚æ­¥ç‰¹æ€§(å¦‚æœéœ€è¦)\r\n7. æ›´æ–°æ•°æ®åº“è¿æ¥(å¦‚æœé€‚ç”¨)\r\n8. è¿ç§»æµ‹è¯•å¥—ä»¶\r\n9. æ›´æ–°éƒ¨ç½²æµç¨‹\r\n10. è¿›è¡Œæ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–\r\n11. å›¢é˜Ÿåä½œï¼šåˆ©ç”¨æ‚¨æä¾›çš„å¸®åŠ©ï¼Œåˆ†é…ä»»åŠ¡å¹¶å®šæœŸåŒæ­¥è¿›åº¦\r\n\r\n```mermaid\r\ngraph TD\r\n    A[è¯„ä¼°å½“å‰Flaskåº”ç”¨] --> B[è®¾è®¡FastAPIè¿ç§»è®¡åˆ’]\r\n    B --> C[ä»»åŠ¡åˆ†é…å’Œå›¢é˜Ÿåä½œ]\r\n    C --> D[è½¬æ¢è·¯ç”±]\r\n    D --> E[å®ç°Pydanticæ¨¡å‹]\r\n    E --> F[é…ç½®ä¾èµ–æ³¨å…¥]\r\n    F --> G[å¯ç”¨å¼‚æ­¥ç‰¹æ€§]\r\n    G --> H[æ›´æ–°æ•°æ®åº“è¿æ¥]\r\n    H --> I[è¿ç§»æµ‹è¯•]\r\n    I --> J[æ›´æ–°éƒ¨ç½²æµç¨‹]\r\n    J --> K[æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–]\r\n    K --> L[æœ€ç»ˆå®¡æŸ¥å’Œä¸Šçº¿]\r\n    C -.-> M[å®šæœŸè¿›åº¦åŒæ­¥]\r\n    M -.-> C\r\n```\r\n\r\n### ğŸš‘ å…¶ä»–ä¿¡æ¯\r\n\r\nåœ¨è¿›è¡Œè¿ç§»æ—¶,éœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹:\r\n\r\n1. ç¡®ä¿å›¢é˜Ÿæˆå‘˜ç†Ÿæ‚‰ FastAPI çš„æ¦‚å¿µå’Œæœ€ä½³å®è·µã€‚\r\n2. è€ƒè™‘æ˜¯å¦éœ€è¦ä¿æŒå‘åå…¼å®¹æ€§,æˆ–è€…æ˜¯å¦å¯ä»¥å®Œå…¨é‡å†™ APIã€‚\r\n3. è¯„ä¼°ç°æœ‰çš„ç¬¬ä¸‰æ–¹æ‰©å±•æ˜¯å¦æœ‰ FastAPI ç­‰æ•ˆæ›¿ä»£å“ã€‚\r\n4. æ›´æ–° API æ–‡æ¡£,åˆ©ç”¨ FastAPI çš„è‡ªåŠ¨æ–‡æ¡£ç”ŸæˆåŠŸèƒ½ã€‚\r\n> PS: å¦‚æœmaintaineréœ€è¦ï¼Œæˆ‘å¯ä»¥æä¾›å¸®åŠ©ï¼Œ æˆ‘å¯¹fastapiæ¯”è¾ƒç†Ÿæ‚‰",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "ä½†æ„Ÿè§‰è¿ç§»çš„è¯å¯¹ç”¨æˆ·å½±å“ä¸å¤§"
      },
      {
        "user": "phil616",
        "body": "å¦‚æœè¿™ä¸ªè¿ç§»åˆ°FastAPIçš„æ–¹æ¡ˆé€šè¿‡ï¼Œæˆ‘ä¹Ÿå¯åŠ å…¥"
      },
      {
        "user": "yuruotong1",
        "body": "> å¦‚æœè¿™ä¸ªè¿ç§»åˆ°FastAPIçš„æ–¹æ¡ˆé€šè¿‡ï¼Œæˆ‘ä¹Ÿå¯åŠ å…¥\r\n\r\næœ‰å‡ ä¸ªé—®é¢˜éœ€è¦ç»™å‡ºç­”æ¡ˆï¼š\r\n\r\n1. è¿™ä¹ˆåšèƒ½ä¸ºç”¨æˆ·å¸¦æ¥ä»€ä¹ˆæ›´å¥½çš„ä½“éªŒï¼Ÿ\r\n2. å›¢é˜Ÿæˆå‘˜æ˜¯å¦æ›´ç†Ÿæ‚‰fastapiï¼Ÿç›¸æ¯”äºflaskæ¥è¯´ï¼Ÿ \r\n3. å¯¹å·²æœ‰é¡¹ç›®å˜æ›´æ˜¯å¦ä¼šå¼•å…¥æ›´å¤§çš„é£é™©ï¼Ÿ\r\n"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 30,
    "title": "ğŸ‘‘ [éœ€æ±‚] autoMate å†…ç½® ollama",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-13T23:37:07Z",
    "updated_at": "2025-03-03T09:40:19Z",
    "labels": [
      "enhancement"
    ],
    "body": "1. ç”¨æˆ·æ‰“å¼€åèµ°é»˜è®¤çš„æœ¬åœ°æ¨¡å‹ï¼›\r\n2. ç‚¹å‡»é…ç½®å¯æ›´æ¢å…¶ä»–æ¨¡å‹ï¼›",
    "comments": [
      {
        "user": "mbt1909432",
        "body": "åœ¨è¿™"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 31,
    "title": "ğŸ‘‘ [éœ€æ±‚]è‡ªåŠ¨å­¦ä¹ apiæ¥å£ä¿¡æ¯ï¼Œå®Œæˆå¯¹è¯¥apiæ¥å£çš„è‡ªåŠ¨åŒ–",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-13T23:38:17Z",
    "updated_at": "2025-03-03T09:40:13Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [
      {
        "user": "phil616",
        "body": "å¦‚æœAPIç¬¦åˆæŸä¸ªè§„èŒƒï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨è§„èŒƒæå‡ºè€…æä¾›çš„ç”Ÿæˆå™¨ï¼Œä»¥FastAPIä¸ºä¾‹ï¼Œappå¯åŠ¨å‚æ•°æä¾›äº†ä¸€ä¸ªç”Ÿæˆç¬¦åˆOpenAPIè§„èŒƒçš„åŸŸä»¥ç”Ÿæˆç«¯ç‚¹IDï¼Œå¯ä»¥ç”¨æ¥ç”Ÿæˆ[TSå®¢æˆ·ç«¯ä»£ç ](https://fastapi.tiangolo.com/advanced/generate-clients/?h=gene#generate-a-typescript-client-with-the-preprocessed-openapi)ï¼Œä¸€èˆ¬éƒ½åŒ…å«åœ¨æ–‡æ¡£çš„SDKä¸­ï¼Œåªè¦æŠŠå¸¸è§å¹³å°çš„SDKæ–‡æ¡£åŒ…å«åˆ°é¡¹ç›®é‡Œå°±å¯ä»¥å®ç°è‡ªåŠ¨å­¦ä¹ APIçš„æ¥å£ä¿¡æ¯ã€‚"
      },
      {
        "user": "yuruotong1",
        "body": "> å¦‚æœAPIç¬¦åˆæŸä¸ªè§„èŒƒï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨è§„èŒƒæå‡ºè€…æä¾›çš„ç”Ÿæˆå™¨ï¼Œä»¥FastAPIä¸ºä¾‹ï¼Œappå¯åŠ¨å‚æ•°æä¾›äº†ä¸€ä¸ªç”Ÿæˆç¬¦åˆOpenAPIè§„èŒƒçš„åŸŸä»¥ç”Ÿæˆç«¯ç‚¹IDï¼Œå¯ä»¥ç”¨æ¥ç”Ÿæˆ[TSå®¢æˆ·ç«¯ä»£ç ](https://fastapi.tiangolo.com/advanced/generate-clients/?h=gene#generate-a-typescript-client-with-the-preprocessed-openapi)ï¼Œä¸€èˆ¬éƒ½åŒ…å«åœ¨æ–‡æ¡£çš„SDKä¸­ï¼Œåªè¦æŠŠå¸¸è§å¹³å°çš„SDKæ–‡æ¡£åŒ…å«åˆ°é¡¹ç›®é‡Œå°±å¯ä»¥å®ç°è‡ªåŠ¨å­¦ä¹ APIçš„æ¥å£ä¿¡æ¯ã€‚\n\næœ‰åŠæ³•é›†æˆåˆ°å’±ä»¬çš„é¡¹ç›®ä¸­å—ï¼Ÿ"
      },
      {
        "user": "phil616",
        "body": "FastAPIæ¯•ç«Ÿåªæ˜¯å•ä¸€åº”ç”¨ï¼Œå„ä¸ªå‚å®¶é‡‡ç”¨çš„æ ‡å‡†ä¸åŒï¼Œé›†æˆåˆ°è¯¥é¡¹ç›®é‡Œé¢éœ€è¦é¡¹ç›®å¼€å‘è€…å›¢é˜Ÿå°½å¯èƒ½å¤šçš„å»ä¸»åŠ¨é€‚é…æ¨¡å‹æä¾›å•†æä¾›çš„SDKåŠç›¸å…³è§„èŒƒï¼Œç›®å‰å›¢é˜Ÿè§„æ¨¡æ— åŠ›é€ä¸ªé€‚é…ï¼Œå»ºè®®å…ˆæç½®"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 32,
    "title": "ğŸ‘‘ [éœ€æ±‚]ç•Œé¢ä¸­å¢åŠ å®¢æˆ·åé¦ˆæ¸ é“ï¼Œèƒ½å¤Ÿåœ¨ç•Œé¢ç›´æ¥æé—®é¢˜å’Œéœ€æ±‚",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-13T23:39:54Z",
    "updated_at": "2025-03-03T09:40:03Z",
    "labels": [
      "enhancement"
    ],
    "body": "å¯ä»¥è€ƒè™‘å’Œå·²æœ‰çš„æé—®å·¥å…·ç»“åˆï¼Œæ¯”å¦‚â€œæˆ‘æ¥â€",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 33,
    "title": "ğŸ‘‘ [éœ€æ±‚]å¯¹äºåœ¨çº¿æ¨¡å‹ï¼Œåªéœ€è¦æ·»åŠ ä¸€ä¸ªtoken",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-14T00:04:36Z",
    "updated_at": "2025-03-03T09:39:55Z",
    "labels": [
      "enhancement"
    ],
    "body": "æä¾›ä¸€ä¸ªæ”¯æŒçš„æ¨¡å‹ä¾›åº”å•†çš„åˆ—è¡¨ä¾›äººé€‰æ‹©    å¯¹äºåœ¨çº¿æ¨¡å‹ï¼Œåªéœ€è¦æ·»åŠ ä¸€ä¸ªtokenå°±å¥½ï¼Œtokençš„ç”³è¯·è‚¯å®šå„å®¶éƒ½æœ‰è¯¦ç»†çš„æ–‡æ¡£ï¼Œè€Œå…·ä½“çš„å’Œæ¨¡å‹çš„äº¤äº’ï¼Œå®Œå…¨å¯ä»¥åç«¯è´Ÿè´£å»å¤„ç†è½¬æ¢ ã€‚",
    "comments": [
      {
        "user": "fjklqq",
        "body": "å¯ä»¥åœ¨åç«¯æ·»åŠ ä¸€ä¸ªè·å–æ”¯æŒçš„æ¨¡å‹å…¥å£åˆ—è¡¨çš„æ¥å£ï¼Œè¿”å›å¦‚ä¸‹ä¿¡æ¯ï¼Œå‰ç«¯ä¾æ®æ­¤ä¿¡æ¯å±•ç¤ºé…ç½®é¡µé¢çš„é€‰é¡¹ã€‚\r\nåŒæ—¶åœ¨å’Œåç«¯äº¤äº’ï¼ˆ`/llm`æ¥å£ï¼‰æ—¶ä¼ é€’`msg`ã€ `enter_id` åŠ `parameters`çš„é…ç½®å†…å®¹(æˆ–å­˜å…¥æ•°æ®åº“ï¼Œåç«¯ç”±æ•°æ®åº“ç›´æ¥è¯»å–)ï¼Œç”±åç«¯è‡ªè¯»åˆ¤æ–­ä½¿ç”¨å“ªä¸€ä¸ªå…¥å£å®Œæˆä¼šè¯ã€‚\r\n```json\r\n[\r\n    {\r\n        \"enter_id\": \"OpenaiEnterPoint\",\r\n        \"name\": \"OpenAI\",\r\n        \"parameters\": {\r\n            \"api_key\": {\r\n                \"default\": null,\r\n                \"name\": \"API KEY\",\r\n                \"required\": true,\r\n                \"typing\": \"string\"\r\n            },\r\n            \"base_url\": {\r\n                \"default\": \"https://api.openai.com/v1/engines/davinci/completions\",\r\n                \"name\": \"Base URL\",\r\n                \"required\": false,\r\n                \"typing\": \"string\"\r\n            },\r\n            \"model_name\": {\r\n                \"default\": \"gpt-3.5-turbo\",\r\n                \"name\": \"æ¨¡å‹åç§°\",\r\n                \"required\": false,\r\n                \"typing\": \"string\"\r\n            }\r\n        }\r\n    },\r\n    {\r\n        \"enter_id\": \"QwenEnterPoint\",\r\n        \"name\": \"é€šä¹‰åƒé—®\",\r\n        \"parameters\": {\r\n            \"api_key\": {\r\n                \"default\": null,\r\n                \"name\": \"Token\",\r\n                \"required\": true,\r\n                \"typing\": \"string\"\r\n            },\r\n            \"model_name\": {\r\n                \"default\": \"qwen2-7b-instruct\",\r\n                \"name\": \"æ¨¡å‹åç§°\",\r\n                \"required\": false,\r\n                \"typing\": \"string\"\r\n            }\r\n        }\r\n    },\r\n    {\r\n        \"enter_id\": \"VLLMEnterPoint\",\r\n        \"name\": \"VLLM\",\r\n        \"parameters\": {\r\n            \"api_key\": {\r\n                \"default\": null,\r\n                \"name\": \"API KEY\",\r\n                \"required\": false,\r\n                \"typing\": \"string\"\r\n            },\r\n            \"base_url\": {\r\n                \"default\": null,\r\n                \"name\": \"Base URL\",\r\n                \"required\": true,\r\n                \"typing\": \"string\"\r\n            },\r\n            \"model_name\": {\r\n                \"default\": null,\r\n                \"name\": \"æ¨¡å‹åç§°\",\r\n                \"required\": true,\r\n                \"typing\": \"string\"\r\n            }\r\n        }\r\n    }\r\n]\r\n```"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 35,
    "title": "ğŸ‘‘ [éœ€æ±‚]èµ°å‘å›½é™…åŒ–ï¼Œgithubé¦–é¡µåŠæ–‡æ¡£å¢åŠ è‹±æ–‡",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-15T01:20:51Z",
    "updated_at": "2025-03-03T09:39:48Z",
    "labels": [
      "documentation"
    ],
    "body": "rt",
    "comments": [
      {
        "user": "FredaZero",
        "body": "æˆ‘æ˜å¤©æä¸€ç‰ˆå‡ºæ¥"
      },
      {
        "user": "yuruotong1",
        "body": "> æˆ‘æ˜å¤©æä¸€ç‰ˆå‡ºæ¥\n\næ„Ÿè°¢ pr"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 44,
    "title": "ğŸ›[BUG] ERROR  Could not resolve \"./shortcut\" from \"src/main/index.ts\"",
    "author": "changye-chen",
    "state": "closed",
    "created_at": "2024-08-10T09:00:09Z",
    "updated_at": "2025-03-03T09:39:41Z",
    "labels": [],
    "body": "### ğŸ› bug æè¿°\r\n\r\n<!--\r\nè¯¦ç»†åœ°æè¿° bugï¼Œè®©å¤§å®¶éƒ½èƒ½ç†è§£\r\n-->\r\nå‰ç«¯å¯åŠ¨å¤±è´¥ï¼ŒåŸå› åœ¨äºindex.tsä¸­shortCutå†™æˆäº†shortcut\r\n### ğŸ“· å¤ç°æ­¥éª¤\r\n\r\n<!--\r\næ¸…æ™°æè¿°å¤ç°æ­¥éª¤ï¼Œè®©åˆ«äººä¹Ÿèƒ½çœ‹åˆ°é—®é¢˜\r\n-->\r\n\r\n### ğŸ æœŸæœ›ç»“æœ\r\n\r\n<!--\r\næè¿°ä½ åŸæœ¬æœŸæœ›çœ‹åˆ°çš„ç»“æœ\r\n-->\r\n\r\n### ğŸ’» å¤ç°ä»£ç \r\n\r\n<!--\r\næä¾›å¯å¤ç°çš„ä»£ç ï¼Œä»“åº“ï¼Œæˆ–çº¿ä¸Šç¤ºä¾‹\r\n(å¯åœ¨ä¸‹æ–¹ codesandbox é“¾æ¥ä¸­æ·»åŠ ä½ çš„æœ€å°å¯å¤ç° demo)\r\n-->\r\n\r\n[å¯å¤ç° demo](https://codesandbox.io/s/html2ksetch-demo-m53be?file=/src/Demo.tsx)\r\n\r\n### Â© ç‰ˆæœ¬ä¿¡æ¯\r\n\r\n- @yuruotong1/autoMate ç‰ˆæœ¬: [e.g. 1.0.0]\r\n- æµè§ˆå™¨ç¯å¢ƒ\r\n- å¼€å‘ç¯å¢ƒ [e.g. mac OS]\r\n\r\n### ğŸš‘ å…¶ä»–ä¿¡æ¯\r\n\r\n<!--\r\nå¦‚æˆªå›¾ç­‰å…¶ä»–ä¿¡æ¯å¯ä»¥è´´åœ¨è¿™é‡Œ\r\n-->",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "æ„Ÿè°¢æä¾›åé¦ˆï¼"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 46,
    "title": "ğŸ§[é—®é¢˜]Missing Activation Script of Backend in Readme",
    "author": "Gushroom",
    "state": "closed",
    "created_at": "2024-09-04T13:55:01Z",
    "updated_at": "2025-03-03T09:39:32Z",
    "labels": [],
    "body": "### ğŸ§ é—®é¢˜æè¿°\r\n\r\nMissing Activation Script of Backend in Readme\r\nFollowing the steps in Readme will install python dependencies in root pip, which is not the expected behavior.\r\n\r\n### ğŸ’» ç¤ºä¾‹ä»£ç \r\n\r\n<img width=\"414\" alt=\"image\" src=\"https://github.com/user-attachments/assets/12f4aaf0-6254-44bf-b4e2-2b7dc21f19d2\">\r\n",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "yes, thank you remind!"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 45,
    "title": "ğŸ§[é—®é¢˜]would it be possible to have a direct download link without going through github I have too many problems installing that I can't solve, is there any method?",
    "author": "RaffaeleCazzorla98",
    "state": "closed",
    "created_at": "2024-08-23T09:53:37Z",
    "updated_at": "2025-03-03T09:39:25Z",
    "labels": [],
    "body": "### ğŸ§ é—®é¢˜æè¿°\r\n\r\n<!--\r\nè¯¦ç»†åœ°æè¿°é—®é¢˜ï¼Œè®©å¤§å®¶éƒ½èƒ½ç†è§£\r\n-->\r\n\r\n### ğŸ’» ç¤ºä¾‹ä»£ç \r\n\r\n<!--\r\nå¦‚æœæœ‰å¿…è¦ï¼Œå±•ç¤ºä»£ç ï¼Œçº¿ä¸Šç¤ºä¾‹ï¼Œæˆ–ä»“åº“\r\n-->\r\n\r\n### ğŸš‘ å…¶ä»–ä¿¡æ¯\r\n\r\n<!--\r\nå¦‚æˆªå›¾ç­‰å…¶ä»–ä¿¡æ¯å¯ä»¥è´´åœ¨è¿™é‡Œ\r\n-->",
    "comments": [
      {
        "user": "yuruotong1",
        "body": "sorry, only can download by  github.I can send you exe by weixin or feishu, do you have these app?"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 7,
    "title": "ğŸ‘‘ [éœ€æ±‚]åœ¨æœç´¢æ¡†æ£€ç´¢åˆ°ä»£ç æ ‡é¢˜åè¾“å…¥å›è½¦ï¼Œç›´æ¥æ‰§è¡Œä»£ç è€Œä¸æ˜¯è·³è½¬åˆ°ä»£ç ç¼–è¾‘é¡µé¢",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:21:16Z",
    "updated_at": "2024-07-24T02:08:19Z",
    "labels": [
      "enhancement"
    ],
    "body": null,
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 19,
    "title": "ğŸ‘‘ [éœ€æ±‚] æ™ºå­åŠ©æ‰‹å›¾æ ‡ä¸‹æ–¹å¢åŠ æ–‡å­—",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T10:22:34Z",
    "updated_at": "2024-07-16T03:14:26Z",
    "labels": [
      "enhancement"
    ],
    "body": "<img width=\"251\" alt=\"5debe07bda6b8b9c7fa302633c9b2cbf_\" src=\"https://github.com/yuruotong1/autoMate/assets/31992251/701676a8-ab27-4ce2-bf42-9641b8ab6f6b\">",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 18,
    "title": "ğŸ‘‘ [éœ€æ±‚]å¢åŠ æ‚¬æµ®æ˜¾ç¤ºâ€œç¼–è¾‘ä»£ç â€",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T10:21:44Z",
    "updated_at": "2024-07-16T03:03:31Z",
    "labels": [
      "enhancement"
    ],
    "body": "<img width=\"597\" alt=\"1ba925961ebeb98388218c739811f6c3_\" src=\"https://github.com/yuruotong1/autoMate/assets/31992251/21390713-553c-4417-91b3-17db74d8db7e\">",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 5,
    "title": "ğŸ‘‘ [éœ€æ±‚]ä¸æ™ºå­å¯¹è¯ï¼Œèƒ½å¤Ÿå¯¹å·²æœ‰ä»£ç è¿›è¡Œä¿®æ”¹ï¼Œè€Œä¸æ˜¯é‡æ–°ç”Ÿæˆä»£ç ",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:18:47Z",
    "updated_at": "2024-07-15T02:01:38Z",
    "labels": [
      "enhancement"
    ],
    "body": null,
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 14,
    "title": "ğŸ‘‘ [éœ€æ±‚]è‡ªåŠ¨æ›´æ–°æ—¶ï¼ŒåŠ å…¥åŠ è½½è¿›åº¦ç•Œé¢",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-09T12:50:03Z",
    "updated_at": "2024-07-15T02:01:36Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 24,
    "title": "ğŸ‘‘ [éœ€æ±‚]å³ä¸‹è§’æ‰˜ç›˜å³é”®å¢åŠ â€œå…³äºâ€ï¼Œå¯æŸ¥çœ‹å½“å‰è½¯ä»¶ç‰ˆæœ¬",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T15:16:56Z",
    "updated_at": "2024-07-15T02:01:19Z",
    "labels": [
      "enhancement"
    ],
    "body": "![image](https://github.com/yuruotong1/autoMate/assets/31992251/1970522d-8f08-4575-a290-cfb609659cde)",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 9,
    "title": "ğŸ‘‘ [éœ€æ±‚]æ™ºå­ç”Ÿæˆä»£ç åï¼Œåœ¨å…¶å³ä¸Šè§’åŠ å…¥è¿è¡ŒæŒ‰é’®",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T23:33:58Z",
    "updated_at": "2024-07-15T01:51:08Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 25,
    "title": "ğŸ‘‘ [éœ€æ±‚]ææ¸…æ¥šå¯åŠ¨æ—¶ä¸ºä»€ä¹ˆä¼šå‡ºç°5ä¸ªautoMate.exeå’Œ2ä¸ªautoMateServer.exeè¿›ç¨‹",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T15:40:21Z",
    "updated_at": "2024-07-13T23:29:12Z",
    "labels": [
      "bug"
    ],
    "body": "![f86ebb6f25594b7ed639255587300c2](https://github.com/yuruotong1/autoMate/assets/31992251/c04ab471-4fb4-49f6-a47c-9f88385e69b1)",
    "comments": [
      {
        "user": "xujiajiadexiaokeai",
        "body": "![automate-screenshot](https://github.com/yuruotong1/autoMate/assets/30225423/e4d124fa-4584-4661-91a2-73e198bf973c)\r\nè¿™è¾¹çœ‹ä¸‹æ¥åº”è¯¥æ˜¯é€šè¿‡Electronæ¡†æ¶å¼•å…¥çš„,ç±»ä¼¼Chromium,æœ‰`gpu-process`ã€`utility`ã€`renderer`è¿™äº›è¿›ç¨‹.\r\nå¯ä»¥é€šè¿‡[process-explorer](https://learn.microsoft.com/en-us/sysinternals/downloads/process-explorer)è¿™ä¸ªå·¥å…·æ¥çœ‹åˆ°è¿›ç¨‹çš„å…·ä½“ä¿¡æ¯.\r\nå¸Œæœ›å¯¹è¿™ä¸ªé—®é¢˜èƒ½æœ‰äº›å¸®åŠ©..."
      },
      {
        "user": "yuruotong1",
        "body": "> ![automate-screenshot](https://private-user-images.githubusercontent.com/30225423/347862398-e4d124fa-4584-4661-91a2-73e198bf973c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3OTY0MzMsIm5iZiI6MTcyMDc5NjEzMywicGF0aCI6Ii8zMDIyNTQyMy8zNDc4NjIzOTgtZTRkMTI0ZmEtNDU4NC00NjYxLTkxYTItNzNlMTk4YmY5NzNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzEyVDE0NTUzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWU2YTBiMzgwYzEwZGVjYjFkMTFjNDkxNWFiYmMwODM0MDk2ODA5MGE5MGUwY2QwNDdmNTBkN2RlMTM3MDE0YmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lo0NM51a_q8oPpVjnRxplhtpeqyde4dbc_4pqbnlUkk) è¿™è¾¹çœ‹ä¸‹æ¥åº”è¯¥æ˜¯é€šè¿‡Electronæ¡†æ¶å¼•å…¥çš„,ç±»ä¼¼Chromium,æœ‰`gpu-process`ã€`utility`ã€`renderer`è¿™äº›è¿›ç¨‹. å¯ä»¥é€šè¿‡[process-explorer](https://learn.microsoft.com/en-us/sysinternals/downloads/process-explorer)è¿™ä¸ªå·¥å…·æ¥çœ‹åˆ°è¿›ç¨‹çš„å…·ä½“ä¿¡æ¯. å¸Œæœ›å¯¹è¿™ä¸ªé—®é¢˜èƒ½æœ‰äº›å¸®åŠ©...\r\n\r\nç›®å‰æ¥çœ‹åº”è¯¥ä¸å½±å“ä½¿ç”¨ï¼Œæ„Ÿè°¢æä¾›çº¿ç´¢ï¼è¿™æ˜¯ä¸æ˜¯electronçš„æ­£å¸¸æœºåˆ¶å‘€"
      },
      {
        "user": "xujiajiadexiaokeai",
        "body": "> > ![automate-screenshot](https://private-user-images.githubusercontent.com/30225423/347862398-e4d124fa-4584-4661-91a2-73e198bf973c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3OTY0MzMsIm5iZiI6MTcyMDc5NjEzMywicGF0aCI6Ii8zMDIyNTQyMy8zNDc4NjIzOTgtZTRkMTI0ZmEtNDU4NC00NjYxLTkxYTItNzNlMTk4YmY5NzNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzEyVDE0NTUzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWU2YTBiMzgwYzEwZGVjYjFkMTFjNDkxNWFiYmMwODM0MDk2ODA5MGE5MGUwY2QwNDdmNTBkN2RlMTM3MDE0YmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lo0NM51a_q8oPpVjnRxplhtpeqyde4dbc_4pqbnlUkk) è¿™è¾¹çœ‹ä¸‹æ¥åº”è¯¥æ˜¯é€šè¿‡Electronæ¡†æ¶å¼•å…¥çš„,ç±»ä¼¼Chromium,æœ‰`gpu-process`ã€`utility`ã€`renderer`è¿™äº›è¿›ç¨‹. å¯ä»¥é€šè¿‡[process-explorer](https://learn.microsoft.com/en-us/sysinternals/downloads/process-explorer)è¿™ä¸ªå·¥å…·æ¥çœ‹åˆ°è¿›ç¨‹çš„å…·ä½“ä¿¡æ¯. å¸Œæœ›å¯¹è¿™ä¸ªé—®é¢˜èƒ½æœ‰äº›å¸®åŠ©...\r\n> \r\n> ç›®å‰æ¥çœ‹åº”è¯¥ä¸å½±å“ä½¿ç”¨ï¼Œæ„Ÿè°¢æä¾›çº¿ç´¢ï¼è¿™æ˜¯ä¸æ˜¯electronçš„æ­£å¸¸æœºåˆ¶å‘€\r\n\r\næ˜¯çš„ï¼Œæ˜¯Electroné¡¹ç›®æ­£å¸¸çš„è¿›ç¨‹æ¶æ„æ¨¡å‹"
      }
    ],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 20,
    "title": "ğŸ‘‘ [éœ€æ±‚]é…ç½®å¤§æ¨¡å‹çš„æŠ¥é”™ä¿¡æ¯æ›´è¯¦ç»†",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-10T11:33:24Z",
    "updated_at": "2024-07-10T14:42:45Z",
    "labels": [
      "enhancement"
    ],
    "body": "ç›®å‰åªæœ‰ä¸€ä¸ªTypeErrorï¼ŒæœŸæœ›åŠ å…¥æ›´å¤šçš„æŠ¥é”™ä¿¡æ¯ï¼š\r\n\r\n![83d0144eb6540c03a70aff64099dff1](https://github.com/yuruotong1/autoMate/assets/31992251/b3f2799a-3c2e-4ea9-98be-ac4e437d34e5)\r\n",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 8,
    "title": "ğŸ‘‘ [éœ€æ±‚]æ£€æµ‹æ›´æ–°åè‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€é‡æ–°ä¸‹è½½exe",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:33:31Z",
    "updated_at": "2024-07-09T12:36:55Z",
    "labels": [
      "enhancement"
    ],
    "body": "rt",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 13,
    "title": "ğŸ‘‘ [éœ€æ±‚]æŠŠé€šä¹‰åƒé—®è®¾ç½®ä¸ºé»˜è®¤æ¨¡å‹",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-08T04:45:46Z",
    "updated_at": "2024-07-08T08:43:36Z",
    "labels": [
      "enhancement"
    ],
    "body": "![e576ed963c90fdab23cf179ba03cac1](https://github.com/yuruotong1/autoMate/assets/31992251/c15632d5-f074-418a-899e-6f6bd1c5b97a)",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 6,
    "title": "ğŸ‘‘ [éœ€æ±‚]åœ¨æœç´¢æ¡†è¾“å…¥å†…å®¹ï¼ŒæŒ‰ä¸‹å›è½¦å¯ç›´æ¥ä¸æ™ºå­å¯¹è¯",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:20:02Z",
    "updated_at": "2024-07-05T10:59:15Z",
    "labels": [
      "enhancement"
    ],
    "body": null,
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 4,
    "title": "ğŸ‘‘ [éœ€æ±‚]é…ç½®LLMç”±jsonè¾“å…¥æ”¹ä¸ºè¾“å…¥æ¡†ï¼ŒåŠ å…¥å–æ¶ˆä¿å­˜æŒ‰é’®",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:17:41Z",
    "updated_at": "2024-07-05T10:59:15Z",
    "labels": [
      "enhancement"
    ],
    "body": "RT",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  },
  {
    "issue_number": 3,
    "title": "ğŸ‘‘ [éœ€æ±‚]é…ç½®LLMçš„åœ°æ–¹å¢åŠ æ ¡éªŒ",
    "author": "yuruotong1",
    "state": "closed",
    "created_at": "2024-07-05T02:16:53Z",
    "updated_at": "2024-07-05T10:59:14Z",
    "labels": [
      "enhancement"
    ],
    "body": "RT",
    "comments": [],
    "repository": "yuruotong1/autoMate"
  }
]