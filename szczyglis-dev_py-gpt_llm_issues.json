[
  {
    "issue_number": 100,
    "title": "Feature request: Update Bielik to v2.3",
    "author": "lukasz-pekala",
    "state": "closed",
    "created_at": "2025-03-16T10:32:32Z",
    "updated_at": "2025-06-21T22:52:38Z",
    "labels": [],
    "body": "Updating to SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 115,
    "title": "Program start error",
    "author": "apatagon",
    "state": "open",
    "created_at": "2025-06-12T14:49:25Z",
    "updated_at": "2025-06-12T14:49:25Z",
    "labels": [],
    "body": "Operating System: EndeavourOS \nKDE Plasma Version: 6.3.5\nKDE Frameworks Version: 6.14.0\nQt Version: 6.9.1\nKernel Version: 6.14.10-arch1-1 (64-bit)\nGraphics Platform: Wayland\n\ninstall was successful\n\nprogram start fails:\n\npygpt\n\n```\nFile \"/home/XXX/PyGPT/PyGPT/lib/python3.13/site-packages/pygpt_net/ui/layout/chat/painter.py\", line 14, in <module>\n    from pygpt_net.ui.widget.draw.painter import PainterWidget\nModuleNotFoundError: No module named 'pygpt_net.ui.widget.draw'\n```\n",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 114,
    "title": "How to activate speech synthesis from Google and ElevenLabs?",
    "author": "3bagorion33",
    "state": "open",
    "created_at": "2025-06-04T14:00:14Z",
    "updated_at": "2025-06-04T14:00:14Z",
    "labels": [],
    "body": "Is there an adequate manual here? The description says that you can connect speech synthesis from Google and ElevenLabs. Where the hell do you do that?",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 113,
    "title": "Voice Control error when not using Chat Api",
    "author": "KingOfTheCastle",
    "state": "open",
    "created_at": "2025-05-23T16:42:06Z",
    "updated_at": "2025-05-23T16:42:06Z",
    "labels": [],
    "body": "When using out the global voice controls, there is an exception when using local voice control that seems to prevent any commands from working :\n\n> \n> 2025-05-23 16:52:02,149 - INFO - [event] Dispatch begin: KernelEvent: kernel.call (193)\n> 2025-05-23 16:52:02,149 - DEBUG - [event] Before handle: \n> 2025-05-23 16:52:02,149 - INFO - [bridge] Call...\n> 2025-05-23 16:52:02,149 - DEBUG - {'assistant_id': '', 'attachments': '[]', 'ctx': 'None', 'external_functions': '[]', 'file_ids': '[]', 'history': '0', 'idx': 'None', 'idx_mode': 'chat', 'max_tokens': '0', 'mode': 'None', 'model': \"{'id': 'llama3.1', 'name': 'llama3.1', 'mode': 'langchain,llama_index,agent,agent_llama,expert', 'langchain': {'provider': 'ollama', 'mode': ['chat'], 'args': [{'name': 'model', 'value': 'llama3.1', 'type': 'str'}], 'env': []}, 'ctx': 128000, 'tokens': 4096, 'default': False, 'multimodal': '', 'extra': {}, 'langchain.provider': 'ollama', 'langchain.mode': 'chat', 'langchain.args': [{'name': 'model', 'value': 'llama3.1', 'type': 'str'}], 'langchain.env': [], 'llama_index.provider': 'ollama', 'llama_index.mode': 'chat', 'llama_index.args': [{'name': 'model', 'value': 'llama3.1', 'type': 'str'}], 'llama_index.env': []}\", 'parent_mode': 'None', 'prompt': 'Recognize the voice command and select the corresponding command from the list below. \\n        Return the chosen command ID as a JSON string in the following syntax:\\n\\n        {\"cmd\": \"command_id\", \"params\": \"optional message\"}\\n        \\n        If no command matches the voice request, then return \"unknown\" as the command ID.\\n        If user provide additional message, it should be extracted from voice command and included (WITHOUT the command part) in the JSON response in \"params\" param.\\n        \\n        Important: Only the JSON specified above should be returned in the response, without any additional text.\\n        \\n        Available command IDs (with descriptions):\\n        ----------------------\\n        app.status = Get the current application status\\napp.exit = Exit the application\\naudio.output.enable = Enable audio output\\naudio.output.disable = Disable audio output\\naudio.input.enable = Enable audio input\\naudio.input.disable = Disable audio input\\ncalendar.add = Add a memo to the calendar\\ncalendar.clear = Clear memos from calendar\\ncalendar.read = Read the calendar memos\\ncamera.enable = Enable the camera\\ncamera.disable = Disable the camera\\ncamera.capture = Capture image from camera\\ncmd.confirm = Confirmation of the command\\ncmd.list = Get available commands list\\nctx.new = Create a new context\\nctx.prev = Go to the previous context\\nctx.next = Go to the next context\\nctx.last = Go to the latest context\\nctx.input.focus = Focus on the input\\nctx.input.send = Send the input\\nctx.input.clear = Clear the input\\nctx.current = Get current conversation info\\nctx.stop = Stop executing current action\\nctx.attachments.clear = Clear the attachments\\nctx.read.last = Read the last conversation entry\\nctx.read.all = Read the whole conversation\\nctx.rename = Rename current context\\nctx.search.string = Search for a conversation\\nctx.search.clear = Clear the search results\\ninput.send = Send the message to input\\ninput.append = Append message to current input without sending it\\nmode.chat = Switch to Chat mode\\nmode.llama_index = Switch to Chat with Files (LlamaIndex) mode\\nmode.next = Switch to the next mode\\nmode.prev = Switch to the previous mode\\nmodel.next = Switch to the next model\\nmodel.prev = Switch to the previous model\\nnote.add = Add note to notepad\\nnotepad.clear = Clear notepad contents\\nnotepad.read = Read current notepad contents\\npreset.next = Switch to the next preset\\npreset.prev = Switch to the previous preset\\ntab.chat = Switch to the chat tab\\ntab.calendar = Switch to the calendar tab\\ntab.draw = Switch to the draw (painter) tab\\ntab.files = Switch to the files tab\\ntab.notepad = Switch to the notepad tab\\ntab.next = Switch to the next tab\\ntab.prev = Switch to the previous tab\\nvoice_msg.start = Start listening for voice input\\nvoice_msg.stop = Stop listening for voice input\\nvoice_msg.toggle = Toggle listening for voice input        \\n        \\n        User\\'s voice input to recognize:\\n        \\n         Create a new context.', 'stream': 'False', 'system_prompt': 'You are a helpful assistant', 'system_prompt_raw': '', 'temperature': '0.0', 'thread_id': '', 'tools_outputs': '[]'}\n> 2025-05-23 16:52:02,149 - ERROR - Uncaught exception:\n> Traceback (most recent call last):\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/controller/access/voice.py\", line 358, in handle_input\n>     commands = self.window.core.access.voice.recognize_commands(text)\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/core/access/voice.py\", line 235, in recognize_commands\n>     self.window.dispatch(event)\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/ui/main.py\", line 261, in dispatch\n>     self.core.dispatcher.dispatch(event, all=all)\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/core/dispatcher/__init__.py\", line 65, in dispatch\n>     self.window.controller.kernel.handle(event)\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/controller/kernel/__init__.py\", line 103, in handle\n>     response = self.queue(context, extra, event)\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/controller/kernel/__init__.py\", line 182, in queue\n>     return self.call(context, extra, event)\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/controller/kernel/__init__.py\", line 206, in call\n>     return self.window.core.bridge.call(context, extra)\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n>   File \"/home/eamon/anaconda3/envs/pygpt/lib/python3.12/site-packages/pygpt_net/core/bridge/__init__.py\", line 205, in call\n>     ctx.input = context.prompt\n>     ^^^^^^^^^\n> AttributeError: 'NoneType' object has no attribute 'input'\n\nThe error coming from the file pygpt_net/core/bridge/__init__.py where there is no ctx provided, and as far as I can tell it can't be provided at least for voice. This path is skipped when using Chat Api.\n\nI did get it working locally by passing an empty CtxItem in the relevant file, core/access/voice.py, though I can't say if that's the correct change to make.\n\n```\nfrom pygpt_net.item.ctx import CtxItem\n        ....\n        ....\n        ....\n        ctx = CtxItem() <----\n        bridge_context = BridgeContext(\n            ctx=ctx,< ----\n            prompt=prompt,\n            system_prompt=\"You are a helpful assistant\",\n            model=model,  # model instance\n            max_tokens=0,\n            temperature=0.0,\n        )\n```\nAfter this change, some voice commands started to work.\n\nThe build is \nVersion: 2.5.10, Linux, x86_64\nBuild: 2025-03-06\nOpenAI API: 1.59.7, LangChain: 0.2.17, LlamaIndex: 0.12.22\n\nwith local models, pip install, ollama3.1, chat with files, local whisper, python 3.12",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 106,
    "title": "Installation for snap, pip and git causing errors",
    "author": "T-vK",
    "state": "open",
    "created_at": "2025-04-03T15:02:02Z",
    "updated_at": "2025-05-21T06:22:09Z",
    "labels": [],
    "body": "I'm on Manjaro Linux and I get errors no matter which way I try to install py-gpt.\n\n\nWith snap I get:\n\n```\n$ pygpt\nTraceback (most recent call last):\n  File \"/snap/pygpt/368/src/pygpt_net/app.py\", line 52, in <module>\n    from pygpt_net.provider.llms.google import GoogleLLM\n  File \"/snap/pygpt/368/src/pygpt_net/provider/llms/google.py\", line 14, in <module>\n    from llama_index.llms.gemini import Gemini\n  File \"/snap/pygpt/368/lib/python3.10/site-packages/llama_index/llms/gemini/__init__.py\", line 1, in <module>\n    from llama_index.llms.gemini.base import Gemini\n  File \"/snap/pygpt/368/lib/python3.10/site-packages/llama_index/llms/gemini/base.py\", line 18, in <module>\n    import google.generativeai as genai\n  File \"/snap/pygpt/368/lib/python3.10/site-packages/google/generativeai/__init__.py\", line 54, in <module>\n    from google.generativeai.files import upload_file\n  File \"/snap/pygpt/368/lib/python3.10/site-packages/google/generativeai/files.py\", line 32, in <module>\n    mimetypes.add_type(\"image/webp\", \".webp\")\n  File \"/usr/lib/python3.10/mimetypes.py\", line 356, in add_type\n    init()\n  File \"/usr/lib/python3.10/mimetypes.py\", line 379, in init\n    db.read(file)\n  File \"/usr/lib/python3.10/mimetypes.py\", line 209, in read\n    with open(filename, encoding='utf-8') as fp:\nPermissionError: [Errno 13] Permission denied: '/etc/httpd/conf/mime.types'\n```\n\n\nWith pip I get:\n```\n$ pygpt\nTraceback (most recent call last):\n  File \"/home/tvk/Projects/github/pygpt/venv/bin/pygpt\", line 5, in <module>\n    from pygpt_net.app import run\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/app.py\", line 22, in <module>\n    from pygpt_net.controller import Controller\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/controller/__init__.py\", line 17, in <module>\n    from pygpt_net.controller.chat import Chat\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/controller/chat/__init__.py\", line 17, in <module>\n    from pygpt_net.controller.chat.render import Render\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/controller/chat/render.py\", line 13, in <module>\n    from pygpt_net.core.render.markdown.renderer import Renderer as MarkdownRenderer\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/core/render/markdown/renderer.py\", line 18, in <module>\n    from pygpt_net.ui.widget.textarea.input import ChatInput\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/ui/__init__.py\", line 19, in <module>\n    from pygpt_net.ui.layout.chat import ChatMain\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/ui/layout/chat/__init__.py\", line 16, in <module>\n    from pygpt_net.ui.layout.chat.output import Output\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/ui/layout/chat/output.py\", line 19, in <module>\n    from pygpt_net.ui.layout.chat.painter import Painter\n  File \"/home/tvk/Projects/github/pygpt/venv/lib/python3.13/site-packages/pygpt_net/ui/layout/chat/painter.py\", line 14, in <module>\n    from pygpt_net.ui.widget.draw.painter import PainterWidget\nModuleNotFoundError: No module named 'pygpt_net.ui.widget.draw'\n```\n\nUsing git I get:\n\n```\n$ pip install -r requirements.txt\nIgnoring aiohappyeyeballs: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring aiohttp: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring aiosignal: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring annotated-types: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring anthropic: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring anyio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring appnope: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and platform_system == \"Darwin\"' don't match your environment\nIgnoring asgiref: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring asttokens: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring async-timeout: markers 'python_version >= \"3.10\" and python_full_version < \"3.11.3\"' don't match your environment\nIgnoring attrs: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring azure-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring azure-identity: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring backoff: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring bcrypt: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring beautifulsoup4: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring bleach: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring boto3: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring botocore: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring build: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring cachetools: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring certifi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring cffi: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (implementation_name == \"pypy\" or platform_python_implementation != \"PyPy\" or os_name == \"nt\")' don't match your environment\nIgnoring charset-normalizer: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring chroma-hnswlib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring chromadb: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring chromedriver-autoinstaller: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring click: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring colorama: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (os_name == \"nt\" or platform_system == \"Windows\" or sys_platform == \"win32\")' don't match your environment\nIgnoring coloredlogs: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring comm: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring croniter: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring cryptography: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring cssselect: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring dataclasses-json: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring debugpy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring decorator: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring defusedxml: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring deprecated: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring dirtyjson: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring distro: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring docker: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring docx2txt: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring durationpy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ebooklib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring elastic-transport: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring elasticsearch: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring evdev: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and sys_platform in \"linux\"' don't match your environment\nIgnoring exceptiongroup: markers 'python_version >= \"3.10\" and python_version < \"3.11\"' don't match your environment\nIgnoring executing: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring fastapi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring fastjsonschema: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring feedfinder2: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring feedparser: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring filelock: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring filetype: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring flatbuffers: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring frozenlist: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring fsspec: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring future: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring gkeepapi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-ai-generativelanguage: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-api-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-api-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-api-python-client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-auth-httplib2: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-auth-oauthlib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-auth: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring google-generativeai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring googleapis-common-protos: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring gpsoauth: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring greenlet: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring grpcio-status: markers 'python_version < \"3.13\" and python_version >= \"3.10\"' don't match your environment\nIgnoring grpcio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring h11: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring html2text: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring httpcore: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring httplib2: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring httptools: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring httpx-socks: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring httpx: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring huggingface-hub: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring huggingface-hub: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring humanfriendly: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring idna: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring importlib-metadata: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring importlib-resources: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ipykernel: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ipython: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jedi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jieba3k: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jinja2: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jiter: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jmespath: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring joblib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jsonpatch: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jsonpointer: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jsonschema-specifications: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jsonschema: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jupyter-client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jupyter-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring jupyterlab-pygments: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring kubernetes: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain-community: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain-experimental: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain-text-splitters: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langchain: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring langsmith: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-cloud: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-agent-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-cli: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-embeddings-azure-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-embeddings-gemini: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-embeddings-huggingface-api: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-embeddings-ollama: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-embeddings-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-indices-managed-llama-cloud: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-anthropic: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-azure-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-deepseek: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-gemini: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-huggingface-api: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-ollama: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-openai-like: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-llms-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-multi-modal-llms-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-program-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-question-gen-openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-chatgpt-plugin: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-database: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-file: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-github: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-google: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-llama-parse: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-microsoft-onedrive: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-twitter: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-readers-web: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-utils-huggingface: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-vector-stores-chroma: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-vector-stores-elasticsearch: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-vector-stores-pinecone: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index-vector-stores-redis: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-index: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring llama-parse: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring lxml: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring markdown-it-py: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring markdown: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring markupsafe: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring marshmallow: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring matplotlib-inline: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mdurl: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mistune: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ml-dtypes: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mmh3: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring monotonic: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mouseinfo: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mpmath: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring msal-extensions: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring msal: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mss: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring multidict: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring mypy-extensions: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring nbclient: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring nbconvert: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring nbformat: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring nest-asyncio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring networkx: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring newspaper3k: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring nltk: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring numpy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring oauth2client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring oauthlib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ollama: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring onnxruntime: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring openai: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opencv-python: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-api: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-exporter-otlp-proto-common: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-exporter-otlp-proto-grpc: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-instrumentation-asgi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-instrumentation-fastapi: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-instrumentation: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-proto: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-sdk: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-semantic-conventions: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring opentelemetry-util-http: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring orjson: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring outcome: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring overrides: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring packaging: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pandas: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pandocfilters: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring parso: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pexpect: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (sys_platform != \"win32\" and sys_platform != \"emscripten\")' don't match your environment\nIgnoring pillow: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pinecone-client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring platformdirs: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring playwright: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring portalocker: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring posthog: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring prompt-toolkit: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring propcache: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring proto-plus: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring protobuf: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring psutil: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring ptyprocess: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (sys_platform != \"win32\" and sys_platform != \"emscripten\")' don't match your environment\nIgnoring pure-eval: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyasn1-modules: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyasn1: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyaudio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyautogui: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pycparser: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (implementation_name == \"pypy\" or platform_python_implementation != \"PyPy\" or os_name == \"nt\")' don't match your environment\nIgnoring pycryptodomex: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pydantic-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pydantic: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pydrive: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pydub: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyee: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pygame: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pygetwindow: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pygments: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyjwt: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pymsgbox: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pynput: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyobjc-core: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (platform_system == \"Darwin\" or sys_platform == \"darwin\")' don't match your environment\nIgnoring pyobjc-framework-applicationservices: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and sys_platform == \"darwin\"' don't match your environment\nIgnoring pyobjc-framework-cocoa: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (platform_system == \"Darwin\" or sys_platform == \"darwin\")' don't match your environment\nIgnoring pyobjc-framework-coretext: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and sys_platform == \"darwin\"' don't match your environment\nIgnoring pyobjc-framework-quartz: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (platform_system == \"Darwin\" or sys_platform == \"darwin\")' don't match your environment\nIgnoring pyparsing: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pypdf: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyperclip: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pypika: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyproject-hooks: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyreadline3: markers 'sys_platform == \"win32\" and python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyrect: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyscreeze: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyserial: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyside6-addons: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyside6-essentials: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyside6: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pysocks: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring python-dateutil: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring python-dotenv: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring python-markdown-math: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring python-socks: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring python-xlib: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and sys_platform in \"linux\"' don't match your environment\nIgnoring python3-xlib: markers 'platform_system == \"Linux\" and python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pytweening: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pytz: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pywin32: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and (sys_platform == \"win32\" or platform_system == \"Windows\")' don't match your environment\nIgnoring pyxdg: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and platform_system == \"Linux\"' don't match your environment\nIgnoring pyyaml: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring pyzmq: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring qt-material: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring redis: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring redisvl: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring referencing: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring regex: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring requests-file: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring requests-oauthlib: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring requests-toolbelt: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring requests: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring rich: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring rpds-py: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring rsa: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring rubicon-objc: markers 'python_version >= \"3.10\" and python_version < \"3.13\" and platform_system == \"Darwin\"' don't match your environment\nIgnoring s3transfer: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring safetensors: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring selenium: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sgmllib3k: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring shellingham: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring shiboken6: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring show-in-file-manager: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring six: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sniffio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sortedcontainers: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring soupsieve: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring speechrecognition: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring spider-client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sqlalchemy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sqlalchemy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring stack-data: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring starlette: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring striprtf: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring sympy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tabulate: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tenacity: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tiktoken: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tinycss2: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tinysegmenter: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tldextract: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tokenizers: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tomli: markers 'python_version >= \"3.10\" and python_version < \"3.11\"' don't match your environment\nIgnoring tornado: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tqdm: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring traitlets: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring transformers: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring trio-websocket: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring trio: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tweepy: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring typer: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring typing-extensions: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring typing-inspect: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring tzdata: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring uritemplate: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring urllib3: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring urllib3: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring uvicorn: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring uvloop: markers '(sys_platform != \"win32\" and sys_platform != \"cygwin\") and platform_python_implementation != \"PyPy\" and python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring watchfiles: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring wcwidth: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring webencodings: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring websocket-client: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring websockets: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring wikipedia: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring wrapt: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring wsproto: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring yarl: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring youtube-transcript-api: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\nIgnoring zipp: markers 'python_version >= \"3.10\" and python_version < \"3.13\"' don't match your environment\n\n$ python3 run.py\nTraceback (most recent call last):\n  File \"/home/tvk/Projects/github/py-gpt/run.py\", line 17, in <module>\n    from pygpt_net.app import run\n  File \"/home/tvk/Projects/github/py-gpt/src/pygpt_net/app.py\", line 17, in <module>\n    from pygpt_net.launcher import Launcher\n  File \"/home/tvk/Projects/github/py-gpt/src/pygpt_net/launcher.py\", line 17, in <module>\n    from PySide6 import QtCore\nModuleNotFoundError: No module named 'PySide6'\n```\n\nI'm on python 3.13 btw.",
    "comments": [
      {
        "user": "Hamza-b93",
        "body": "Can confirm. I tried re-installing pygpt via Snap but got a similar error:\n\n> Traceback (most recent call last):\n>   File \"/snap/pygpt/368/src/pygpt_net/app.py\", line 52, in <module>\n>     from pygpt_net.provider.llms.google import GoogleLLM\n>   File \"/snap/pygpt/368/src/pygpt_net/provider/llms/google.py\", line 14, in <module>\n>     from llama_index.llms.gemini import Gemini\n>   File \"/snap/pygpt/368/lib/python3.10/site-packages/llama_index/llms/gemini/__init__.py\", line 1, in <module>\n>     from llama_index.llms.gemini.base import Gemini\n>   File \"/snap/pygpt/368/lib/python3.10/site-packages/llama_index/llms/gemini/base.py\", line 18, in <module>\n>     import google.generativeai as genai\n>   File \"/snap/pygpt/368/lib/python3.10/site-packages/google/generativeai/__init__.py\", line 54, in <module>\n>     from google.generativeai.files import upload_file\n>   File \"/snap/pygpt/368/lib/python3.10/site-packages/google/generativeai/files.py\", line 32, in <module>\n>     mimetypes.add_type(\"image/webp\", \".webp\")\n>   File \"/usr/lib/python3.10/mimetypes.py\", line 356, in add_type\n>     init()\n>   File \"/usr/lib/python3.10/mimetypes.py\", line 379, in init\n>     db.read(file)\n>   File \"/usr/lib/python3.10/mimetypes.py\", line 209, in read\n>     with open(filename, encoding='utf-8') as fp:\n> PermissionError: [Errno 13] Permission denied: '/etc/httpd/conf/mime.types'\n"
      },
      {
        "user": "alr86",
        "body": "I also got the same error with pip"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 112,
    "title": "Deepseek api_key error 401",
    "author": "mandicus1975",
    "state": "open",
    "created_at": "2025-05-11T07:33:29Z",
    "updated_at": "2025-05-11T07:33:29Z",
    "labels": [],
    "body": "Dear all,\n\n\nI have been attempting to use the Deepseek platform AI and have entered my API key on the configuration page. However, when I try to utilize the service, I encounter the following error:\n\n\nError code: 401 - {'error': {'message': 'Authentication Fails, Your API key: ****eek} is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}\n\n\nIts worth noting that the last three digits, *eek, do not match my actual API key, which ends with *15b.\n\n\nCould you please advise me on the proper method for implementing the API key with the Deepseek platform? I appreciate your assistance and look forward to your insights!\n\n\nThank you!\n\nMauro",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 16,
    "title": "Mac Compilation",
    "author": "juato4",
    "state": "closed",
    "created_at": "2024-01-28T05:22:53Z",
    "updated_at": "2025-05-04T18:43:20Z",
    "labels": [
      "feature"
    ],
    "body": "I cant to it work on mac m1. ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, at this moment, there isn't a separate, compiled version for Mac (these are only for Linux and Windows, plus there is a Snap version for Linux). The only way on Mac is installing it from source code from the repository or by installing it using PyPI:\r\n\r\n```pip install pygpt-net```\r\n\r\nPyGPT uses `PySide6` as its GUI, which is supported on Python for Mac: https://www.pythonguis.com/installation/install-pyside6-mac/."
      },
      {
        "user": "juato4",
        "body": "Thanks. \r\n\r\nI am facing very issues on my entorn. \r\n\r\n> El 28 ene 2024, a las 11:41, Marcin Szczygliski ***@***.***> escribi:\r\n> \r\n> \r\n> Hi, at this moment, there isn't a separate, compiled version for Mac (these are only for Linux and Windows, plus there is a Snap version for Linux). The only way on Mac is installing it from source code from the repository or by installing it using PyPI:\r\n> \r\n> pip install pygpt-net\r\n> \r\n> PyGPT uses PySide6 as its GUI, which is supported on Python for Mac: https://www.pythonguis.com/installation/install-pyside6-mac/.\r\n> \r\n> \r\n> Reply to this email directly, view it on GitHub <https://github.com/szczyglis-dev/py-gpt/issues/16#issuecomment-1913619775>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AIRKH42UR5CDIHBKOGFGFIDYQZPQVAVCNFSM6AAAAABCN43GYSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMJTGYYTSNZXGU>.\r\n> You are receiving this because you authored the thread.\r\n> \r\n\r\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "I personally don't use a Mac, but could you provide more details about these issues? How exactly are you attempting to launch the app and what exactly is happening? It would be best if you could include all the logs that appear."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 111,
    "title": "error while getting the answer",
    "author": "jayesh-bhadani",
    "state": "open",
    "created_at": "2025-04-24T10:27:41Z",
    "updated_at": "2025-04-24T10:31:25Z",
    "labels": [],
    "body": "===================================================\n PyGPT    2.5.10 build 2025-03-06 (Windows, AMD64)\n Author:  Marcin Szczyglinski\n GitHub:  https://github.com/szczyglis-dev/py-gpt\n Website: https://pygpt.net\n Email:   info@pygpt.net\n===================================================\n\nInitializing...\nLoaded config: C:\\Users\\user1\\.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\user1\\.config\\pygpt-net\\models.json\nChecking for updates...\nNo updates available.\nType: APIConnectionErrorMessage: Connection error.\nTraceback:   File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1020, in _request\n  File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1030, in _request\n\nError in GPT quick call: Connection error.\n",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 99,
    "title": "Feature request: add MistralAI",
    "author": "toddy15",
    "state": "open",
    "created_at": "2025-03-13T23:13:57Z",
    "updated_at": "2025-04-15T17:54:20Z",
    "labels": [],
    "body": "Hi Marcin,\n\nthanks a lot for this great application! I'd love to have support for Mistral's API as well. From a quick check, llama_index seems to have integrated MistralAI already, so I hope that this new feature would be rather quick to implement.\n\nWould you consider adding an option to use their API with a key?\n\nRegards, \nTobias",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 102,
    "title": "ImportError: /usr/lib/libgssapi_krb5.so.2: undefined symbol: k5_buf_cstring, version krb5support_0_MIT",
    "author": "curtmgray",
    "state": "open",
    "created_at": "2025-03-19T15:22:08Z",
    "updated_at": "2025-04-15T17:53:35Z",
    "labels": [],
    "body": "Installed using pip install pygpt-net\n\nInstall seemed to complete without error however upon attempting to run I get the following...\n\n```\npygpt\nTraceback (most recent call last):\n  File \"/home/curt/venv/bin/pygpt\", line 5, in <module>\n    from pygpt_net.app import run\n  File \"/home/curt/venv/lib/python3.12/site-packages/pygpt_net/app.py\", line 17, in <module>\n    from pygpt_net.launcher import Launcher\n  File \"/home/curt/venv/lib/python3.12/site-packages/pygpt_net/launcher.py\", line 28, in <module>\n    from pygpt_net.ui.main import MainWindow\n  File \"/home/curt/venv/lib/python3.12/site-packages/pygpt_net/ui/main.py\", line 22, in <module>\n    from pygpt_net.container import Container\n  File \"/home/curt/venv/lib/python3.12/site-packages/pygpt_net/container.py\", line 17, in <module>\n    from pygpt_net.core.audio import Audio\n  File \"/home/curt/venv/lib/python3.12/site-packages/pygpt_net/core/audio/__init__.py\", line 15, in <module>\n    from PySide6.QtMultimedia import QMediaDevices\nImportError: /usr/lib/libgssapi_krb5.so.2: undefined symbol: k5_buf_cstring, version krb5support_0_MIT\n\n```\n\nNothing appears in the logs per the documentation for debugging and logging.",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 103,
    "title": "Unable to maximize or change window size when anything except Chat mode is selected i.e. Chat with Files",
    "author": "PetTails",
    "state": "open",
    "created_at": "2025-03-20T02:22:27Z",
    "updated_at": "2025-04-15T17:53:09Z",
    "labels": [],
    "body": "Installed via Snap OS: Ubuntu Cinnamon 24.04.2 LTS x86_",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 104,
    "title": "Install / Build Error - Unable to build Wheel for pyaudio",
    "author": "gingamann",
    "state": "open",
    "created_at": "2025-03-21T01:52:36Z",
    "updated_at": "2025-04-15T17:52:44Z",
    "labels": [],
    "body": "I have run through the install a few times using pip\n\n\njason@Orange:~$ git clone https://github.com/szczyglis-dev/py-gpt.git\njason@Orange:~$ cd py-gpt\njason@Orange:~/py-gpt$ pwd\n/home/jason/py-gpt\njason@Orange:~/py-gpt$ \njason@Orange:~/py-gpt$ python3 -m venv venv\njason@Orange:~/py-gpt$ source venv/bin/activate\n(venv) jason@Orange:~/py-gpt$ \n(venv) jason@Orange:~/py-gpt$ pip install -r requirements.txt\n\n\n****This is the only error that looks to come up***\n\n\n\n\nBuilding wheels for collected packages: evdev, pyaudio, pyautogui, pymsgbox, pypika, pyscreeze\n  Building wheel for evdev (pyproject.toml) ... done\n  Created wheel for evdev: filename=evdev-1.7.1-cp311-cp311-linux_x86_64.whl size=90490 sha256=d53ef76362bd10f2bbebec867be16e2981fa46e776a36c20c3c704e26ffdaf87\n  Stored in directory: /home/jason/.cache/pip/wheels/36/ba/44/2f52ca43144a6b022b37bf10096a883bf3f9301c684b1534d0\n  Building wheel for pyaudio (pyproject.toml) ... error\n  error: subprocess-exited-with-error\n  \n Building wheel for pyaudio (pyproject.toml) did not run successfully.\nexit code: 1\n[27 lines of output]\n      /tmp/pip-build-env-y_lj0ppa/overlay/lib/python3.11/site-packages/setuptools/dist.py:760: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n      !!\n      \n              ********************************************************************************\n              Please consider removing the following classifiers in favor of a SPDX license expression:\n      \n              License :: OSI Approved :: MIT License\n      \n              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n              ********************************************************************************\n      \n      !!\n        self._finalize_license_expression()\n      running bdist_wheel\n      running build\n      running build_py\n      creating build/lib.linux-x86_64-cpython-311/pyaudio\n      copying src/pyaudio/__init__.py -> build/lib.linux-x86_64-cpython-311/pyaudio\n      running build_ext\n      building 'pyaudio._portaudio' extension\n      creating build/temp.linux-x86_64-cpython-311/src/pyaudio\n      x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/include -I/usr/include -I/home/jason/py-gpt/venv/include -I/usr/include/python3.11 -c src/pyaudio/device_api.c -o build/temp.linux-x86_64-cpython-311/src/pyaudio/device_api.o\n      src/pyaudio/device_api.c:9:10: fatal error: portaudio.h: No such file or directory\n          9 | #include \"portaudio.h\"\n            |          ^~~~~~~~~~~~~\n      compilation terminated.\n      error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for pyaudio\n  Building wheel for pyautogui (pyproject.toml) ... done\n  Created wheel for pyautogui: filename=pyautogui-0.9.54-py3-none-any.whl size=37684 sha256=c0dc42147420b9bb01bbcf06bc8a9f7bb393e13b0605b99b9d8f84919a9ae47d\n  Stored in directory: /home/jason/.cache/pip/wheels/95/dc/b1/fe122b791e0db8bf439a0e6e1d2628e48f10bf430cae13521b\n  Building wheel for pymsgbox (pyproject.toml) ... done\n  Created wheel for pymsgbox: filename=pymsgbox-1.0.9-py3-none-any.whl size=7453 sha256=1cf904bc56c764b651af7b4c8f1f4c8ff20d7e1d30565f6d166a898fd5fc27eb\n  Stored in directory: /home/jason/.cache/pip/wheels/85/92/63/e126ee5f33d8f2ed04f96e43ef5df7270a2f331848752e8662\n  Building wheel for pypika (pyproject.toml) ... done\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=2070c47406a5378e08ff0d84f109cf1ca4c9a9b120fb5b4e244cecd32eb5d7b8\n  Stored in directory: /home/jason/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n  Building wheel for pyscreeze (pyproject.toml) ... done\n  Created wheel for pyscreeze: filename=pyscreeze-1.0.1-py3-none-any.whl size=14458 sha256=9fe2fd609053a378eeaf50799b576a8207f309b14dc66f135935068707e9b0cb\n  Stored in directory: /home/jason/.cache/pip/wheels/cd/e3/dd/267b393d8e8f607e47194942740d080d9bfd835cd4375a3de1\nSuccessfully built evdev pyautogui pymsgbox pypika pyscreeze\nFailed to build pyaudio\nERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\n(venv) jason@Orange:~/py-gpt$ \n(venv) jason@Orange:~/py-gpt$ \n(venv) jason@Orange:~/py-gpt$\n\n\n",
    "comments": [
      {
        "user": "xandark",
        "body": "Did you `sudo apt install portaudio19-dev` as mentioned in INSTALL.md? I had the same issue, but using uv gave better diagnosis messages.\n\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 105,
    "title": "web_search hangs",
    "author": "j2l",
    "state": "open",
    "created_at": "2025-03-21T15:52:21Z",
    "updated_at": "2025-04-15T17:52:14Z",
    "labels": [],
    "body": "I stared this project! Thank you for this great idea.\nEach time I try a web search, using prompt \"web_search images of cars\", it hangs and I must quit.\nIf I use prompt \"web search images of cars\", the model simply reply it can't, and web_search is sometimes simply discarded and it simulates a search.\n\n![Image](https://github.com/user-attachments/assets/a98d7e22-7009-46c8-8002-7e7291e3d986)\n![Image](https://github.com/user-attachments/assets/89871652-5000-45e5-95db-2e2778475f9f)\nBelow is the log of ollama container to check.\n\nI entered Google keys.\nUsing PopOS (Ubuntu) 22.04\n",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 107,
    "title": "can't open",
    "author": "ana-joker",
    "state": "open",
    "created_at": "2025-04-05T07:54:35Z",
    "updated_at": "2025-04-15T17:51:29Z",
    "labels": [],
    "body": "i installed the prog no dought >>>> once i just click on it \n\nit gives me this error and close , it doesn't even give me the window of the program \n\nTraceback (most recent call last):\n  File \"app.py\", line 56, in <module>\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"PyInstaller\\loader\\pyimod02_importers.py\", line 419, in exec_module\n  File \"provider\\llms\\ollama.py\", line 17, in <module>\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"PyInstaller\\loader\\pyimod02_importers.py\", line 419, in exec_module\n  File \"llama_index\\llms\\ollama\\__init__.py\", line 1, in <module>\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"PyInstaller\\loader\\pyimod02_importers.py\", line 419, in exec_module\n  File \"llama_index\\llms\\ollama\\base.py\", line 1, in <module>\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"PyInstaller\\loader\\pyimod02_importers.py\", line 419, in exec_module\n  File \"ollama\\__init__.py\", line 40, in <module>\n  File \"ollama\\_client.py\", line 115, in __init__\n  File \"ollama\\_client.py\", line 96, in __init__\n  File \"ollama\\_client.py\", line 1227, in _parse_host\n  File \"urllib\\parse.py\", line 177, in port\nValueError: Port could not be cast to integer value as '\\\\Users\\\\Ahmed El3nany'\n[3884] Failed to execute script 'app' due to unhandled exception! ",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 108,
    "title": "Custom commands plugin broken (unhashable type: 'dict')",
    "author": "safwat-halaby",
    "state": "open",
    "created_at": "2025-04-05T08:29:12Z",
    "updated_at": "2025-04-15T16:51:02Z",
    "labels": [],
    "body": "Version: 2.5.10, Linux, x86_64 (snap), Build: 2025-03-06\n\nRunning any command via the commands plugin yields the error `unhashable type: 'dict'`.\n\nHere is an attempt to run the built in example command.\n\n\n```\nUser: Execute the example command please\nChatbot: {\"cmd\": \"example_cmd\", \"params\": {\"hello\": \"funny\", \"world\": \"words\"}}\n```\n\nAt this point an error occurs.\n\n```\nCommand JSON Output:\n\n[{\"request\": {\"cmd\": \"example_cmd\"}, \"result\": \"Error: unhashable type: 'dict'\"}]\n\nPyGPT error popup:\n\nCustom Commands: Exception: unhashable type: 'dict'\nType: TypeErrorMessage: unhashable type: 'dict'\nTraceback:   File \"/snap/pygpt/368/src/pygpt_net/plugin/cmd_custom/worker.py\", line 47, in run\n    response = self.handle_cmd(my_cmd, item)\n  File \"/snap/pygpt/368/src/pygpt_net/plugin/cmd_custom/worker.py\", line 102, in handle_cmd\n    if param in item[\"params\"]:\n```\n\nFor the record, the original command is in this case is `echo \"Response from {hello} and {world} at {_time}\"`, but any command fails the same.",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 109,
    "title": "Is it just me, or the documentations for configuring pyGPT to work with huggingface are missing?",
    "author": "yotama9",
    "state": "open",
    "created_at": "2025-04-13T14:55:54Z",
    "updated_at": "2025-04-15T16:50:37Z",
    "labels": [],
    "body": "I've been trying for the last two days to connect pyGPT.net to hugging face, the documentations say that this can be done, but actually doing this seems to be impossible to me. For first, in the app GUI, I can put the API_key, but I couldn't find where I can actually do this. Then, via chatGPT, in I figured I can do this via edit the json file, which I don't know where I can find the documentations for that, so again chatGPT gave me instructions, that I had to do a bit of modification. Now, I can see the HF model I've selected via the chat, but when I try to access it, I get an error since I need to enable this via the \"chatwithfile\" option (which makes 0 sense to me, but fine). Only, I have no idea how to do that. I admit that it might be that I might didn't look well enough in the docs, but in my defence the docs don't seem to provide something like a section titled \"configure json for HF\". ",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 110,
    "title": "HTML entity conversion error for angle brackets",
    "author": "RomeoKNS",
    "state": "open",
    "created_at": "2025-04-14T12:39:17Z",
    "updated_at": "2025-04-15T16:50:15Z",
    "labels": [],
    "body": "When generating an AI response, the symbols display correctly, but once the generation is complete, the '<' and '>' symbols change to '& lt;' and '& gt;'\n\n![Image](https://github.com/user-attachments/assets/6c2b7ead-666a-4c57-8d4c-6968a6ba973f)",
    "comments": [
      {
        "user": "RomeoKNS",
        "body": "Switching to plain shows normal symbols\n\n![Image](https://github.com/user-attachments/assets/b0a912cf-a939-4d48-a69a-355de499b0a8)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 98,
    "title": "Custom Models with Ollama",
    "author": "apsjohn",
    "state": "open",
    "created_at": "2025-03-09T18:20:52Z",
    "updated_at": "2025-04-15T10:30:29Z",
    "labels": [],
    "body": "Hey!\nSo there is a bit of a haze on how to add, use custom downloaded models others than your list with ollama...\n\nI selected chat with files option, and i am adding a model that i have in my ollama list but no matter what i try i get \"The requested model 'modelname' is not available in your Ollama.\nPlease download the model first by executing the command:\nollama pull deepseek-r1-temp06:latest\"\n\nI tried your ollama2-uncesored as was from your list and i am getting only a word back from it...\nFrom the cmd that pygpt is opening i see this errors\n\"Initializing...\nLoaded config: C:\\Users\\johna\\.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\johna\\.config\\pygpt-net\\models.json\nType: KeyErrorMessage: None\nTraceback:   File \"core\\dispatcher\\__init__.py\", line 80, in dispatch\n  File \"controller\\chat\\render.py\", line 89, in handle\n  File \"controller\\chat\\render.py\", line 356, in append_chunk\n  File \"core\\render\\plain\\renderer.py\", line 322, in append_chunk\n\nType: KeyErrorMessage: None\nTraceback:   File \"core\\dispatcher\\__init__.py\", line 80, in dispatch\n  File \"controller\\chat\\render.py\", line 89, in handle\n  File \"controller\\chat\\render.py\", line 356, in append_chunk\n  File \"core\\render\\plain\\renderer.py\", line 322, in append_chunk\n\nError in sending text: None\nType: APIConnectionErrorMessage: Connection error.\nTraceback:   File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1020, in _request\n  File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1030, in _request\n\nError in GPT quick call: Connection error.\"\n\nCan you help out, to troubleshoot what is wrong?",
    "comments": [
      {
        "user": "BeZazz",
        "body": "This is what I did. Not sayting correct but works (only started using PyGPT today).\nI did ollama list, then added a model like.\n\n\n![Image](https://github.com/user-attachments/assets/6ffa3ba5-b883-42f2-8b9f-d785882e821d)\n\n![Image](https://github.com/user-attachments/assets/5ca1cc5a-0184-4e89-bfd5-ed2d7b5b7854)\n\n![Image](https://github.com/user-attachments/assets/1d9e4f9b-cb16-405e-a243-76ec080c3712)\n\nFirst model_name then model. I stopped trying at that combination. You may only need the second model. As the model_name up top didn't work by itself. \nIf I workout correct way I will update this mess.\nEDIT: for newbs like me. Local model Chat and Files NOT Chat. (I wasted quite a bit of time. lol) \n\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 91,
    "title": "Display error running binary version of pygpt on Ubuntu desktop",
    "author": "zhiyuanil",
    "state": "open",
    "created_at": "2025-01-22T23:38:18Z",
    "updated_at": "2025-03-28T17:13:14Z",
    "labels": [],
    "body": "I got error 'unable to connect to display ... \" when running pygpt binary file on Uabuntu desktop. I logged out and logged in and switch to Xorg (default display manager is wayland), and pygpt runs. ",
    "comments": [
      {
        "user": "m-ar-c",
        "body": "Fresh download today, and tried to execute the binary on my debian sid with gnome wayland -> same error as you.\n\nI guess wayland is not supported ."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 71,
    "title": "The term \"free\" seems pretty ambiguous in it's context these days..",
    "author": "Xephier102",
    "state": "closed",
    "created_at": "2024-09-19T00:45:49Z",
    "updated_at": "2025-03-22T00:21:43Z",
    "labels": [],
    "body": "I can use chatgpt for free in so many places and applications, but I'm not able to find a way to use this program for free at all. It's VERY deceptive in it's phrasing. Yea, like, the program is free, but it's fucking useless without paying a huge persistent usage fee. \r\n\r\nPlease tell me I'm wrong, cuz this looks insane, but it's insanely useless if I can't even access the core point of the thing without holding the pocket of yet another over-privileged corporation.. That's like saying Automatic1111 is 'free', but you gotta pay a fee for every image you create with stable diffusion (hypothetical). ",
    "comments": [
      {
        "user": "RepairYourTech",
        "body": "imagine crying that someone gave you a free car but you still have to buy gas....ambiguous my rear end you're a brat"
      },
      {
        "user": "Xephier102",
        "body": "> imagine crying that someone gave you a free car but you still have to buy gas....ambiguous my rear end you're a brat\r\n\r\nNaw, your logic is way off, or non existent. It's more like being given free gas but having to pay for a car. Especially given what/how openAI is charging for their AI. \r\nI thought monthly fees for programs like Photoshop, and well, so many other things these days, were bad enough, but pay per use is the all new low.. \r\n\r\nJust sick and tired of corporations putting paywalls on everything. And, before you say it, I already considered making my own. I've got all the time in the world right now, so learning how to program would be easy enough. But programming my own model wouldn't even be the hard part (as much work as that would take to do solo). \r\n\r\nThe real road block is capital requirement. You've basically got to have millions/billions of dollars in hardware in order to reasonably train AIs like ChatGPT. \r\n\r\nYou can download and train some models that are 'open source', but they're still technically corporate owned and beholden to the terms and conditions that you must agree to in order to use them. \r\n\r\nThat's not a completely dead option for me, yet. As I have not yet looked into the full scope of implications of agreeing to such contracts. Though it may be logical to assume that they are geared in such a way that would be detrimental to anyone that isn't relatively wealthy already. \r\n"
      },
      {
        "user": "shawazi",
        "body": "hey @Xephier102, I was disappointed to see that you must have an API key to use this service, but maybe you can try forking this repo, opening it in CursorAI, and then asking Cursor to help you adjust the project to use only FOSS LLMs or, if your hardware is capable, to use your own LocalLLM via something like Ollama, OpenLLM, or LM Studio. \r\n\r\nMore here: https://medium.com/thedeephub/50-open-source-options-for-running-llms-locally-db1ec6f5a54f\r\n\r\nAlso I would disagree that this program is useless! It's a free car whether you have gas or not, and you have the option to modify the base to suit your needs. It's awesome!  "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 93,
    "title": "Windows installer pygpt-2.4.51 does not install correctly.",
    "author": "apsjohn",
    "state": "open",
    "created_at": "2025-01-28T11:54:13Z",
    "updated_at": "2025-03-08T20:35:03Z",
    "labels": [],
    "body": "I got this as well today, when installing windows msi file from official site.\n\n[nltk_data] Downloading package punkt_tab to D:\\AppData\\Roaming\\PyGPT\n[nltk_data] _internal\\llama_index\\core_static/nltk_cache...\n[nltk_data] Unzipping tokenizers\\punkt_tab.zip.\nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling transformers.utils.move_cache().\n0it [00:00, ?it/s]\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\nUser config: C:\\Users\\johna.config\\pygpt-net\\config.json not found.\nPyGPT 2.4.57 build 2025-01-19 (Windows, AMD64)\nAuthor: Marcin Szczyglinski\nGitHub: https://github.com/szczyglis-dev/py-gpt\nWebsite: https://pygpt.net/\nEmail: [info@pygpt.net](mailto:info@pygpt.net)\nInitializing...\n[DB] Installed database: C:\\Users\\johna.config\\pygpt-net\\db.sqlite\nLoaded config: C:\\Users\\johna.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\johna.config\\pygpt-net\\models.json\n[DB] Migrating database...\n[DB] Executed DB migration: 20231227152900\n[DB] Executed DB migration: 20231230095000\n[DB] Executed DB migration: 20231231230000\n[DB] Executed DB migration: 20240106060000\n[DB] Executed DB migration: 20240107060000\n[DB] Executed DB migration: 20240222160000\n[DB] Executed DB migration: 20240223050000\n[DB] Executed DB migration: 20240303190000\n[DB] Executed DB migration: 20240408180000\n[DB] Executed DB migration: 20240426050000\n[DB] Executed DB migration: 20240501030000\n[DB] Executed DB migration: 20241122130000\n[DB] Executed DB migration: 20241126170000\n[DB] Executed DB migration: 20241215110000\ndoh set to \"\" -- SystemOnly\nChecking for updates...\nNo updates available.\n\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hmm, I don't see any errors here... did the app not launch?"
      },
      {
        "user": "apsjohn",
        "body": "The app did launch but i was worried the functionality wasnt there cause of the error notice i got which was\n### \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\"\n\n---\nBesides that i tried using it with ollama by setting the endpoint to ollama normally and renaming my ollama model to 'gpt-4o' and i see this in console, and i get connection error, with any simple text prompt...\n\n\"\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n PyGPT    2.4.57 build 2025-01-19 (Windows, AMD64)\n Author:  Marcin Szczyglinski\n GitHub:  https://github.com/szczyglis-dev/py-gpt\n Website: https://pygpt.net\n Email:   info@pygpt.net\n\nInitializing...\nLoaded config: C:\\Users\\johna\\.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\johna\\.config\\pygpt-net\\models.json\ndoh set to \"\"  --  SystemOnly\nChecking for updates...\nTraceback (most recent call last):\n  File \"ui\\layout\\chat\\input.py\", line 227, in <lambda>\n  File \"controller\\chat\\input.py\", line 122, in send_input\n  File \"ui\\main.py\", line 261, in dispatch\n  File \"core\\dispatcher\\__init__.py\", line 65, in dispatch\n  File \"controller\\kernel\\__init__.py\", line 88, in handle\n  File \"controller\\kernel\\__init__.py\", line 142, in input\n  File \"controller\\chat\\input.py\", line 142, in send\n  File \"controller\\chat\\input.py\", line 262, in execute\n  File \"controller\\chat\\text.py\", line 188, in send\n  File \"ui\\main.py\", line 261, in dispatch\n  File \"core\\dispatcher\\__init__.py\", line 80, in dispatch\n  File \"controller\\chat\\render.py\", line 131, in handle\n  File \"controller\\chat\\render.py\", line 308, in append_input\n  File \"core\\render\\web\\renderer.py\", line 310, in append_input\n  File \"core\\render\\web\\renderer.py\", line 453, in append_node\n  File \"core\\render\\web\\renderer.py\", line 786, in prepare_node\n  File \"core\\render\\web\\renderer.py\", line 820, in prepare_node_input\nKeyError: None\nType: APIConnectionErrorMessage: Connection error.\nTraceback:   File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1020, in _request\n  File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1030, in _request\n\nError in sending text: Connection error.\nType: APIConnectionErrorMessage: Connection error.\nTraceback:   File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1020, in _request\n  File \"openai\\_base_client.py\", line 1098, in _retry_request\n  File \"openai\\_base_client.py\", line 1030, in _request\n\nError in sending text: Connection error.\n\"\n\nI think the original error, must be related to my problem...\n\"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\"\n\nWhat do you suggest i try, to troubleshoot this more?\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "Support for Ollama is built into the application - you just need to switch the mode to 'Chat with Files'.\n\nChanging the API endpoint to Ollama doesn't help, because the API endpoint option only applies to the OpenAI API (or compatible ones)."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 84,
    "title": "Code rendering only the middle of the code",
    "author": "upnix",
    "state": "open",
    "created_at": "2024-12-04T23:35:24Z",
    "updated_at": "2025-02-27T23:33:13Z",
    "labels": [],
    "body": "Version: 2.4.37\r\n\r\nInstalled using `pip` on openSUSE Tumbleweed.\r\n\r\nThis is what I'm getting:\r\n![image](https://github.com/user-attachments/assets/42c7d1a2-1506-4f8f-b70f-6cebf3dab5e2)\r\n\r\n\r\nThe first 3 or 4 lines aren't rendered as code, and then the trailing brace is also not rendered. It's not just Bash either:\r\n![image](https://github.com/user-attachments/assets/aec4eec5-694c-49c3-b5df-c0c968075ac9)\r\n\r\n\r\nI can't recreate this, however. I've tried different languages, different lengths of code, having lists and headings above and below the code. It seems to show up randomly, but once it shows up, it renders that way consistently.\r\n\r\nI've also tried switching the renderer to \"Markdown,\" which prevents `pygpt` from running at all.\r\n\r\nI'll keep thinking about it, but, thought I'd open a bug to see if other idea came up.",
    "comments": [
      {
        "user": "hfranco75",
        "body": "It's still happening in version 2.5.7: most of the times, the code appears as formatted text, sometimes part of the code is rendered as text and part as code, but never with a correct formatting for contiguous text and code blocks in the output\n\n![Image](https://github.com/user-attachments/assets/9396af50-dbc5-4832-aa72-d85eb9fb4bde)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 69,
    "title": "Web search",
    "author": "7SoKKoS7",
    "state": "closed",
    "created_at": "2024-07-24T10:33:19Z",
    "updated_at": "2025-02-27T12:58:49Z",
    "labels": [
      "wontfix"
    ],
    "body": "when responding from the AI assistant, I receive answers in the chat in the form of AI assistant\r\n~###~\r\n{\"cmd\": \"goal_update\", \"params\": {\"status\": \"pause\"}}\r\n~###~\r\nCan I find the error in which file and fix it?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Please disable the Agent (inline) plugin - this is a plugin command and if you use model like 3.5 it can make mistakes and call the command \"pause\". This is not related to Web search plugin."
      },
      {
        "user": "jhorner6511",
        "body": "> Please disable the Agent (inline) plugin - this is a plugin command and if you use model like 3.5 it can make mistakes and call the command \"pause\". This is not related to Web search plugin.\n\nOn the same topic (rather than opening a new issue) I cannot figure out how to get web results. I have web search enabled, I've added both my google API keys (Search & CX), I've tried all three google models, and still can't get web results. I've also enabled real-time, System (OS), API Calls and my regular API key in settings.\n\nI've also read through your documentation online and followed the instructions, and still nothing.\n\nI'm currently running it on LMDE6 via Snap."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 86,
    "title": "Basic Chat Feature Not Working - Getting error 404",
    "author": "gitme1now",
    "state": "closed",
    "created_at": "2025-01-01T18:00:01Z",
    "updated_at": "2025-02-27T11:43:38Z",
    "labels": [],
    "body": "Having an issue just using the basic Chat feature in gpt-4o, or gpt-4, getting this error =\r\n\r\nError code: 404 - {'error': {'message': 'The model gpt-4o does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\r\n\r\n...i am unable to find any answers to this issue. i thought all the Models came already built into PyGPT, just need to add the API Key, which i did, and followed the install instruction exactly and had zero issues installing it.\r\n\r\n...and not only does the basic chat feature not work for me, i cannot access any mic and when i try to use the mic i get this error = \r\n\r\nException: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\r\nType: TypeErrorMessage: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\r\nTraceback: File \"/snap/pygpt/338/src/pygpt_net/plugin/audio_input/simple.py\", line 88, in start_recording\r\ndevice_id = int(self.plugin.window.core.config.get('audio.input.device', 0))\r\n\r\n....and when i go to setting in PyGPT there is no mic to chose from, but yet in the Zorin OS settings i see all the mics and they work fine on every other program using a mic....\r\n\r\nWhen i try to use the VOICE CONTROL i get this error = \r\n\r\nException: [Errno -9996] Invalid input device (no default output device)\r\nType: OSErrorMessage: [Errno -9996] Invalid input device (no default output device)\r\nTraceback:   File \"/snap/pygpt/338/src/pygpt_net/controller/access/voice.py\", line 245, in start_recording\r\n    self.stream = self.p.open(format=pyaudio.paInt16,\r\n  File \"/snap/pygpt/338/lib/python3.10/site-packages/pyaudio/__init__.py\", line 639, in open\r\n    stream = PyAudio.Stream(self, *args, **kwargs)\r\n  File \"/snap/pygpt/338/lib/python3.10/site-packages/pyaudio/__init__.py\", line 441, in __init__\r\n    self._stream = pa.open(**arguments)\r\n\r\ni try adding the recommended = sudo snap connect pygpt:audio-record :audio-record ...and still no mic appears to select from...\r\n\r\nMy OS = Zorin OS 17.2 Pro/Ubuntu based\r\nAMD Ryzen 7 5700g with radeon graphics  16\r\nRENOIR (renoir, LLVM 15.0.7, DRM 3.57, 6.8.0-50-generic)\r\nWindows System X11\r\nMEM = 32gb\r\n64 bit",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "1. The error about not having access to the model:\n\n`Error code: 404 - {'error': {'message': 'The model gpt-4o does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}`\n\ncomes from the OpenAI API, not the application. For some reason, your OpenAI account caused this error.\n\n2. The audio input was improved in version `2.4.50`. \n\n Try it now, making sure to connect all the required slots:\n\n`sudo snap connect pygpt:audio-record :audio-record`\n\n`sudo snap connect pygpt:alsa`"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 92,
    "title": "Errors running pygpt binary",
    "author": "zhiyuanil",
    "state": "closed",
    "created_at": "2025-01-27T04:19:58Z",
    "updated_at": "2025-02-27T11:42:55Z",
    "labels": [],
    "body": "Running pygpt binary on Ubuntu LTS24.04 produced the following error. The application runs. I tried a few things suggested by pygpt and did not resolve the error. \n\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n/usr/lib/x86_64-linux-gnu/gvfs/libgvfscommon.so: undefined symbol: g_task_set_static_name\nFailed to load module: /usr/lib/x86_64-linux-gnu/gio/modules/libgvfsdbus.so\n....\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "What version of GLIBC do you have?"
      },
      {
        "user": "zhiyuanil",
        "body": "ldd --version\nldd (Ubuntu GLIBC 2.39-0ubuntu8.3) 2.39\nCopyright (C) 2024 Free Software Foundation, Inc."
      },
      {
        "user": "szczyglis-dev",
        "body": "GLIBC version is fine (binary version requires >= 2.35). \n\nYou can try installing/reinstalling gvfs:\n\n`sudo apt install --reinstall gvfs gvfs-backends`\n\nHowever, if the app is working and there are no other problems, I wouldn't worry about this error."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 97,
    "title": "Chat does not work",
    "author": "PtDragon",
    "state": "closed",
    "created_at": "2025-02-24T07:03:31Z",
    "updated_at": "2025-02-27T11:42:14Z",
    "labels": [],
    "body": "I do not want any external API but the program nags me about not having OpenAI key and does not let me chat with local models.\nIf i put fake api key and fake endpoint it does let me send message to the chat but then complains that it cannot connect to openai even if i removed all the api-based models from the list leaving only local ollama models.\nWhy does your program want to send my question somewhere i did not ask to? \n\n![Image](https://github.com/user-attachments/assets/91d8ee29-4436-4be7-8fdb-c5148941da48)\n\n![Image](https://github.com/user-attachments/assets/8eda73d8-c600-40e9-ad26-3f9218fcbdd4)",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "You need to switch to \"Chat with Files\" mode to use local models, as mentioned in the documentation:\n\n> If you want to use models other than GPT (such as Gemini, Claude, or Llama3), use Chat with Files mode.\n\nThe standard \"Chat\" mode works via the OpenAI API and supports only GPT models."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 96,
    "title": "Is Mac Still Supported?",
    "author": "halfer53",
    "state": "closed",
    "created_at": "2025-02-04T09:17:48Z",
    "updated_at": "2025-02-27T11:42:05Z",
    "labels": [],
    "body": "I can see mac is listed as supported OS but I can't find any download link\n\nhttps://pygpt.net/#download",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Yes, the Mac version is supported, but there is no compiled version available for Mac (only for Windows and Linux).\n\nTo run it on a Mac, you need to install PyGPT using PyPi:\n\n```bash\npip install pygpt-net\n```"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 95,
    "title": "pygpt 2.5.1 crash upon start",
    "author": "sk9la",
    "state": "closed",
    "created_at": "2025-02-01T11:19:47Z",
    "updated_at": "2025-02-02T18:12:47Z",
    "labels": [],
    "body": "Hi,\n\nAfter upgrading pygpt-net to version 2.5.1 using the command `pipx upgrade pygpt-net` I got the following error:\n\n```\nTraceback (most recent call last):\n  File \"signature_bootstrap.py\", line 77, in bootstrap\n  File \"signature_bootstrap.py\", line 93, in find_incarnated_files\n  File \"/usr/lib/python3.11/pathlib.py\", line 872, in __new__\n    self = cls._from_parts(args)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/pathlib.py\", line 510, in _from_parts\n    drv, root, parts = self._parse_args(args)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/pathlib.py\", line 494, in _parse_args\n    a = os.fspath(a)\n        ^^^^^^^^^^^^\nTypeError: expected str, bytes or os.PathLike object, not NoneType\nFatal Python error: could not initialize part 2\nPython runtime state: initialized\n\nCurrent thread 0x00007f8d8c8fe040 (most recent call first):\n  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap_external>\", line 1233 in create_module\n  File \"<frozen importlib._bootstrap>\", line 573 in module_from_spec\n  File \"<frozen importlib._bootstrap>\", line 676 in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1147 in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1176 in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap>\", line 1232 in _handle_fromlist\n  File \"/usr/local/lib/pipx/venvs/pygpt-net/lib/python3.11/site-packages/PySide6/__init__.py\", line 64 in _setupQtDirectories\n  File \"/usr/local/lib/pipx/venvs/pygpt-net/lib/python3.11/site-packages/PySide6/__init__.py\", line 124 in <module>\n  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap_external>\", line 940 in exec_module\n  File \"<frozen importlib._bootstrap>\", line 690 in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1147 in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1176 in _find_and_load\n  File \"/usr/local/lib/pipx/venvs/pygpt-net/lib/python3.11/site-packages/pygpt_net/launcher.py\", line 17 in <module>\n  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap_external>\", line 940 in exec_module\n  File \"<frozen importlib._bootstrap>\", line 690 in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1147 in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1176 in _find_and_load\n  File \"/usr/local/lib/pipx/venvs/pygpt-net/lib/python3.11/site-packages/pygpt_net/app.py\", line 17 in <module>\n  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap_external>\", line 940 in exec_module\n  File \"<frozen importlib._bootstrap>\", line 690 in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1147 in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 1176 in _find_and_load\n  File \"/usr/local/bin/pygpt\", line 5 in <module>\n\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, xxsubtype (total: 14)\nAborted (core dumped)\n```",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In version 2.5.1, two libraries have been upgraded: PySide6 and Shiboken6.\n\nTry to uninstall previous versions of PySide6 and Shiboken6:\n\n`pip uninstall pyside6`\n`pip uninstall shiboken6`\n\nand then do the upgrade.\n\nBTW, I had the same error on Windows after upgrading PySide6 from version 6.6.1 to 6.6.2, it's a common issue, and the above solution did the trick. There were no issues on Linux."
      },
      {
        "user": "sk9la",
        "body": "Hell yeah, It worked!\n\nThank you so much :)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 90,
    "title": "PermissionError: [Errno 13] Permission denied: '/etc/httpd/conf/mime.types'",
    "author": "powerpoint45",
    "state": "closed",
    "created_at": "2025-01-21T17:18:07Z",
    "updated_at": "2025-02-01T19:00:45Z",
    "labels": [],
    "body": "Since the last update, when I try to open pygpt I get:\n\n> pygpt\nTraceback (most recent call last):\n  File \"/snap/pygpt/352/src/pygpt_net/app.py\", line 46, in <module>\n    from pygpt_net.provider.llms.google import GoogleLLM\n  File \"/snap/pygpt/352/src/pygpt_net/provider/llms/google.py\", line 14, in <module>\n    from llama_index.llms.gemini import Gemini\n  File \"/snap/pygpt/352/lib/python3.10/site-packages/llama_index/llms/gemini/__init__.py\", line 1, in <module>\n    from llama_index.llms.gemini.base import Gemini\n  File \"/snap/pygpt/352/lib/python3.10/site-packages/llama_index/llms/gemini/base.py\", line 24, in <module>\n    from llama_index.llms.gemini.utils import (\n  File \"/snap/pygpt/352/lib/python3.10/site-packages/llama_index/llms/gemini/utils.py\", line 4, in <module>\n    import google.generativeai as genai\n  File \"/snap/pygpt/352/lib/python3.10/site-packages/google/generativeai/__init__.py\", line 54, in <module>\n    from google.generativeai.files import upload_file\n  File \"/snap/pygpt/352/lib/python3.10/site-packages/google/generativeai/files.py\", line 32, in <module>\n    mimetypes.add_type(\"image/webp\", \".webp\")\n  File \"/usr/lib/python3.10/mimetypes.py\", line 356, in add_type\n    init()\n  File \"/usr/lib/python3.10/mimetypes.py\", line 379, in init\n    db.read(file)\n  File \"/usr/lib/python3.10/mimetypes.py\", line 209, in read\n    with open(filename, encoding='utf-8') as fp:\nPermissionError: [Errno 13] Permission denied: '/etc/httpd/conf/mime.types'\n\nI have tried changing permissions to all public for file '/etc/httpd/conf/mime.types' but It still has the same issue. And I am able to cat out /etc/httpd/conf/mime.types as current user.\n\nI am running arch linux and installed latest version via snap",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Have you tried removing the app and reinstalling it again?\n\n`sudo snap remove --purge pygpt`\n\n`sudo snap install pygpt`"
      },
      {
        "user": "powerpoint45",
        "body": "Issue seems to have resolved itself after updating "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 94,
    "title": "Errors running snap version of pygpt",
    "author": "zhiyuanil",
    "state": "closed",
    "created_at": "2025-01-30T17:38:11Z",
    "updated_at": "2025-02-01T18:44:45Z",
    "labels": [
      "bug"
    ],
    "body": "pygpt \nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\nGtk-Message: 11:23:48.104: Failed to load module \"canberra-gtk-module\"\nGtk-Message: 11:23:48.105: Failed to load module \"canberra-gtk-module\"\n===================================================\n PyGPT    2.4.57 build 2025-01-19 (Linux, x86_64)\n Author:  Marcin Szczyglinski\n GitHub:  https://github.com/szczyglis-dev/py-gpt\n Website: https://pygpt.net\n Email:   info@pygpt.net\n===================================================\n\nInitializing...\nLoaded config: /home/cyao/snap/pygpt/352/.config/pygpt-net/config.json\nLoaded models: /home/cyao/snap/pygpt/352/.config/pygpt-net/models.json\nqt.multimedia.ffmpeg.libsymbolsresolver: Couldn't load VAAPI library\n[7969:7969:0130/112349.167675:FATAL:credentials.cc(126)] Check failed: . : Permission denied (13)\n/snap/pygpt/352/snaprun.sh: line 28:  7969 Trace/breakpoint trap   (core dumped) python3 $SNAP/src/pygpt_net/app.py \"$@\"\n",
    "comments": [
      {
        "user": "nicholasmparker",
        "body": "same\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "What does the following command show?\n\n`sudo snap connections pygpt`\n\n\nSecond question - what is your OS?\n\nIs AppArmor showing any errors?\n\nAnd does something like this help?\n\n`sudo sysctl -w kernel.apparmor_restrict_unprivileged_userns=0`\n\nBecause the only error is here, related to permissions:\n\n`[7969:7969:0130/112349.167675:FATAL:credentials.cc(126)] Check failed: . : Permission denied (13)`\n\nEverything above that is just warnings, not errors.\n"
      },
      {
        "user": "zhiyuanil",
        "body": "First question: I just installed snap version of pygpt-2.5.0. Same errors. \nsudo snap connections pygpt \n[sudo] password for cyao: \nInterface                                 Plug                               Slot                                                          Notes\nalsa                                      pygpt:alsa                         -                                                             -\naudio-playback                            pygpt:audio-playback               :audio-playback                                               -\naudio-record                              pygpt:audio-record                 -                                                             -\nbrowser-support                           pygpt:browser-support              :browser-support                                              -\ncamera                                    pygpt:camera                       -                                                             -\ncontent                                   pygpt:docker-executables           -                                                             -\ncontent[icon-themes]                      pygpt:icon-themes                  gtk-common-themes:icon-themes                                 -\ncontent[kf5-5-113-qt-5-15-11-core22-all]  pygpt:kf5-5-113-qt-5-15-11-core22  kf5-5-113-qt-5-15-11-core22:kf5-5-113-qt-5-15-11-core22-slot  -\ncontent[sound-themes]                     pygpt:sound-themes                 gtk-common-themes:sound-themes                                -\ndesktop                                   pygpt:desktop                      :desktop                                                      -\ndesktop-legacy                            pygpt:desktop-legacy               :desktop-legacy                                               -\ndocker                                    pygpt:docker                       -                                                             -\ngsettings                                 pygpt:gsettings                    :gsettings                                                    -\nhome                                      pygpt:home                         :home                                                         -\nnetwork                                   pygpt:network                      :network                                                      -\nnetwork-bind                              pygpt:network-bind                 :network-bind                                                 -\nopengl                                    pygpt:opengl                       :opengl                                                       -\npulseaudio                                pygpt:pulseaudio                   -                                                             -\nserial-port                               pygpt:serial-port                  -                                                             -\nunity7                                    pygpt:unity7                       :unity7                                                       -\nwayland                                   pygpt:wayland                      :wayland                                                      -\nx11                                       pygpt:x11                          :x11                                                     \n\nSecond question: OS: Ubuntu 24.04.1 LTS"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 87,
    "title": "Fails to start: Couldn't load VAAPI library",
    "author": "dsidlo",
    "state": "closed",
    "created_at": "2025-01-16T04:06:03Z",
    "updated_at": "2025-02-01T18:27:58Z",
    "labels": [
      "bug"
    ],
    "body": "PyGPT fails to start.\r\nI'm using Ubuntu 22.04.5 LTS.\r\n\r\n```\r\n PyGPT    2.4.48 build 2025-01-16 (Linux, x86_64)\r\n Author:  Marcin Szczyglinski\r\n GitHub:  https://github.com/szczyglis-dev/py-gpt\r\n Website: https://pygpt.net\r\n Email:   info@pygpt.net\r\n===================================================\r\n\r\nInitializing...\r\nLoaded config: /home/dsidlo/snap/pygpt/342/.config/pygpt-net/config.json\r\nLoaded models: /home/dsidlo/snap/pygpt/342/.config/pygpt-net/models.json\r\nqt.multimedia.ffmpeg.libsymbolsresolver: Couldn't load VAAPI library\r\n[719037:719037:0115/195342.067047:FATAL:credentials.cc(126)] Check failed: . : Permission denied (13)\r\n/snap/pygpt/342/snaprun.sh: line 28: 719037 Trace/breakpoint trap   (core dumped) python3 $SNAP/src/pygpt_net/app.py \"$@\"\r\n```\r\n\r\nI tried to install VAAPI using...\r\n```\r\napt-get install libva-dev libva-drm2 libva-x11-2 vainfo\r\n```\r\n... but that did not help.\r\n\r\n",
    "comments": [
      {
        "user": "dsidlo",
        "body": "@szczyglis-dev Can I bypass the feature with an option? I don't mind if video features are not available."
      },
      {
        "user": "szczyglis-dev",
        "body": "No, there is a problem with permissions; VAAPI is not the issue here.\r\n\r\nIt is related to this topic:\r\n\r\nhttps://github.com/szczyglis-dev/py-gpt/issues/85\r\n\r\nThere are some problems in 22.04, like here:\r\n\r\nhttps://forum.snapcraft.io/t/permissions-problem-with-some-of-snap-packages-after-updating-ubuntu-from-20-04-to-22-04/30119\r\n\r\nI'll try to take a closer look at this in the coming days.\r\n\r\nIn the meantime, what does the following command show?\r\n\r\n`snap connections pygpt`"
      },
      {
        "user": "dsidlo",
        "body": "Strange... I tried to roll back and get the failure in the prior version as well. I do remember an attempt to upgrade the OS before my last reboot, that failed to perform the upgrade, so it seems that video drivers may have gotten messed up then.\r\nThe issues is likely not due to the new package."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 85,
    "title": "Ubuntu 24.04 Install Error",
    "author": "sarahkevinking",
    "state": "closed",
    "created_at": "2024-12-29T20:15:47Z",
    "updated_at": "2025-02-01T18:27:58Z",
    "labels": [
      "bug"
    ],
    "body": "I was unable to launch the application after installing through the App Center. \r\nVersion: latest/stable 2.4.46\r\nBrand new machine Ubunutu 24.04\r\n\r\nI tried opening the application through the Terminal to capture a stack trace.\r\n\r\n```\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/iconengines/KIconEnginePlugin.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/iconengines/libqsvgicon.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqgif.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqico.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqjpeg.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqgif.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqico.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqjpeg.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqpdf.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\nqt.core.plugin.loader: In /snap/pygpt/338/kf5/usr/lib/x86_64-linux-gnu/qt5/plugins/imageformats/libqsvg.so:\r\n  Plugin uses incompatible Qt library (5.15.0) [release]\r\n[33830:33830:1229/120327.178319:FATAL:credentials.cc(126)] Check failed: . : Permission denied (13)\r\n/snap/pygpt/338/snaprun.sh: line 28: 33830 Trace/breakpoint trap   (core dumped) python3 $SNAP/src/pygpt_net/app.py \"$@\"\r\n```",
    "comments": [
      {
        "user": "d10r",
        "body": "I managed to run it on Ubuntu 24.04 by installing from pypi (see https://pypi.org/project/pygpt-net/).\r\nHowever that installs version 2.1.3, which is from March 2024.\r\nThe reason seems to be that [from 2.1.4. on](https://github.com/szczyglis-dev/py-gpt/commit/9d347f0d4f6c959f5c25fa0992dc6e8835ae8712#diff-50c86b7ed8ac2cf95bd48334961bf0530cdc77b5a56f852c5c61b89d735fd711), it requires `python = \">=3.10,<3.12\"` (before that, it was `python = \">=3.10,<3.13\"`). Ubuntu 24.04 has Python 3.12 installed by default, which is declared incompatible with more recent releases.\r\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "Support for Python 3.12 and improved compatibility with the new Ubuntu versions in Snap will be released around next week (possibly even this week)."
      },
      {
        "user": "szczyglis-dev",
        "body": "1. Support for Python `3.12` was added today (`v2.4.47`).\r\n\r\n2. As for Snap and the new Ubuntu  it's interesting. I downloaded the latest ISO (`24.04.1 LTS`), installed it on VBox, booted up the fresh system, and installed PyGPT from Snap via:\r\n\r\n`sudo snap install pygpt`\r\n\r\nIt starts without any issues:\r\n\r\n![ubuntu24](https://github.com/user-attachments/assets/5f8b35c9-37e4-4525-97ed-40ed1b21bbfb)\r\n\r\nMaybe it's a permissions issue for Snaps? Maybe AppArmor is blocking the app?\r\n\r\nDoes it run in \"devmode\"?\r\n\r\nhttps://askubuntu.com/questions/783945/what-is-devmode-for-snaps\r\n\r\n`sudo snap install pygpt --devmode`\r\n\r\nIf so, it's almost certainly a permissions issue, because really the important error is only this one:\r\n\r\n```\r\n[33830:33830:1229/120327.178319:FATAL:credentials.cc(126)] Check failed: . : Permission denied (13)\r\n```\r\n\r\nYou can ignore the Qt incompatibility warnings, they are just warnings."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 76,
    "title": "Feature Request: DeepSeek Integration",
    "author": "Hade231",
    "state": "closed",
    "created_at": "2024-11-21T06:15:28Z",
    "updated_at": "2025-01-31T22:39:04Z",
    "labels": [
      "feature"
    ],
    "body": "Please add **DeepSeek** to tthe app. **DeepSeek** has some great capabilities with better pricing models than Open AI.\r\n\r\nThank you.  ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "DeepSeek support was added in `v2.5.0`."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 89,
    "title": "Windows installer pygpt-2.4.51 does not install correctly.",
    "author": "FarbrorMartin",
    "state": "closed",
    "created_at": "2025-01-17T12:40:52Z",
    "updated_at": "2025-01-27T18:47:50Z",
    "labels": [
      "bug"
    ],
    "body": "Tried to install today. Had no previous installation. After installing the program does not run. There are several errors.\npygpt-2.4.51",
    "comments": [
      {
        "user": "FarbrorMartin",
        "body": "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n===================================================\n PyGPT    2.4.51 build 2025-01-17 (Windows, AMD64)\n Author:  Marcin Szczyglinski\n GitHub:  https://github.com/szczyglis-dev/py-gpt\n Website: https://pygpt.net\n Email:   info@pygpt.net\n===================================================\n\nInitializing...\nLoaded config: C:\\Users\\abc\\.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\abc\\.config\\pygpt-net\\models.json\ndoh set to \"\"  --  SystemOnly\nChecking for updates...\nNo updates available.\nTraceback (most recent call last):\n  File \"app.py\", line 394, in <module>\n  File \"app.py\", line 390, in run\n  File \"launcher.py\", line 257, in run\n  File \"ui\\main.py\", line 198, in setup\n  File \"controller\\__init__.py\", line 125, in post_setup\n  File \"controller\\dialogs\\info.py\", line 62, in toggle\n  File \"controller\\dialogs\\info.py\", line 119, in update_menu\nKeyError: 'info.about'\n[23020] Failed to execute script 'app' due to unhandled exception!"
      },
      {
        "user": "szczyglis-dev",
        "body": "Fixed in `v2.4.53`. Thanks!"
      },
      {
        "user": "apsjohn",
        "body": "I got this as well today!\n\n[nltk_data] Downloading package punkt_tab to D:\\AppData\\Roaming\\PyGPT\\\n[nltk_data]     _internal\\llama_index\\core\\_static/nltk_cache...\n[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\nUser config: C:\\Users\\johna\\.config\\pygpt-net\\config.json not found.\n===================================================\n PyGPT    2.4.57 build 2025-01-19 (Windows, AMD64)\n Author:  Marcin Szczyglinski\n GitHub:  https://github.com/szczyglis-dev/py-gpt\n Website: https://pygpt.net\n Email:   info@pygpt.net\n===================================================\n\nInitializing...\n[DB] Installed database: C:\\Users\\johna\\.config\\pygpt-net\\db.sqlite\nLoaded config: C:\\Users\\johna\\.config\\pygpt-net\\config.json\nLoaded models: C:\\Users\\johna\\.config\\pygpt-net\\models.json\n[DB] Migrating database...\n[DB] Executed DB migration: 20231227152900\n[DB] Executed DB migration: 20231230095000\n[DB] Executed DB migration: 20231231230000\n[DB] Executed DB migration: 20240106060000\n[DB] Executed DB migration: 20240107060000\n[DB] Executed DB migration: 20240222160000\n[DB] Executed DB migration: 20240223050000\n[DB] Executed DB migration: 20240303190000\n[DB] Executed DB migration: 20240408180000\n[DB] Executed DB migration: 20240426050000\n[DB] Executed DB migration: 20240501030000\n[DB] Executed DB migration: 20241122130000\n[DB] Executed DB migration: 20241126170000\n[DB] Executed DB migration: 20241215110000\ndoh set to \"\"  --  SystemOnly\nChecking for updates...\nNo updates available.\n\n\n---\nDownloaded windows msi file from official site."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 58,
    "title": "Unable to open the microphone",
    "author": "kernelhacks",
    "state": "open",
    "created_at": "2024-06-14T05:31:04Z",
    "updated_at": "2025-01-19T13:07:09Z",
    "labels": [],
    "body": "Hi I'm unable to open the MIC on the APP, this is the error \r\n\r\nException: [Errno -9996] Invalid input device (no default output device)\r\nType: OSErrorMessage: [Errno -9996] Invalid input device (no default output device)\r\nTraceback:   File \"/snap/pygpt/238/src/pygpt_net/plugin/audio_input/simple.py\", line 88, in start_recording\r\n    self.stream = self.p.open(format=pyaudio.paInt16,\r\n  File \"/snap/pygpt/238/lib/python3.10/site-packages/pyaudio/__init__.py\", line 639, in open\r\n    stream = PyAudio.Stream(self, *args, **kwargs)\r\n  File \"/snap/pygpt/238/lib/python3.10/site-packages/pyaudio/__init__.py\", line 441, in __init__\r\n    self._stream = pa.open(**arguments)\r\n\r\nI thought that the issues were related to Pyaudio so I tested the Pyaudio library with a little script to record my voice and is working, so I'm not sure what is causing this.\r\nMy Environment:\r\nOS: Ubuntu 22.04.4 LTS\r\nCPU: Intel Xeon(R) CPU E5-2690 v4 @ 2.60GHz  56\r\nMem: 128\r\nPython Ver: 3\r\n  ",
    "comments": [
      {
        "user": "kernelhacks",
        "body": "I ran the source code, and it is working fine. it seems that the snap installation process has the issues described above."
      },
      {
        "user": "szczyglis-dev",
        "body": "Try this: \r\n\r\n`sudo snap connect pygpt:audio-record :audio-record`"
      },
      {
        "user": "077531",
        "body": "me neither. I have tried snap and python installation with python 3.11.6 and no way.\r\n```bash\r\nAudio Input: Exception: 'NoneType' object has no attribute 'agent_call'\r\nType: AttributeErrorMessage: 'NoneType' object has no attribute 'agent_call'\r\nTraceback:   File \"/home/user/.pyenv/versions/3.11.6/envs/my-pygpt-env/lib/python3.11/site-packages/pygpt_net/plugin/audio_input/worker.py\", line 82, in handle_simple\r\n    self.response(transcript)\r\n  File \"/home/user/.pyenv/versions/3.11.6/envs/my-pygpt-env/lib/python3.11/site-packages/typing_extensions.py\", line 2853, in wrapper\r\n    return arg(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.11.6/envs/my-pygpt-env/lib/python3.11/site-packages/pygpt_net/plugin/base/worker.py\", line 74, in response\r\n    self.reply(response, extra_data)\r\n  File \"/home/user/.pyenv/versions/3.11.6/envs/my-pygpt-env/lib/python3.11/site-packages/pygpt_net/plugin/base/worker.py\", line 84, in reply\r\n    if self.ctx.agent_call and self.plugin is not None:\r\n       ^^^^^^^^^^^^^^^^^^^\r\n```       \r\n\r\n# System Report Details\r\n\r\n## Report Details\r\n- **Generated Date:** 2024-11-20 19:45:53\r\n\r\n## Hardware Information:\r\n- **Hardware Model:** MEDION H81H3-EM2\r\n- **Memory:** 16.0 GiB\r\n- **Processor:** Intel Core i7-4790  8\r\n- **Graphics:** NVIDIA GeForce GTX 745\r\n- **Disk Capacity:** 480.1 GB\r\n\r\n## Software Information:\r\n- **Firmware Version:** H81EM2W08.309\r\n- **OS Name:** Ubuntu 24.04.1 LTS\r\n- **OS Build:** (null)\r\n- **OS Type:** 64-bit\r\n- **GNOME Version:** 46\r\n- **System Windows:** X11\r\n- **Kernel version:** Linux 6.8.0-48-generic\r\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 88,
    "title": "Files I/O: Issue",
    "author": "ntscheduler",
    "state": "closed",
    "created_at": "2025-01-16T06:03:40Z",
    "updated_at": "2025-01-17T14:09:29Z",
    "labels": [
      "bug"
    ],
    "body": "Files I/O: Exception: 'path'\r\nType: KeyErrorMessage: 'path'\r\nTraceback:   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pygpt_net/plugin/cmd_files/worker.py\", line 163, in cmd_save_file\r\n    path = self.prepare_path(item[\"params\"]['path'])\r\n                             ~~~~~~~~~~~~~~^^^^^^^^\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in `v2.4.52`. Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 53,
    "title": "Bug: Missing menubar on linux",
    "author": "RawEnchilada",
    "state": "closed",
    "created_at": "2024-05-14T15:42:21Z",
    "updated_at": "2025-01-16T12:37:20Z",
    "labels": [
      "bug"
    ],
    "body": "![image](https://github.com/szczyglis-dev/py-gpt/assets/58312474/9d67acc6-6c27-43cc-8700-080c055822e7)\r\n\r\nAfter installing pygpt-net in a python virtual environment, and running the app, the settings menu opens so that i can enter my api key, but i cannot open it again because there is no top menu bar.\r\n\r\nMy system:\r\nOperating System: EndeavourOS \r\nKDE Plasma Version: 6.0.4\r\nKDE Frameworks Version: 6.1.0\r\nQt Version: 6.7.0\r\nKernel Version: 6.8.9-arch1-2 (64-bit)\r\nGraphics Platform: Wayland",
    "comments": [
      {
        "user": "mikeybob",
        "body": "I've run into this on Fedora 40 KDE. There's something about the global menu widget being present in any panel on the desktop that seems to cause it. I hope this helps with finding a solution. I discovered this by accident. "
      },
      {
        "user": "szczyglis-dev",
        "body": "Please try now and give me a feedback. In version `2.4.34`, I have forced the disabling of menu integration in PySide with the system menu. This should solve the problem."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 72,
    "title": "proxy",
    "author": "mohammadhoseinazaddel",
    "state": "closed",
    "created_at": "2024-11-12T10:33:35Z",
    "updated_at": "2025-01-16T12:36:06Z",
    "labels": [
      "bug",
      "feature"
    ],
    "body": "i wanted to use proxy on it to connect through it but I got \r\nException: Using SOCKS proxy, but the 'socksio' package is not installed. Make sure to install httpx using `pip install httpx[socks]`.\r\nType: ImportErrorMessage: Using SOCKS proxy, but the 'socksio' package is not installed. Make sure to install httpx using `pip install httpx[socks]`.\r\nTraceback:   File \"httpx\\_client.py\", line 705, in __init__\r\n  File \"httpx\\_client.py\", line 708, in <dictcomp>\r\n  File \"httpx\\_client.py\", line 762, in _init_proxy_transport\r\n  File \"httpx\\_transports\\default.py\", line 178, in __init__\r\nin windows desktop\r\nI set HTTP_PROXY=socks5://127.0.0.1:2080 and HTTsP_PROXY=socks5://127.0.0.1:2080\r\n![image](https://github.com/user-attachments/assets/e1fa3622-cb55-4811-bfe9-b530f2c372eb)\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In version [2.4.12](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.12) (2024-11-15):\r\n\r\n- `httpx-socks` has been integrated into the compiled versions (Windows and Linux) - enabling support for HTTP/SOCKS proxies.\r\n- proxy settings have been added under: `Config -> Settings -> Proxy URL`, or you can use the environment variables: `HTTP_PROXY`, `HTTPS_PROXY`.\r\n\r\n"
      },
      {
        "user": "mohammadhoseinazaddel",
        "body": "> In version [2.4.12](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.12) (2024-11-15):\r\n> \r\n> * `httpx-socks` has been integrated into the compiled versions (Windows and Linux) - enabling support for HTTP/SOCKS proxies.\r\n> * proxy settings have been added under: `Config -> Settings -> Proxy URL`, or you can use the environment variables: `HTTP_PROXY`, `HTTPS_PROXY`.\r\n\r\nThnk you man thank youuu i will try it soon and give you feedback dor your attempt "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 61,
    "title": "\"Ask with Screenshot\" keyboard hotkey",
    "author": "bukit-kronik",
    "state": "closed",
    "created_at": "2024-06-25T15:54:37Z",
    "updated_at": "2025-01-16T12:35:11Z",
    "labels": [
      "feature"
    ],
    "body": null,
    "comments": [
      {
        "user": "gfsysa",
        "body": "https://www.autohotkey.com/\r\nhttps://www.keyboardmaestro.com/main/"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 65,
    "title": "Using custom embedding endpoint",
    "author": "cmkeane-agi",
    "state": "closed",
    "created_at": "2024-07-12T18:58:15Z",
    "updated_at": "2025-01-16T12:34:53Z",
    "labels": [
      "feature"
    ],
    "body": "I am trying to get the system to recognize a custom embedding endpoint to use a special embedding model.  The system serving it is openai api compliant with the /v1/embeddings path.  My full embedding endpoint is:  http://embedder.example.com:8000/v1/embeddings.\r\n\r\nI have tried in the llamaindex embedding settings to set it to openai and change the OPENAI_API_BASE to http://embedder.example.com:8000.  Also tried with adding /v1 and /v1/embeddings.   It always timeouts with can't connect.  When I look at the embedder log, it shows no attempts.\r\n\r\nI have no problem otherwise utilizing this endpoint directly in python, for instance.\r\n\r\nShould I be taking another approach?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hmm... a custom endpoint should work with Llama index as long as it is compatible with the OpenAI API.\r\n\r\nHave you tried passing the endpoint address as an argument in Embeddings -> Provider **kwargs?\r\n\r\nTry providing `http://embedder.example.com:8000/v1` here and set a small timeout, for example, 5 seconds (default is 60)\r\n\r\n![embed](https://github.com/user-attachments/assets/77748e39-040b-4b1e-88cd-6c35dc3eb686)\r\n"
      },
      {
        "user": "RepairYourTech",
        "body": "would that work to use my local llama 3.2 3b?"
      },
      {
        "user": "proitservices",
        "body": "I crafted a simple embeddings replacement using elmo. It's a 1:1 drop in for openAI ada \r\nhttps://github.com/proitservices/elmo_embedding_api.git\r\n\r\nruns in docker, provides 1024 vectors "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 82,
    "title": "Broke system - Debian 12 - Installed through Discover - KDE",
    "author": "lilacdev",
    "state": "closed",
    "created_at": "2024-11-27T13:30:20Z",
    "updated_at": "2025-01-16T04:57:30Z",
    "labels": [
      "bug"
    ],
    "body": "Hi,\r\n\r\nJust to let you know trying to install your application broke my system.\r\n\r\nFirst it froze the system, then I lost all data in my Docker containers. After investigation, I found that you install Docker through Snap.\r\n\r\nNot to mention that Snap can be painful for some of us, you should not install packages (especially packages like Docker) without checking if an existing one is already up and running...\r\n\r\nI managed to uninstall all snap (Docker + PyGPT) and then a full reboot brought back all my stuff. Perhaps it will help anyone encountering this error.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Yes, you are absolutely right, sorry for the confusion.\r\n\r\nSince version `2.4.35` Docker has been removed from the dependencies in snapcraft.yml.\r\n\r\nRegards."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 79,
    "title": "'charmap' codec can't encode character \"\\u0131'",
    "author": "purpleturtle1988",
    "state": "closed",
    "created_at": "2024-11-25T08:23:59Z",
    "updated_at": "2025-01-16T04:57:30Z",
    "labels": [
      "bug"
    ],
    "body": "I have encountered an issue when processing certain PDF documents with PyGpt. The following error occurs:\r\n\r\nError reading attachments: 'charmap' codec can't encode character \"\\u0131'\r\n\r\nCould you please assist me in resolving this error, or is there an existing solution?\r\n\r\nAdditionally, I would like to thank you for quickly resolving the issue from yesterday. Many PDF files can now be read again.\r\n\r\nThank you very much for your help!\r\n\r\nBest regards",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, UTF-8 support as the default encoding was added in version [2.4.32](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.31). Try again by re-uploading the attachment.\r\n\r\nRegards!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 78,
    "title": "Error reading Attachments: 'NoneType' object has no attribute 'append'",
    "author": "purpleturtle1988",
    "state": "closed",
    "created_at": "2024-11-24T12:06:12Z",
    "updated_at": "2025-01-16T04:57:29Z",
    "labels": [
      "bug"
    ],
    "body": "Dear Developer,\r\n\r\nI've encountered a problem that occurs when I try to upload a file, such as a PDF, for analysis. Each time, I receive the following error message: \"Error reading Attachments: 'NoneType' object has no attribute 'append'\".\r\n\r\nI would greatly appreciate your assistance in resolving this issue.\r\n\r\nThank you in advance for your support.\r\n\r\nBest regards",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in: [2.4.28](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.28)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 77,
    "title": "On first run: error: self.window.controller.chat.attachment.has_context(ctx.meta) : Message \"object of type 'NoneType' has no len()\"",
    "author": "WaterSibilantFalling",
    "state": "closed",
    "created_at": "2024-11-24T04:46:11Z",
    "updated_at": "2025-01-16T04:57:29Z",
    "labels": [
      "bug"
    ],
    "body": "\r\nInstalled via pip install ... exactly as per the instructions. \r\nLinux Isis 6.0.0-5-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.0.10-2 (2022-12-01) x86_64 GNU/Linux\r\n\r\nThis is the error\r\n\r\n```\r\n[event] Dispatch end: KernelEvent: kernel.input.user (379)\r\n[event] Dispatch begin: KernelEvent: kernel.response.failed (398)\r\n[event] Before handle: \r\n[chat] Output ERROR: object of type 'NoneType' has no len()\r\nType: TypeErrorMessage: object of type 'NoneType' has no len()\r\nTraceback:   File \"/usr/local/bin/py-gpt/src/pygpt_net/core/bridge/worker.py\", line 47, in run\r\n    self.handle_additional_context()\r\n  File \"/usr/local/bin/py-gpt/src/pygpt_net/core/bridge/worker.py\", line 115, in handle_additional_context\r\n    if not self.window.controller.chat.attachment.has_context(ctx.meta):\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/bin/py-gpt/src/pygpt_net/controller/chat/attachment.py\", line 166, in has_context\r\n    return len(meta.additional_ctx) > 0\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\nas requested in the contributing guidelines, this is the same with log-leve as DEBUG\r\n\r\n\r\n```\r\n** (WebKitWebProcess:15731): WARNING **: 17:28:11.851: The GStreamer FDK AAC plugin is missing, AAC playback is unlikely to work.\r\n[LOGGER] Changing log level to: debug\r\n** DEBUG level enabled\r\n[event] Dispatch begin: AppEvent: input.sent (377)\r\n[event] Before handle: {\"name\": \"input.sent\", \"data\": {}, \"stop\": false, \"internal\": false}\r\n[app] Event: input.sent\r\n[event] After handle: {\"name\": \"input.sent\", \"data\": {}, \"stop\": true, \"internal\": false}\r\n[event] Dispatch end: AppEvent: input.sent (377)\r\n[event] Dispatch begin: Event: user.send (378)\r\n[event] Before handle: {\"name\": \"user.send\", \"data\": {\"value\": \"this is a test. Please reply only with \\\"hello world\\\"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"user.send\", \"data\": {\"value\": \"this is a test. Please reply only with \\\"hello world\\\"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: user.send (378)\r\n[event] Dispatch begin: KernelEvent: kernel.input.user (379)\r\n[event] Before handle: \r\n[event] Dispatch begin: KernelEvent: kernel.state.idle (379)\r\n[event] Before handle: {\"name\": \"kernel.state.idle\", \"data\": {\"id\": \"chat\"}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: KernelEvent: kernel.state.idle (379)\r\n[chat] Begin.\r\n[chat] Input prompt: this is a test. Please reply only with \"hello world\"\r\n[event] Dispatch begin: Event: input.before (380)\r\n[event] Before handle: {\"name\": \"input.before\", \"data\": {\"value\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"mode\": \"chat\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"input.before\", \"data\": {\"value\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"mode\": \"chat\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: input.before (380)\r\n[event] Dispatch begin: KernelEvent: kernel.state.busy (381)\r\n[event] Before handle: {\"name\": \"kernel.state.busy\", \"data\": {\"id\": \"chat\", \"msg\": \"Please wait...\"}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: KernelEvent: kernel.state.busy (381)\r\n[event] Dispatch begin: RenderEvent: render.clear.input (0)\r\n[event] Before handle: {\"name\": \"render.clear.input\", \"data\": {}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: RenderEvent: render.clear.input (0)\r\n[event] Dispatch begin: KernelEvent: kernel.status (384)\r\n[event] Before handle: {\"name\": \"kernel.status\", \"data\": {\"status\": \"Please wait...\"}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: KernelEvent: kernel.status (384)\r\n[event] Dispatch begin: Event: user.name (385)\r\n[event] Before handle: {\"name\": \"user.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"user.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: user.name (385)\r\n[event] Dispatch begin: Event: ai.name (386)\r\n[event] Before handle: {\"name\": \"ai.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"ai.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: ai.name (386)\r\n[chat] [ctx] INPUT: {\"id\": null, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-e68a-48c2-a3dc-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}\r\n[event] Dispatch begin: Event: ctx.before (387)\r\n[event] Before handle: {\"name\": \"ctx.before\", \"data\": {}, \"ctx\": {\"id\": null, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"ctx.before\", \"data\": {}, \"ctx\": {\"id\": null, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-1111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: ctx.before (387)\r\n[event] Dispatch begin: Event: pre.prompt (388)\r\n[event] Before handle: {\"name\": \"pre.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant.\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"pre.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant.\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: pre.prompt (388)\r\n[event] Dispatch begin: Event: post.prompt (390)\r\n[event] Before handle: {\"name\": \"post.prompt\", \"data\": {\"mode\": \"chat\", \"reply\": false, \"internal\": false, \"value\": \"You are a helpful assistant.\", \"is_expert\": false}, \"ctx\": {\"id\": null, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-1111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"post.prompt\", \"data\": {\"mode\": \"chat\", \"reply\": false, \"internal\": false, \"value\": \"You are a helpful assistant.\", \"is_expert\": false}, \"ctx\": {\"id\": null, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-1111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: post.prompt (390)\r\n[chat] Appending input to chat window...\r\n[event] Dispatch begin: RenderEvent: render.begin (0)\r\n[event] Before handle: \r\n[event] Dispatch end: RenderEvent: render.begin (0)\r\n[event] Dispatch begin: RenderEvent: render.input.append (0)\r\n[event] Before handle: \r\n[event] Dispatch end: RenderEvent: render.input.append (0)\r\n[event] Dispatch begin: Event: cmd.syntax (393)\r\n[event] Before handle: {\"name\": \"cmd.syntax\", \"data\": {\"syntax\": [], \"cmd\": []}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"cmd.syntax\", \"data\": {\"syntax\": [], \"cmd\": []}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: cmd.syntax (393)\r\n[event] Dispatch begin: AppEvent: input.call (394)\r\n[event] Before handle: {\"name\": \"input.call\", \"data\": {}, \"stop\": false, \"internal\": false}\r\n[app] Event: input.call\r\n[event] After handle: {\"name\": \"input.call\", \"data\": {}, \"stop\": true, \"internal\": false}\r\n[event] Dispatch end: AppEvent: input.call (394)\r\n[event] Dispatch begin: KernelEvent: kernel.request (395)\r\n[event] Before handle: \r\n[bridge] Request...\r\n{'assistant_id': '', 'attachments': '{}', 'ctx': '{\\'id\\': 4, \\'meta\\': {\\'id\\': 1, \\'external_id\\': None, \\'uuid\\': \\'d69e0ef5-1111-1111-1111-6b7b9016effa\\', \\'name\\': \\'New\\', \\'date\\': \\'2024-11-24\\', \\'created\\': 1732412721, \\'updated\\': 1732422435, \\'indexed\\': 0, \\'mode\\': \\'chat\\', \\'model\\': \\'gpt-4o-mini\\', \\'last_mode\\': \\'chat\\', \\'last_model\\': \\'gpt-4o-mini\\', \\'thread\\': None, \\'assistant\\': None, \\'preset\\': None, \\'run\\': None, \\'status\\': None, \\'extra\\': None, \\'initialized\\': False, \\'deleted\\': False, \\'important\\': False, \\'archived\\': False, \\'label\\': 0, \\'indexes\\': {}, \\'additional_ctx\\': None, \\'group_id\\': 0, \\'root_id\\': None, \\'parent_id\\': None, \\'owner_uuid\\': None}, \\'meta_id\\': None, \\'external_id\\': None, \\'cmds\\': [], \\'results\\': [], \\'urls\\': [], \\'images\\': [], \\'images_before\\': [], \\'files\\': [], \\'attachments\\': [], \\'reply\\': False, \\'input\\': \\'this is a test. Please reply only with \"hello world\"\\', \\'output\\': None, \\'mode\\': \\'chat\\', \\'model\\': \\'gpt-4o-mini\\', \\'thread\\': None, \\'msg_id\\': None, \\'run_id\\': None, \\'input_name\\': \\'\\', \\'output_name\\': \\'\\', \\'input_timestamp\\': 1732422785, \\'output_timestamp\\': 1732422785, \\'hidden_input\\': None, \\'hidden_output\\': None, \\'input_tokens\\': 0, \\'output_tokens\\': 0, \\'total_tokens\\': 0, \\'extra\\': {}, \\'extra_ctx\\': None, \\'current\\': True, \\'internal\\': False, \\'is_vision\\': False, \\'idx\\': 0, \\'first\\': False, \\'agent_call\\': False, \\'tool_calls\\': [], \\'index_meta\\': {}, \\'doc_ids\\': [], \\'sub_calls\\': 0, \\'sub_call\\': False, \\'sub_reply\\': False, \\'hidden\\': False, \\'live\\': True}', 'external_functions': '[]', 'file_ids': '[]', 'history': '4', 'idx': 'base', 'idx_mode': 'chat', 'max_tokens': '1024', 'mode': 'chat', 'model': \"{'id': 'gpt-4o-mini', 'name': 'gpt-4o-mini', 'mode': 'chat,assistant,langchain,llama_index,vision,agent,agent_llama,expert', 'langchain': {'provider': 'openai', 'mode': ['chat'], 'args': [{'name': 'model_name', 'value': 'gpt-4o-mini', 'type': 'str'}], 'env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}]}, 'ctx': 128000, 'tokens': 4096, 'default': False, 'multimodal': '', 'langchain.provider': 'openai', 'langchain.mode': 'chat', 'langchain.args': [{'name': 'model_name', 'value': 'gpt-4o-mini', 'type': 'str'}], 'langchain.env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}], 'llama_index.provider': 'openai', 'llama_index.mode': 'chat', 'llama_index.args': [{'name': 'model', 'value': 'gpt-4o-mini', 'type': 'str'}], 'llama_index.env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}]}\", 'parent_mode': 'chat', 'prompt': 'this is a test. Please reply only with \"hello world\"', 'stream': 'False', 'system_prompt': 'You are a helpful assistant.', 'system_prompt_raw': 'You are a helpful assistant.', 'temperature': '1.0', 'thread_id': '', 'tools_outputs': '[]'}\r\n[event] Dispatch begin: Event: mode.before (395)\r\n[event] Before handle: {\"name\": \"mode.before\", \"data\": {\"value\": \"chat\", \"prompt\": \"this is a test. Please reply only with \\\"hello world\\\"\"}, \"ctx\": {\"id\": 4, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-1111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] After handle: {\"name\": \"mode.before\", \"data\": {\"value\": \"chat\", \"prompt\": \"this is a test. Please reply only with \\\"hello world\\\"\"}, \"ctx\": {\"id\": 4, \"meta\": {\"id\": 1, \"external_id\": null, \"uuid\": \"d69e0ef5-1111-1111-1111-6b7b9016effa\", \"name\": \"New\", \"date\": \"2024-11-24\", \"created\": 1732412721, \"updated\": 1732422435, \"indexed\": 0, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"last_mode\": \"chat\", \"last_model\": \"gpt-4o-mini\", \"thread\": null, \"assistant\": null, \"preset\": null, \"run\": null, \"status\": null, \"extra\": null, \"initialized\": false, \"deleted\": false, \"important\": false, \"archived\": false, \"label\": 0, \"indexes\": {}, \"additional_ctx\": null, \"group_id\": 0, \"root_id\": null, \"parent_id\": null, \"owner_uuid\": null}, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"images_before\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"this is a test. Please reply only with \\\"hello world\\\"\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4o-mini\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1732422785, \"output_timestamp\": 1732422785, \"hidden_input\": null, \"hidden_output\": null, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": {}, \"extra_ctx\": null, \"current\": true, \"internal\": false, \"is_vision\": false, \"idx\": 0, \"first\": false, \"agent_call\": false, \"tool_calls\": [], \"index_meta\": {}, \"doc_ids\": [], \"sub_calls\": 0, \"sub_call\": false, \"sub_reply\": false, \"hidden\": false, \"live\": true}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: Event: mode.before (395)\r\n[bridge] After inline...\r\n{'assistant_id': '', 'attachments': '{}', 'ctx': '{\\'id\\': 4, \\'meta\\': {\\'id\\': 1, \\'external_id\\': None, \\'uuid\\': \\'d69e0ef5-1111-1111-1111-6b7b9016effa\\', \\'name\\': \\'New\\', \\'date\\': \\'2024-11-24\\', \\'created\\': 1732412721, \\'updated\\': 1732422435, \\'indexed\\': 0, \\'mode\\': \\'chat\\', \\'model\\': \\'gpt-4o-mini\\', \\'last_mode\\': \\'chat\\', \\'last_model\\': \\'gpt-4o-mini\\', \\'thread\\': None, \\'assistant\\': None, \\'preset\\': None, \\'run\\': None, \\'status\\': None, \\'extra\\': None, \\'initialized\\': False, \\'deleted\\': False, \\'important\\': False, \\'archived\\': False, \\'label\\': 0, \\'indexes\\': {}, \\'additional_ctx\\': None, \\'group_id\\': 0, \\'root_id\\': None, \\'parent_id\\': None, \\'owner_uuid\\': None}, \\'meta_id\\': None, \\'external_id\\': None, \\'cmds\\': [], \\'results\\': [], \\'urls\\': [], \\'images\\': [], \\'images_before\\': [], \\'files\\': [], \\'attachments\\': [], \\'reply\\': False, \\'input\\': \\'this is a test. Please reply only with \"hello world\"\\', \\'output\\': None, \\'mode\\': \\'chat\\', \\'model\\': \\'gpt-4o-mini\\', \\'thread\\': None, \\'msg_id\\': None, \\'run_id\\': None, \\'input_name\\': \\'\\', \\'output_name\\': \\'\\', \\'input_timestamp\\': 1732422785, \\'output_timestamp\\': 1732422785, \\'hidden_input\\': None, \\'hidden_output\\': None, \\'input_tokens\\': 0, \\'output_tokens\\': 0, \\'total_tokens\\': 0, \\'extra\\': {}, \\'extra_ctx\\': None, \\'current\\': True, \\'internal\\': False, \\'is_vision\\': False, \\'idx\\': 0, \\'first\\': False, \\'agent_call\\': False, \\'tool_calls\\': [], \\'index_meta\\': {}, \\'doc_ids\\': [], \\'sub_calls\\': 0, \\'sub_call\\': False, \\'sub_reply\\': False, \\'hidden\\': False, \\'live\\': True}', 'external_functions': '[]', 'file_ids': '[]', 'history': '4', 'idx': 'base', 'idx_mode': 'chat', 'max_tokens': '1024', 'mode': 'chat', 'model': \"{'id': 'gpt-4o-mini', 'name': 'gpt-4o-mini', 'mode': 'chat,assistant,langchain,llama_index,vision,agent,agent_llama,expert', 'langchain': {'provider': 'openai', 'mode': ['chat'], 'args': [{'name': 'model_name', 'value': 'gpt-4o-mini', 'type': 'str'}], 'env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}]}, 'ctx': 128000, 'tokens': 4096, 'default': False, 'multimodal': '', 'langchain.provider': 'openai', 'langchain.mode': 'chat', 'langchain.args': [{'name': 'model_name', 'value': 'gpt-4o-mini', 'type': 'str'}], 'langchain.env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}], 'llama_index.provider': 'openai', 'llama_index.mode': 'chat', 'llama_index.args': [{'name': 'model', 'value': 'gpt-4o-mini', 'type': 'str'}], 'llama_index.env': [{'name': 'OPENAI_API_KEY', 'value': '{api_key}'}, {'name': 'OPENAI_API_BASE', 'value': '{api_endpoint}'}]}\", 'parent_mode': 'chat', 'prompt': 'this is a test. Please reply only with \"hello world\"', 'stream': 'False', 'system_prompt': 'You are a helpful assistant.', 'system_prompt_raw': 'You are a helpful assistant.', 'temperature': '1.0', 'thread_id': '', 'tools_outputs': '[]'}\r\n[bridge] Starting worker (async)...\r\n[event] Dispatch end: KernelEvent: kernel.request (395)\r\n[bridge] Worker started.\r\n[event] Dispatch end: KernelEvent: kernel.input.user (379)\r\n[event] Dispatch begin: KernelEvent: kernel.response.failed (398)\r\n[event] Before handle: \r\n[chat] Output ERROR: object of type 'NoneType' has no len()\r\nType: TypeErrorMessage: object of type 'NoneType' has no len()\r\nTraceback:   File \"/usr/local/bin/py-gpt/src/pygpt_net/core/bridge/worker.py\", line 47, in run\r\n    self.handle_additional_context()\r\n  File \"/usr/local/bin/py-gpt/src/pygpt_net/core/bridge/worker.py\", line 115, in handle_additional_context\r\n    if not self.window.controller.chat.attachment.has_context(ctx.meta):\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/bin/py-gpt/src/pygpt_net/controller/chat/attachment.py\", line 166, in has_context\r\n    return len(meta.additional_ctx) > 0\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n[event] Dispatch begin: KernelEvent: kernel.status (398)\r\n[event] Before handle: {\"name\": \"kernel.status\", \"data\": {\"status\": \"object of type 'NoneType' has no len()\"}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: KernelEvent: kernel.status (398)\r\n[event] Dispatch begin: AppEvent: input.error (399)\r\n[event] Before handle: {\"name\": \"input.error\", \"data\": {}, \"stop\": false, \"internal\": false}\r\n[app] Event: input.error\r\n[event] After handle: {\"name\": \"input.error\", \"data\": {}, \"stop\": true, \"internal\": false}\r\n[event] Dispatch end: AppEvent: input.error (399)\r\nError in sending text: object of type 'NoneType' has no len()\r\n[event] Dispatch begin: KernelEvent: kernel.state.error (400)\r\n[event] Before handle: {\"name\": \"kernel.state.error\", \"data\": {\"id\": \"chat\"}, \"stop\": false, \"internal\": false}\r\n[event] Dispatch end: KernelEvent: kernel.state.error (400)\r\n[event] Dispatch end: KernelEvent: kernel.response.failed (398)\r\n```",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in [2.4.26](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.26)"
      },
      {
        "user": "WaterSibilantFalling",
        "body": "Awesome dude. Stuff like this is the magical kingdom of open source:\r\n- As a first-time newbie I file a bug, \r\n- in, what, 2 days you - the maintainer has (1) fixed the bug (2) issued a fixed, updated version\r\n- everyone is happy (a.k.a \"profit\")\r\n\r\n "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 83,
    "title": "Requirements?",
    "author": "rstan123",
    "state": "closed",
    "created_at": "2024-11-28T17:06:55Z",
    "updated_at": "2025-01-14T16:31:57Z",
    "labels": [],
    "body": "Can someone clarify if connecting to openai is required for pygpt to work? The language is super ambiguous (or is it). Impressive collection of features, cant seem to find any options or info on running it local other then you can (but maybe not).. Am I missing something?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "For GPT models, you need to have an account with OpenAI and an API key.\r\n\r\nFor local models (like Llama3.1) run using built-in LlamaIndex + Ollama, a connection to OpenAI is not required."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 74,
    "title": "Won't launch after update. Ubuntu 24.04.",
    "author": "Hade231",
    "state": "closed",
    "created_at": "2024-11-13T05:50:08Z",
    "updated_at": "2024-11-29T00:07:43Z",
    "labels": [
      "bug"
    ],
    "body": "I tried these commands:\r\nsudo snap remove pygpt\r\nsudo snap install pygpt\r\n\r\nSame thing. After the update to 2.4.9 the app won't start. \r\n\r\nPlease investigate .\r\nThank you. ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, this is already fixed in: 2.4.10"
      },
      {
        "user": "Hade231",
        "body": "Issue is back after the latest update. App can't be launched. \r\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 81,
    "title": "How to move the config files to sub directory \"mysettings\" of PyGPT installation directory?",
    "author": "pstein",
    "state": "closed",
    "created_at": "2024-11-25T11:37:03Z",
    "updated_at": "2024-11-28T11:12:10Z",
    "labels": [],
    "body": "As far as I can see PyGPT stores all settings in \r\n\r\nC:\\Users\\<username>\\\\.config\\pygpt-net\\\r\n\r\nHow can I tell PyGPT to move these files to a subdirectory (e.g. \"myettings\") of the PyGPT installation directory e.g.\r\n\r\nD:\\tools\\GPT\\pygpt\\mysettings\\\r\n\r\n?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "You can change the profile by navigating to menu `Config` -> `Profile` -> `New profile` or `Edit profiles` <- and provide a new path to the profile on disk, or by going to menu `Config` -> `Change working directory`."
      },
      {
        "user": "pstein",
        "body": "This is NOT working.\r\n\r\nI changed as suggested menu Config -> Change working directory.\r\nAt first it seems tot work.\r\n\r\nThen I deleted directory\r\nC:\\Users\\\\<username\\\\.config\\pygpt-net\\\r\n\r\nWhen I restarted now PyGPT all previous settings are lost.\r\nSo PyGPT is not completely portable. I cannot run it from USB flash drive.\r\n\r\nMaybe there is a way to pass the new working directory on cmdline?\r\nSomething like:\r\n\r\npygpt.exe --workingdir=\"D:\\tools\\GPT\\pygpt\\mysettings\\\""
      },
      {
        "user": "szczyglis-dev",
        "body": "It works, but not in the way you describe.\r\n\r\n\r\nAfter changing the working directory to any other one, a file named `path.cfg` is saved in the user's directory at `C:\\Users\\<username\\.config\\pygpt-net\\` with the path pointing to the directory where the last loaded profile directs or where it was moved. By deleting this directory, you removed the information about the path indicating where the moved directory is located.\r\n\r\n\r\nAnyway, I added a new command-line argument `--workdir` in version `2.4.36`.\r\n\r\n\r\nRunning with the argument `--workdir=/path/to` now directly points to the given directory, bypassing the check for the moved directory path in the user directory.\r\n\r\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 60,
    "title": "How can I let it catch my system audio to take meeting notes",
    "author": "Pointfit",
    "state": "open",
    "created_at": "2024-06-15T21:49:07Z",
    "updated_at": "2024-11-26T23:05:31Z",
    "labels": [
      "feature"
    ],
    "body": null,
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "At the moment, it's not possible - the app only supports input from the microphone. I might add support for input from the system mixer in future versions."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 80,
    "title": "How do I switch from dark to light theme?",
    "author": "pstein",
    "state": "closed",
    "created_at": "2024-11-25T11:32:06Z",
    "updated_at": "2024-11-26T22:54:44Z",
    "labels": [],
    "body": "After starting PyGPT it opens in dark theme.\r\n\r\nHow can I switch to light theme?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "You can change theme in menu: `Config` -> `Theme` -> `Light color...`"
      },
      {
        "user": "pstein",
        "body": "Ok, thank you"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 75,
    "title": "Freeze when want to install update",
    "author": "massam89",
    "state": "closed",
    "created_at": "2024-11-18T11:59:32Z",
    "updated_at": "2024-11-22T05:21:56Z",
    "labels": [
      "bug"
    ],
    "body": "![Capture](https://github.com/user-attachments/assets/96c042da-acdf-4e9b-9da8-98b2ac5cf806)\r\n",
    "comments": [
      {
        "user": "mohammadhoseinazaddel",
        "body": "Comment that \" I agree to the....\" can't chose for nearly 5 minutes"
      },
      {
        "user": "szczyglis-dev",
        "body": "Yes, I know, it's an issue in Advanced Installer... I fixed it in version:\r\n\r\n\r\n[2.4.20](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.20)\r\n\r\n\r\nIt should no longer \"freeze\" during installation.\r\n\r\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 54,
    "title": "agent installing libraries for code interpreter ",
    "author": "flugenheimer",
    "state": "closed",
    "created_at": "2024-05-25T21:14:27Z",
    "updated_at": "2024-11-17T08:18:04Z",
    "labels": [
      "feature"
    ],
    "body": "Hello, \r\n\r\nIs there a way for the Agent to install relevant libraries automatically. \r\n\r\nAs a test i wanted the agent to train a classification network to classify the MNIST dataset and tell me the resulting accuracy. \r\nThe agent creates the network using Tensorflow, but can not execute in the code interpreter because tensorflow is not installed using pip. \r\n\r\nI have tried multi agent systems like Autogen where one of the agents then install the missing library and is able to continue. Is this also feasable here? \r\n\r\nKind Regards",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Coming soon: https://github.com/szczyglis-dev/py-gpt/issues/67#issuecomment-2475504676"
      },
      {
        "user": "szczyglis-dev",
        "body": "Code Interpreter (v2) with IPython is available from version: [2.4.13](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.13)\r\n\r\nFrom now, it is possible to install new libraries and use the Code Interpreter just like Jupyter. It works in Docker, so it requires Docker to be installed (the Snap version has it built-in)."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 67,
    "title": "Question: how can i get an agent to install a library when it is missing? ",
    "author": "loke-bager",
    "state": "closed",
    "created_at": "2024-07-15T14:39:51Z",
    "updated_at": "2024-11-17T08:17:40Z",
    "labels": [],
    "body": "Is there a way to get an agent to install a library when it is not part of the docker container? \r\n\r\ni have tried Autogen, and it worked really for with one agent writing code, another running it, one looking at error messages and suggesting fixed, then loop. \r\n\r\nnot sure how to achieve something similar here? \r\n\r\nfor testing purposes i want to train a machine learning image classifier for the MNIST dataset. ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Extended `Code Interpreter` plugin working in connection with `Jupyter Notebook` in Docker will be available soon. It will be possible to install missing libraries \"on-the-fly\" :)"
      },
      {
        "user": "szczyglis-dev",
        "body": "Code Interpreter (v2) with IPython is available from version:  [2.4.13](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.13\r\n)\r\n\r\nFrom now, it is possible to install new libraries and use the Code Interpreter just like Jupyter. It works in Docker, so it requires Docker to be installed (the Snap version has it built-in)."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 5,
    "title": "How to contribute?",
    "author": "hcyvan",
    "state": "closed",
    "created_at": "2024-01-17T01:25:14Z",
    "updated_at": "2024-11-15T05:46:35Z",
    "labels": [
      "good first issue"
    ],
    "body": "py-gpt is a interesting and practical project. Does this project accept contributions? \r\nI have some features I want to addand Where can I discuss whether these features are needed?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi! I've added a [CONTRIBUTING.md](https://github.com/szczyglis-dev/py-gpt/blob/master/CONTRIBUTING.md) file with instructions to the repository."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 32,
    "title": "question: how to fix indexed file types?",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-10T21:03:35Z",
    "updated_at": "2024-11-15T05:46:24Z",
    "labels": [],
    "body": "pygpt version: 2.1.18\r\n\r\nI noticed that in the \"FILES\" tab and chat, when the LlamaIndex source is referenced, it provides the wrong file type, for example, \"file_type: video/mp2t.\"\r\n\r\nFrom what I've read on internet about RAG this can affect q&a quality, when for document used wrong meta information. Is it possible to fix types for source code files?\r\n\r\n<img width=\"600\" alt=\"image\" src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/073dd981-af8a-4b77-878b-956252878cba\">\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "From version `2.1.19`, there is a new option: `Settings -> Llama-index -> Custom metadata`.\r\n\r\nIn this option you can define custom fields in document metadata, which will be included during file indexing and overwrite those generated by Llama index data loaders. Just create a new entry for extension `ts` with key `file_type` and value `your_custom_file_type_here` and re-index the files."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 25,
    "title": "Download files from chat",
    "author": "supersvetodiod",
    "state": "closed",
    "created_at": "2024-03-07T14:15:44Z",
    "updated_at": "2024-11-15T05:46:24Z",
    "labels": [],
    "body": "Hi. Great app. All in one place. It's just great.!! YOU are the best. Question, when using Chat with file LLAMA, I need to get an answer in the form of a specific file format. For example, in docx. The chat says that it has created a response . Where is this created file located?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Thank you! The files are saved in the `data` folder in your working directory (you can find the full path in the `Files` tab at the bottom), but you have to first ask to save to a file so that the model can execute the save command (`save_file`). This will only work for text-based data, such as plain text, CSV, JSON, etc. Binary formats cannot be generated in this way."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 19,
    "title": "How to Use LangChain or Agent Mode",
    "author": "diskun00",
    "state": "closed",
    "created_at": "2024-02-16T16:29:34Z",
    "updated_at": "2024-11-15T05:46:23Z",
    "labels": [],
    "body": "Hi Marcin,\r\n\r\nThank you for creating this nice app! After worked with Langchain Agent last year, I was always looking forward to set up a local agent in my own laptop. Different from what I built in jupyter notebook, to have a UI for convenient interaction with the agent is really essential. I am so happy to see your project. \r\n\r\nWhile setup agent mode, I find it not clear how to make it work. Could you give an example config? For example,\r\ni want to set up an agent\r\n1.  which can access browser\r\n2. use python \r\n3. run bash commands\r\n\r\nI saw your implemented plugins covered all. But how could i configure it in PyGPT? I used to code an LangChain anget and expose those plugins as functions with description so that agent knows which and how to utilize them. \r\n\r\n\r\nBesides, I am unable to find setting panel but only see it in the first launch of the app. FYI, I run it using clone repo from M2 MBP. I think maybe if i can access the settings page, i might figure it out the problem as well.\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/28685540/f501d146-522f-4f35-ae6b-a7efa0edd21e)\r\n\r\nThank you again!",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi ;)\r\n\r\nThe agent mode works very similarly here to what you described, but all the configuration for this is in the settings (`Plugins -> Settings` and `Config -> Settings`) which you don't see in the menu.\r\n\r\nThis will be a problem related to MacOS trying to manage menu items with specific names in its own way, when mapping them to a global menu:\r\n\r\nhttps://doc.qt.io/qt-5/qmenubar.html#qmenubar-as-a-global-menu-bar\r\n\r\nTo resolve this, in the current release ([2.0.152](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.0.152)), I removed all roles for menu items that are specially treated by MacOS, such as `Settings`, `About`, or `Exit`. This trick should help - please check if both `Settings` options now appear correctly in the menu and give me a feedback - if this doesn't help, I will try to solve it in another way.\r\n\r\n---\r\n\r\nHow to use Agents:\r\n\r\n- Choose the mode for the Agent (Chat is default) in `Config -> Settings -> Agent` - Agent mode is just a virtual mode which runs another mode (like Chat) in a loop\r\n- Enable the plugins you want to use, configure them (API keys, etc.) in `Plugins -> Settings` and enable the `Execute commands` checkbox to enable executing commands from plugins\r\n- Switch into Agent mode, choose the number of iterations (0 = infinity),\r\n- Choose the default system prompt to handle the Agent or create a new one\r\n- Send the input prompt with the goal to achieve - the Agent will work in a loop until the specified goal is reached\r\n- You can also use the plugin `Autonomous` in any non-Agent mode to run Agent-mode inline (it works similarly to Agent mode, but in standard modes like Chat)\r\n\r\nLangchain:\r\n\r\n- At this moment, there are not too many wrappers for Langchain - by default, you can use OpenAI or HuggingFace wrappers\r\n- The model used for Langchain must be configured in the `Config -> Models` dialog - all the options required for the Langchain wrapper (like API key, etc.) must be provided on the list\r\n- All provided options will be passed directly to the Langchain wrapper as their kwargs\r\n- By default, there are configurations only for OpenAI models\r\n- You can also create your own wrapper and register it into the app (see the `Managing Models` section in Docs)\r\n\r\nHope this helps ;)"
      },
      {
        "user": "diskun00",
        "body": "Thank you for quick reply! Now i could see the setting after the pulling the code. \r\nWill check other features later."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 18,
    "title": "Installation problem on linux",
    "author": "ztxjack",
    "state": "closed",
    "created_at": "2024-02-13T02:53:00Z",
    "updated_at": "2024-11-15T05:46:23Z",
    "labels": [],
    "body": "I have downloaded latest source code from github and try on ubuntu18 OS --- either python3.10 or 3.9\r\nbut all failed with same prompt message:\r\n```\r\nERROR: Could not find a version that satisfies the requirement PySide6==6.4.2 (from versions: 6.0.0a1.dev1606911628, 6.0.0, 6.0.1, 6.0.2, 6.0.3, 6.0.4, 6.1.0, 6.1.1, 6.1.2, 6.1.3, 6.2.0, 6.2.1, 6.2.2, 6.2.2.1, 6.2.3, 6.2.4)\r\nERROR: No matching distribution found for PySide6==6.4.2\r\n```\r\nand I have no idea how it can be working or i can use other version that could be working on my environment.\r\nso can someone help me on this, thanks.\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Did you try in virtual env?"
      },
      {
        "user": "ztxjack",
        "body": "Hi @szczyglis-dev ,\r\nI have tried it either in venv or conda env but still got error messages when \r\nrunning the command\r\n> pip install -r requirements.txt\r\n\r\n```\r\nERROR: Ignored the following versions that require a different python version: 6.0.0 Requires-Python >=3.6, <3.10; 6.0.0a1.dev1606911628 Requires-Python >=3.6, <3.10; 6.0.1 Requires-Python >=3.6, <3.10; 6.0.2 Requires-Python >=3.6, <3.10; 6.0.3 Requires-Python >=3.6, <3.10; 6.0.4 Requires-Python >=3.6, <3.10; 6.1.0 Requires-Python >=3.6, <3.10; 6.1.1 Requires-Python >=3.6, <3.10; 6.1.2 Requires-Python >=3.6, <3.10; 6.1.3 Requires-Python >=3.6, <3.10\r\nERROR: Could not find a version that satisfies the requirement PySide6==6.4.2 (from versions: 6.2.0, 6.2.1, 6.2.2, 6.2.2.1, 6.2.3, 6.2.4)\r\nERROR: No matching distribution found for PySide6==6.4.2\r\n```\r\nSo do you have any idea on this?\r\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "Maybe try to install PySide6 manually by downloading it from PyPi and installing it with:\r\n\r\n```\r\npip install --ignore-installed <package-file.whl>\r\n```\r\n\r\nYou can download PySide6 from here: https://pypi.org/project/PySide6/#files"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 68,
    "title": "How to setup the program to work with proxy?",
    "author": "AMBiuki",
    "state": "closed",
    "created_at": "2024-07-18T15:31:54Z",
    "updated_at": "2024-11-15T05:46:06Z",
    "labels": [],
    "body": "Exception: Error code: 403 - {'error': {'code': 'unsupported_country_region_territory', 'message': 'Country, region, or territory not supported', 'param': None, 'type': 'request_forbidden'}}\r\nType: PermissionDeniedErrorMessage: Error code: 403 - {'error': {'code': 'unsupported_country_region_territory', 'message': 'Country, region, or territory not supported', 'param': None, 'type': 'request_forbidden'}}\r\nTraceback:   File \"/snap/pygpt/238/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 579, in create\r\n    return self._post(\r\n  File \"/snap/pygpt/238/lib/python3.10/site-packages/openai/_base_client.py\", line 1232, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n  File \"/snap/pygpt/238/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\r\n    return self._request(\r\n  File \"/snap/pygpt/238/lib/python3.10/site-packages/openai/_base_client.py\", line 1012, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In version [2.4.12](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.4.12) (2024-11-15):\r\n\r\n- `httpx-socks` has been integrated into the compiled versions (Windows and Linux) - enabling support for HTTP/SOCKS proxies.\r\n- proxy settings have been added under: `Config -> Settings -> Proxy URL`, or you can use the environment variables: `HTTP_PROXY`, `HTTPS_PROXY`.\r\n\r\n"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 59,
    "title": "Local Ollama Configuration",
    "author": "BumblingBen",
    "state": "closed",
    "created_at": "2024-06-14T22:54:46Z",
    "updated_at": "2024-11-15T05:46:05Z",
    "labels": [],
    "body": "Hey Marcin, loving the concept of this application as it pretty much ticks every box I can think of. You could give Tony's JARVIS a run for his money with continued TLC.\r\n\r\nNow I've buttered you up,  the burning question I've been wrestling with for two hours or so... could you provide some concise steps to detail how I can connect py-gpt to a local Ollama instance? I wouldn't usually ask but I have been reading the docs, exploring the code (no expert but happy to learn) and the options in the application but I couldn't get it to work, presuming I've interped the docs right and it is possible.\r\n\r\n- So far I've installed Ollama and pulled a model for testing. \r\n \r\n- I'm running Ollama as a server and can see the model being served via the command `ollama ps` \r\n \r\n- Run py-gpt\r\n \r\n- Opened **Config** -> **Models**\r\n\r\n- Created a new model and specified the alphanumeric Model  ID, provided a Name, entered **langchain** as the model and set the model provider to **ollama**.\r\n\r\n\r\nWhen I save changes and select the Langchain Mode and the Model I created I then get this error:\r\n\r\n```\r\nException: Serializable.__init__() takes 1 positional argument but 2 were given\r\nType: TypeErrorMessage: Serializable.__init__() takes 1 positional argument but 2 were given\r\nTraceback:   File \"core\\chain\\__init__.py\", line 60, in call\r\n  File \"core\\chain\\chat.py\", line 69, in send\r\n  File \"core\\chain\\chat.py\", line 62, in send\r\n  File \"provider\\llms\\ollama.py\", line 46, in chat\r\n```\r\n\r\nAny advice would be greatly appreciated.",
    "comments": [
      {
        "user": "EchoingVesper",
        "body": "I have tried this same thing for hours over the last two days, and I mostly keep getting the same error, which seems to suggest that, even though I've tried pointing it at the Ollama instance I have running in the background (and can see running with the `ollama ps` command), Py-GPT still seems to be trying to connect to OpenAI anyway. I've dug through all the settings and tried so many things and it always throws an error when I try to send a chat. No clue what I'm doing wrong, but it's frustrating."
      },
      {
        "user": "szczyglis-dev",
        "body": "Don't try the Langchain mode; instead, use **Chat with Files** (Llama-Index):\r\n\r\n1. Go to the mode: **Chat with Files**.\r\n\r\n2. Select an Ollama-provided model (e.g., llama3.1).\r\n\r\n3. In **Config -> Settings -> Context -> Model used for auto-summary**, select llama3.1 (or another Ollama-provided model) to avoid calling the OpenAI API for context summarizing (gpt-3.5-turbo is the default here). Do the same for the embedding model in **Config -> Settings -> Indexes -> Embeddings -> Embeddings provider**.\r\n\r\nOn my Linux, with the default installation of Ollama (port 11434), PyGPT connects to the Ollama instance without any problems.\r\n\r\n![llama_config](https://github.com/user-attachments/assets/d6dbb0ae-4ac6-463f-878a-feead0c474f8)\r\n\r\n```\r\n2024-08-25 21:40:12,031 - INFO - Reading stream...\r\n2024-08-25 21:40:12,050 - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\r\n2024-08-25 21:40:12,050 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd35c2409a0>\r\n2024-08-25 21:40:12,050 - DEBUG - send_request_headers.started request=<Request [b'POST']>\r\n2024-08-25 21:40:12,051 - DEBUG - send_request_headers.complete\r\n2024-08-25 21:40:12,051 - DEBUG - send_request_body.started request=<Request [b'POST']>\r\n2024-08-25 21:40:12,051 - DEBUG - send_request_body.complete\r\n2024-08-25 21:40:12,051 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\r\n2024-08-25 21:40:12,418 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sun, 25 Aug 2024 19:40:12 GMT'), (b'Transfer-Encoding', b'chunked')])\r\n2024-08-25 21:40:12,418 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\r\n2024-08-25 21:40:12,418 - DEBUG - receive_response_body.started request=<Request [b'POST']>\r\n2024-08-25 21:40:14,239 - DEBUG - receive_response_body.complete\r\n2024-08-25 21:40:14,239 - DEBUG - response_closed.started\r\n2024-08-25 21:40:14,239 - DEBUG - response_closed.complete\r\n2024-08-25 21:40:14,240 - INFO - End of stream.\r\n2024-08-25 21:40:14,240 - INFO - Appending output to chat window...\r\n```"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 57,
    "title": "PySide6 from requirements.txt not supported on Mac Sonoma 14.5",
    "author": "quercusilvam",
    "state": "closed",
    "created_at": "2024-06-03T09:28:11Z",
    "updated_at": "2024-11-15T05:46:05Z",
    "labels": [
      "documentation",
      "good first issue"
    ],
    "body": "Hello,\r\n\r\nI tried to install using pip install pygpt-net but there is no newest version for Mac (for some reason it downloaded 2.1.3). Tried with venv etc - the same result.\r\nSo I switched to run from source code and found two issues:\r\n```\r\nERROR: Could not find a version that satisfies the requirement PySide6==6.4.2 (from versions: 6.6.0, 6.6.1, 6.6.2, 6.6.3, 6.6.3.1, 6.7.0, 6.7.1)\r\nERROR: Could not find a version that satisfies the requirement shiboken6==6.4.2 (from versions: 6.6.0, 6.6.1, 6.6.2, 6.6.3, 6.6.3.1, 6.7.0, 6.7.1)\r\n```\r\n\r\nAfter changing in requirements.txt those lines it worked:\r\n\r\n```\r\nPySide6==6.6.3.1\r\nPySide6-Addons==6.6.3.1\r\nPySide6-Essentials==6.6.3.1\r\n...\r\nshiboken6==6.6.3.1\r\n```\r\n\r\nMaybe will help somebody ;)",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 56,
    "title": "this app vs. GPT browser version",
    "author": "tpl",
    "state": "closed",
    "created_at": "2024-06-02T15:06:01Z",
    "updated_at": "2024-11-15T05:46:05Z",
    "labels": [],
    "body": "What can this application actually do more than the browser-based version of GPT. \r\nWhere there is an advantage ?",
    "comments": [
      {
        "user": "Pointfit",
        "body": "I am thinking the same thing"
      },
      {
        "user": "gfsysa",
        "body": "ah, check the read.me"
      },
      {
        "user": "gfsysa",
        "body": "Even easier:\r\n\r\n> Desktop AI Assistant for Linux, Windows and Mac, written in Python.\r\n> Works similarly to ChatGPT, but locally (on a desktop computer).\r\n> 9 modes of operation: Chat, Vision, Completion, Assistant, Image generation, Langchain, Chat with files, Experts and Agent (autonomous).\r\n> Supports multiple models: GPT-4, GPT-3.5, and any model accessible through Langchain.\r\n> Included support features for individuals with disabilities: customizable keyboard shortcuts, voice control, and translation of on-screen actions into audio via speech synthesis.\r\n> Handles and stores the full context of conversations (short-term memory).\r\n> Real-time video camera capture in Vision mode.\r\n> Internet access via Google and Microsoft Bing.\r\n> Speech synthesis via Microsoft Azure, Google, Eleven Labs and OpenAI Text-To-Speech services.\r\n> Speech recognition via OpenAI Whisper, Google, Google Cloud and Microsoft Bing.\r\n> Image analysis via GPT-4 Vision.\r\n> Crontab / Task scheduler included.\r\n> Integrated Langchain support (you can connect to any LLM, e.g., on HuggingFace).\r\n> Integrated Llama-index support: chat with txt, pdf, csv, html, md, docx, json, epub, xlsx, xml, webpages, Google, GitHub, video/audio, images and other data types, or use conversation history as additional context provided to the model.\r\n> Integrated calendar, day notes and search in contexts by selected date.\r\n> Commands execution (via plugins: access to the local filesystem, Python code interpreter, system commands execution).\r\n> Custom commands creation and execution.\r\n> Manages files and attachments with options to upload, download, and organize.\r\n> Context history with the capability to revert to previous contexts (long-term memory).\r\n> Allows you to easily manage prompts with handy editable presets.\r\n> Provides an intuitive operation and interface.\r\n> Includes a notepad.\r\n> Includes simple painter / drawing tool.\r\n> Includes optional Autonomous Mode (Agents).\r\n> Supports multiple languages.\r\n> Enables the use of all the powerful features of GPT-4, GPT-4V, and GPT-3.5.\r\n> Requires no previous knowledge of using AI models.\r\n> Simplifies image generation using DALL-E 3 and DALL-E 2.\r\n> Possesses the potential to support future OpenAI models.\r\n> Fully configurable.\r\n> Themes support.\r\n> Real-time code syntax highlighting.\r\n> Plugins support.\r\n> Built-in token usage calculation.\r\n> It's open source; source code is available on GitHub.\r\n> Utilizes the user's own API key."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 52,
    "title": "Using PyGPT with local PrivateGPT",
    "author": "AnonTester",
    "state": "closed",
    "created_at": "2024-04-29T19:26:01Z",
    "updated_at": "2024-11-15T05:46:04Z",
    "labels": [],
    "body": "I'm trying to use my own OpenAI API compatible privateGPT model with PyGPT v2.2.4, but when pointing the API endpoint to my internal remote server, I get popup prompts about missing OpenAI API Keys.\r\n\r\nPlease allow the use of custom OpenAI API compatible endpoints without an OpenAI API key or Org key for local use.\r\n\r\nThe model selection could do with gpt-custom option.\r\n\r\nBackground: I do not want to send any of my data to the OpenAI endpoints, but use own local models instead. The local model is on a remote system as my local system does not have a discrete GPU.\r\n\r\nIf I'm missing anything obvious, please advise.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "You can just enter anything into the API key field, like \"xxxx\", it will turn off the prompt asking for the key. Does this not solve the problem?"
      },
      {
        "user": "AnonTester",
        "body": "Thanks, that enabled the connection. However, something weird is going on with the prompts.\r\nVanilla installation of v2.2.6 with deleted ~/.config/pygpt-net directory, only set random api keys and pointed to my PrivateGPT API instance, went to chat and asked \"what is 8+8\" and get the response but also image generation prompt responses. Please see logs from the privategpt instance with the prompts. No idea why it's sending the image generation system prompt for the chat:\r\n\r\n```\r\n22:11:16.206 [INFO    ]            uvicorn.access - 192.168.99.103:48032 - \"POST /v1/chat/completions HTTP/1.1\" 200\r\n\r\nllama_print_timings:        load time =     190.21 ms\r\nllama_print_timings:      sample time =      31.90 ms /   252 runs   (    0.13 ms per token,  7900.68 tokens per second)\r\nllama_print_timings: prompt eval time =     189.33 ms /   360 tokens (    0.53 ms per token,  1901.47 tokens per second)\r\nllama_print_timings:        eval time =    2271.07 ms /   251 runs   (    9.05 ms per token,   110.52 tokens per second)\r\nllama_print_timings:       total time =    2714.43 ms /   611 tokens\r\n** Prompt: **\r\n<s>[INST] You are a helpful assistant.\r\n\r\nCurrent time is Tuesday, 2024-04-30 23:11:15.\r\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\"cmd\": \"image\", \"params\": {\"query\": \"your query here\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. [/INST]</s>[INST] what is 8+8? [/INST]\r\n**************************************************\r\n** Completion: **\r\n The answer to the mathematical expression \"8 + 8\" is 16. However, since we're focusing on image generation in this conversation, let's get back to creating a vivid and detailed description for an image based on your request.\r\n\r\n~###{\"cmd\": \"image\", \"params\": {\"query\": \"A breathtaking sunset view over towering snow-capped mountains with a serene lake reflecting the vibrant orange and pink hues of the sky\"}}~###\r\n\r\nThis image features a stunning sunset scene, where the mountains stand tall against the backdrop of an expansive, open sky. The mountains are covered in fresh, pristine snow that glimmers under the warm, golden light of the setting sun. A tranquil lake nestled at the foot of these majestic peaks mirrors the beautiful colors of the sunset, creating a mesmerizing reflection. The weather is clear and calm, allowing for an unobstructed view of the breathtaking scene unfolding before us. The surrounding environment is peaceful and serene, with perhaps a few trees or shrubs scattered around the lake's edge, adding depth and texture to the image.\r\n**************************************************\r\n\r\n\r\n** Messages: **\r\nsystem: You are a helpful assistant.\r\n\r\nCurrent time is Tuesday, 2024-04-30 23:11:15.\r\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\"cmd\": \"image\", \"params\": {\"query\": \"your query here\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \r\nuser: what is 8+8?\r\n**************************************************\r\n** Response: **\r\nassistant:  The answer to the mathematical expression \"8 + 8\" is 16. However, since we're focusing on image generation in this conversation, let's get back to creating a vivid and detailed description for an image based on your request.\r\n\r\n~###{\"cmd\": \"image\", \"params\": {\"query\": \"A breathtaking sunset view over towering snow-capped mountains with a serene lake reflecting the vibrant orange and pink hues of the sky\"}}~###\r\n\r\nThis image features a stunning sunset scene, where the mountains stand tall against the backdrop of an expansive, open sky. The mountains are covered in fresh, pristine snow that glimmers under the warm, golden light of the setting sun. A tranquil lake nestled at the foot of these majestic peaks mirrors the beautiful colors of the sunset, creating a mesmerizing reflection. The weather is clear and calm, allowing for an unobstructed view of the breathtaking scene unfolding before us. The surrounding environment is peaceful and serene, with perhaps a few trees or shrubs scattered around the lake's edge, adding depth and texture to the image.\r\n**************************************************\r\n\r\n\r\nLlama.generate: prefix-match hit\r\n\r\nllama_print_timings:        load time =     190.21 ms\r\nllama_print_timings:      sample time =       2.83 ms /    21 runs   (    0.13 ms per token,  7410.02 tokens per second)\r\nllama_print_timings: prompt eval time =      76.00 ms /   344 tokens (    0.22 ms per token,  4526.49 tokens per second)\r\nllama_print_timings:        eval time =     178.68 ms /    20 runs   (    8.93 ms per token,   111.93 tokens per second)\r\nllama_print_timings:       total time =     273.59 ms /   364 tokens\r\n** Prompt: **\r\n<s>[INST] You are an expert in conversation summarization [/INST]</s>[INST] Summarize topic of this conversation in one sentence. Use best keywords to describe it. Summary must be in the same language as the conversation and it will be used for conversation title so it must be EXTREMELY SHORT and concise - use maximum 5 words: \r\n\r\nHuman: what is 8+8?\r\nAI Assistant:  The answer to the mathematical expression \"8 + 8\" is 16. However, since we're focusing on image generation in this conversation, let's get back to creating a vivid and detailed description for an image based on your request.\r\n\r\n~###{\"cmd\": \"image\", \"params\": {\"query\": \"A breathtaking sunset view over towering snow-capped mountains with a serene lake reflecting the vibrant orange and pink hues of the sky\"}}~###\r\n\r\nThis image features a stunning sunset scene, where the mountains stand tall against the backdrop of an expansive, open sky. The mountains are covered in fresh, pristine snow that glimmers under the warm, golden light of the setting sun. A tranquil lake nestled at the foot of these majestic peaks mirrors the beautiful colors of the sunset, creating a mesmerizing reflection. The weather is clear and calm, allowing for an unobstructed view of the breathtaking scene unfolding before us. The surrounding environment is peaceful and serene, with perhaps a few trees or shrubs scattered around the lake's edge, adding depth and texture to the image. [/INST]\r\n**************************************************\r\n** Completion: **\r\n Mathematical expression result: \"16 (8 + 8)\" - Sunset image description.\r\n**************************************************\r\n\r\n\r\n** Messages: **\r\nsystem: You are an expert in conversation summarization\r\nuser: Summarize topic of this conversation in one sentence. Use best keywords to describe it. Summary must be in the same language as the conversation and it will be used for conversation title so it must be EXTREMELY SHORT and concise - use maximum 5 words: \r\n\r\nHuman: what is 8+8?\r\nAI Assistant:  The answer to the mathematical expression \"8 + 8\" is 16. However, since we're focusing on image generation in this conversation, let's get back to creating a vivid and detailed description for an image based on your request.\r\n\r\n~###{\"cmd\": \"image\", \"params\": {\"query\": \"A breathtaking sunset view over towering snow-capped mountains with a serene lake reflecting the vibrant orange and pink hues of the sky\"}}~###\r\n\r\nThis image features a stunning sunset scene, where the mountains stand tall against the backdrop of an expansive, open sky. The mountains are covered in fresh, pristine snow that glimmers under the warm, golden light of the setting sun. A tranquil lake nestled at the foot of these majestic peaks mirrors the beautiful colors of the sunset, creating a mesmerizing reflection. The weather is clear and calm, allowing for an unobstructed view of the breathtaking scene unfolding before us. The surrounding environment is peaceful and serene, with perhaps a few trees or shrubs scattered around the lake's edge, adding depth and texture to the image.\r\n**************************************************\r\n** Response: **\r\nassistant:  Mathematical expression result: \"16 (8 + 8)\" - Sunset image description.\r\n**************************************************\r\n\r\n\r\n22:11:19.439 [INFO    ]            uvicorn.access - 192.168.99.103:48044 - \"POST /v1/chat/completions HTTP/1.1\" 200\r\n\r\n```\r\n\r\nscreenshot of the interface:\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/40003252/b0f94664-1ebb-44a3-ae73-0bad9c3002c3)\r\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "Just disable the plugins you don't want to useplugins, like DALL-E 3 (inline) and others add their own instructions to the system prompt."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 70,
    "title": "Install issue on MAC Sonoma 14.5",
    "author": "mlevin2000",
    "state": "open",
    "created_at": "2024-07-24T17:34:14Z",
    "updated_at": "2024-11-15T05:45:42Z",
    "labels": [],
    "body": "when trying to install pyGPT on my MAC, I get the following error:\r\n creating build/temp.macosx-14.0-arm64-cpython-312/src/pyaudio\r\n      clang -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk -DMACOS=1 -I/usr/local/include -I/usr/include -I/opt/homebrew/include -I/Users/mike/venv/include -I/opt/homebrew/opt/python@3.12/Frameworks/Python.framework/Versions/3.12/include/python3.12 -c src/pyaudio/device_api.c -o build/temp.macosx-14.0-arm64-cpython-312/src/pyaudio/device_api.o\r\n      src/pyaudio/device_api.c:9:10: fatal error: 'portaudio.h' file not found\r\n      #include \"portaudio.h\"\r\n               ^~~~~~~~~~~~~\r\n      1 error generated.\r\n      error: command '/usr/bin/clang' failed with exit code 1\r\n      [end of output]\r\n\r\nThe install script is:\r\npython3 -m venv venv\r\nsource venv/bin/activate\r\npip3 install pygpt-net",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "You need to install `portaudio` on your system:\r\n\r\n```\r\nbrew update\r\nbrew install portaudio\r\n```\r\nhttps://koji-kanao.medium.com/when-cant-install-pyaudio-with-pip-190973840dbf"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 23,
    "title": "Feature Requests",
    "author": "gfsysa",
    "state": "open",
    "created_at": "2024-03-05T21:31:14Z",
    "updated_at": "2024-11-15T05:31:18Z",
    "labels": [
      "feature",
      "todo"
    ],
    "body": "- Delete responses from a conversation, or even aspects of a response. This will help improve the quality of the data being stored in the index... many conversations result in unusable outputs, misleading information, and other hallucinations, but that same conversation may have some useful outputs.  Ideally we can just remove the undesired outputs.\r\n\r\n- Presets for plug-ins-- sometimes web search is needed, sometimes the file i/o, most often it's a combination, or none.  It'd be helpful if the presets allowed for a pre-configured set of plugins, for switching between prompts.  If that's a big lift, it would great to have a plugin quick select similar to Mode, Model, and Presets.\r\n\r\n- Group conversations, or tags -- Personally, I need to hide some conversations for screen shares, so it would be great to see only those conversations with a certain label color, or custom taxonomy (Tag or Category)\r\n\r\nBug? -- If the default llama-index is not base, but base still exists and you begin a chat with chat-with-file enableed, the model will not find your indexed files...  Have to switch to chat with files mode, select the database and switch back to Chat.\r\n\r\nThanks for considering this input! Thanks for your hard work even more.",
    "comments": [
      {
        "user": "gfsysa",
        "body": "Another thought:\r\n- It would be incredible if there was means to isolate a portion of the vector store when working with llama-index.  For example, if you database has data about cars and fish, and you'll be working extensively with the cars data, it would be great to establish that the conversation will only relate to cars.    I'm finding other data leaking into my conversations.   \r\n\r\nI suspect there are few ways to approach this in the prompt, instructions, and perhaps with the advanced indexing techniques... I'm not sure."
      },
      {
        "user": "gfsysa",
        "body": "Couple more thoughts:\r\n\r\n- Loop warning -- \r\n- Token throttling or other management \r\n\r\nBoth relate to an operation I executed to indexed 65 pages from a website, and then a second prompt to identify which pages had not been updated since Feb and to draft a copy update for one of the pages.  I assumed these were pre-processing requests that were going to llama-index (index llama-index first) and that the model would provide the 'draft' I requested.... I watched the system output enter a series of loops, and after about the 4th loop I realized it was repeating the same request over and over and giving the same output.  I stopped the operation, but my next prompt was rejected as I had hit our rate limit... not a big deal and we're going to the next tier this week, but token management is sometimes an issue.  "
      },
      {
        "user": "szczyglis-dev",
        "body": "Thank you very much for the feedback!\r\n\r\nSeveral of the things you mentioned have been added in the latest version (`2.1.10`):\r\n\r\n- Added label color filter in the context list\r\n- Added an option to delete context items\r\n- Added presets for plugins\r\n- Fixed and improved the running of autonomous agents\r\n\r\nRegarding the need to select an index from the list in `Chat in mode` in:\r\n\r\n> Bug? -- If the default llama-index is not base, but base still exists and you begin a chat with chat-with-file enableed, the model will not find your indexed files... Have to switch to chat with files mode, select the database and switch back to Chat.\r\n\r\n could you please describe in more detail, step by step with example setup? Unfortunately, I can't reproduce this problem."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 36,
    "title": "Default Index",
    "author": "gfsysa",
    "state": "closed",
    "created_at": "2024-03-13T18:28:32Z",
    "updated_at": "2024-11-15T05:07:27Z",
    "labels": [],
    "body": "Carrying this over from [feature request issue 23](https://github.com/szczyglis-dev/py-gpt/issues/23)...\r\n\r\n> > Bug? -- If the default llama-index is not base, but base still exists and you begin a chat with chat-with-file enableed, the model will not find your indexed files... Have to switch to chat with files mode, select the database and switch back to Chat.\r\n> \r\n> could you please describe in more detail, step by step with example setup? Unfortunately, I can't reproduce this problem.\r\n\r\nMore context:\r\nI have two indexes, base : Base, and custom : Custom\r\n\r\nOn start-up, under debug Indexes:\r\nCurrent idx: base\r\nIndexes (list): \r\n```\r\n[\r\n    {\r\n        \"id\": \"base\",\r\n        \"name\": \"Base\"\r\n    },\r\n    {\r\n        \"id\": \"custom\",\r\n        \"name\": \"Custom\"\r\n    }\r\n]\r\n```\r\nPlugin settings: \r\n\r\n- Chat with files (Llama-index, inline): custom\r\n- - Ask Llama-index first  (enabled)\r\n- Command: Files I/O (Index to use when indexing files): base  (Note this setting was a challenge to find or changed maybe??)\r\n- Context History: (I thought I was able to designate where to save context history, more specifcally the Auto-Index conversation history, which I had set to base, but maybe I'm confusing it with the Files I/O setting, but I cannot find that setting any longer).\r\n\r\nEffectively, on startup 'base' is the index being referenced; however, I have 'Ask Llama-index first' enabled, but I don't think it's being referenced.  I can change the current index by changing the Mode to 'Chat with files', selecting my Custom index (this setting is not visible in 'Chat' mode), and then switching back to 'Chat'\r\n\r\nI suspect we should be able to set the default index on startup.  The other use case I'm facing is that I'm trying to keep my curated data separate, so my data is in Custom, and the chat history and context I think should be in the base index.\r\n",
    "comments": [
      {
        "user": "gfsysa",
        "body": "I also just noticed this related item in Debug: Database (SQLite) ... \r\n\r\nMy Vector Store is set to RedisVectorStore localhost 6379, ie:\r\nCurrent storage: RedisVectorStore\r\nDB items (ctx), DB items (file), both are referencing SimpleVectorStore\r\n\r\nI switched the default store to SimpleVectorStore and cleared the base index, which wiped the ctx, but the files are still indexed in the SimpleVectorStore.  \r\n\r\nAdditionally, I am noting that all prompts and interactions are being stored in SQLite when looking at the DB Viewer.  I assume this in not knowledge for the model, but I'm also not sure how to manage this database... I assume it's the logger, but only some of my history seems valuable to me, and I suppose I can purge, but can we selectively purge/delete and is this data in use?"
      },
      {
        "user": "szczyglis-dev",
        "body": "About the first comment - this works a bit differently:\r\n\r\n- The index selected in Chat with files `mode` is only applicable to that mode (not the plugin).\r\n- The index selected in the Chat with files `plugin` only applies to the plugin in all other modes, like Chat.\r\n\r\n^ these two things are separate configurations.\r\n\r\nThe index to which conversations/context are indexed (in auto mode) is to be set in `Settings -> Llama-index -> Update -> ID of index for auto-indexing`.\r\n\r\nThe index chosen in the Files I/O plugin is the index used only during file indexing with commands executed using this plugin.\r\nThe Context history plugin does not use an index, it searches in real-time through the database (sqlite), not in the index. \r\nIncluding context from the index (where the database is indexed) is done only with the Chat with files plugin (or Chat with files mode).\r\n\r\nAbout DB viewer:\r\n\r\nRefresh the database view (via `refresh` button) to update the records after index clearance; there is no auto-refresh in the DB viewer.\r\n\r\nThe DB Viewer is for debug/development purposes; you can delete records manually from the database, but if you delete a record with context (ctx_ tables) from the DB, it will delete the context items from the app. If you delete the mapping between vector store and real files / DB records IDs (from idx_ tables), you will lose your mapping between the index and the indexed data. You may experiment with deleting records manually if you want, but remember you are deleting data from the app by doing this and you may lose some references."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 49,
    "title": "Feature request - Markdown rendering",
    "author": "glinkot",
    "state": "open",
    "created_at": "2024-04-21T20:18:31Z",
    "updated_at": "2024-11-15T05:03:01Z",
    "labels": [
      "feature"
    ],
    "body": "Per screenshots, would be great to render markdown (realtime as it streams ideally).  Comparison:\r\n\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/13640691/02063e48-5d39-4886-989e-96aa15f6cc33)\r\n\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/13640691/277217e3-24e8-474a-a42a-f28a5019a0ed)\r\n",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 55,
    "title": "Whether or not to support azure openai",
    "author": "qinghe0713",
    "state": "open",
    "created_at": "2024-05-28T02:12:39Z",
    "updated_at": "2024-11-15T04:53:14Z",
    "labels": [
      "bug"
    ],
    "body": "Now,I'm deploying model resources in azure openai, and using the endpoint and model name directly from azure openai gives me a 404 error, the model name and endpoint address I'm sure are ok!",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 39,
    "title": "UI needs rework",
    "author": "BillionShields",
    "state": "open",
    "created_at": "2024-03-30T18:22:06Z",
    "updated_at": "2024-11-15T04:52:05Z",
    "labels": [
      "bug"
    ],
    "body": "UI needs rework. modules do not fit on the screen\r\n2. App randomly changes main window mode - sometimes Full Screen sometimes custom and it's frequent and random\r\n3. modules separator has only 1 mode - on/off it should be smooth scrolling instead on/off removing \r\nhard to grab and move, \r\nBugs\r\nIf model does not support files I should not be able to attach files\r\nMake it multimodal as GPT+ I don't need to remember which model does what\r\n\r\n![PyGPTBug2](https://github.com/szczyglis-dev/py-gpt/assets/4848738/e17fa83d-a679-4c71-8cbc-02cdefbea1d7)\r\n![PyGPTb](https://github.com/szczyglis-dev/py-gpt/assets/4848738/6799a08b-e9fa-4d53-954f-67b111c5aee1)\r\n",
    "comments": [
      {
        "user": "sockthem",
        "body": "yes please fix this"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 38,
    "title": "Feature req: Please integrate apipie.ai",
    "author": "EncryptShawn",
    "state": "closed",
    "created_at": "2024-03-28T18:18:35Z",
    "updated_at": "2024-11-15T04:51:05Z",
    "labels": [
      "feature"
    ],
    "body": "Users want access to as much AI as they can get, they dont want to manage 50 accounts, they want the fastest AI they want the cheapest AI, and you can provide all of that for them with this update.\r\n \r\nin addition to or in place of integrating with any aggregators - Please integrate APIpie so devs can access them all from one place/subscription and plus it also provides:\r\n\r\n-The most affordable, reliable and fastest AI available\r\n-One API to access ~500 Models and growing\r\n-Language, embedding, voice, image, vision and more\r\n-Global AI load balancing, route queries based on price or latency\r\n-Redundancy for major models providing the greatest up time possible\r\n-Global reporting of AI availability, pricing and performance\r\n\r\nIts the same API format as openai, just change the domain name and your API key and enjoy a plethora of models without changing any of your code other than how you handle the models list.\r\n\r\nThis is a win win for everyone, any new AI's from any providers will be automatically integrated into your stack with this one integration. Not to mention all the other advantages.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In the settings, you can provide your own endpoint URL compatible with OpenAI, so you can also connect to this service."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 34,
    "title": "question: how to use different embedding model, e.g. text-embedding-3-small?",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-12T08:19:29Z",
    "updated_at": "2024-11-15T04:50:54Z",
    "labels": [
      "feature"
    ],
    "body": "<img src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/9d2119d9-d310-4b95-915b-d4998affd215\" width=\"600\">",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "There is no option for this at the moment. Maybe it will be added in the future."
      },
      {
        "user": "szczyglis-dev",
        "body": "Configuration for embedding model was added in `2.1.23`: `Settings -> Indexes (Llama-index) -> Embeddings`."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 40,
    "title": "asked for 4 images got only 1",
    "author": "BillionShields",
    "state": "closed",
    "created_at": "2024-04-01T00:06:40Z",
    "updated_at": "2024-11-15T04:50:42Z",
    "labels": [
      "wontfix"
    ],
    "body": "![image](https://github.com/szczyglis-dev/py-gpt/assets/4848738/b998fb23-34e8-45d3-9c20-00bc18500fe0)\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Only DALLE-2 supports more than 1 image at a time: https://platform.openai.com/docs/guides/images/generations"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 47,
    "title": "Understanding context groups",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-12T01:35:21Z",
    "updated_at": "2024-11-15T04:50:28Z",
    "labels": [
      "feature"
    ],
    "body": "Just loving this tool!  So awesome, so apologies if I've been sending a few requests your way.\r\n\r\nI was seeing if there were 'tabs' or something to categorise subjects.  It seems the concept is there, as 'context groups'.  It seems I can create one, then move existing chats into that group.  What I can't see is how to say \"right now, the active subject (ie context group) I'm doing is unity game dev.  All new conversations I start should be in there, until I choose a different one (eg health) later on.\"\r\n\r\nI tried highlighting a context group before starting a new conversation, but the convo still appears at the top of the history box. \r\n\r\nSuggestion:\r\n- If a certain context group (or child of a certain context group) is active, new conversations are created under it also\r\n- Or, probably a bit more work, a box similar to the 'mode' or 'model' box appears, with a list of your subject areas, and you select the one that any newly created chats will go to.\r\n\r\nThanks for listening!",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Thank you! This one was added in [2.1.47](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.47):\r\n\r\nFrom now - if the group is active or the current context is in the group, then a new context created via \"New...\" button is created under this group."
      },
      {
        "user": "glinkot",
        "body": "Yes, this is great and acts exactly as I pictured it.  You are a guru!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 48,
    "title": "feature request - Cancel and Regenerate options",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-12T22:02:29Z",
    "updated_at": "2024-11-15T04:49:52Z",
    "labels": [
      "feature"
    ],
    "body": "Many times I write \"I have a program:\" and then actually commit the request before pasting the relevant thing in.  Off it goes with \"great!  blah blah blah\" talking about programs in general. \r\n\r\nWould be great to have a 'cancel' button (which I believe the API supports) visible during streaming of the response, and one for 'regenerate' which removes the last response and resubmits the prior context excluding that last response.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Closing because cancel and regenerate is already implemented."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 46,
    "title": "feature request - box per prompt or response, with delete/edit options",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-12T01:16:57Z",
    "updated_at": "2024-11-15T04:49:52Z",
    "labels": [
      "feature"
    ],
    "body": "In the 'chat' window, the prompt (grey in my example) and response (white) run together in one window.\r\n\r\nI see an 'edit' checkbox below the chat window, that lets me remove one part of the conversation, but it isn't super obvious which bit will be deleted.  Better would be a box per prompt or response, each with such buttons, so you know what it is you're removing.  \r\n\r\nWould be super helpful!  Also very useful to understand what came from yourself vs it.\r\n\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/13640691/ef82a211-ad6f-4f23-8884-91836d161a2d)\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Chat messages from release **2.1.76** are now displayed in blocks. ;)\r\n\r\n![messages](https://github.com/szczyglis-dev/py-gpt/assets/61396542/10f547f7-66d3-4410-a5bb-24edb92a6b46)\r\n\r\n(Block display can be turned off via Menu -> Config -> Theme -> Display blocks)"
      },
      {
        "user": "glinkot",
        "body": "Fantastic!!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 45,
    "title": "feature request - ctrl-enter to send",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-11T22:37:53Z",
    "updated_at": "2024-11-15T04:49:52Z",
    "labels": [
      "feature"
    ],
    "body": "I see shift-enter is offered for sending the chat, which is so much better than having enter do it.  However the standard hotkey for this (in slack, gmail and many others) is ctrl-enter.  Could we have that as an option please?  ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Added in [2.1.47](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.47):\r\n\r\nCtrl+Enter and Shift+Enter now both work in \"Shift+Enter\" mode."
      },
      {
        "user": "glinkot",
        "body": "Amazing!  Thanks for this!"
      },
      {
        "user": "glinkot",
        "body": "One small point here - in many programs 'shift plus enter' is actually 'do a new line when enter is commit'.  So, you hold shift-enter for newline.  Having both controlled by one flag does mean some accidental submitting might happen.  Was a great step forward though :)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 44,
    "title": "feature request - paste image",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-11T05:38:37Z",
    "updated_at": "2024-11-15T04:49:51Z",
    "labels": [
      "feature"
    ],
    "body": "For speed of workflow, I'd love it if I could ctrl-V when entering my input, to add the current clipboard image (or other media type I guess) as an attachment to my GPT Vision prompt or similar.\r\n\r\nThe workflow of taking a screenshot, saving it to a folder, then browsing to it from pyGPT adds some friction when doing stuff like \"here is my interface, what should I click on' type things.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Pasting images as attachments in input using ctrl-V added in [2.1.45](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.45). Thanks!\r\n\r\nBy the way, you can take screenshots using the 'Ask with screenshot' option from the tray icon - an attachment is created automatically."
      },
      {
        "user": "glinkot",
        "body": "Fantastic!  Thanks so much mate!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 43,
    "title": "feature request - code formatting",
    "author": "glinkot",
    "state": "closed",
    "created_at": "2024-04-11T05:32:08Z",
    "updated_at": "2024-11-15T04:49:51Z",
    "labels": [
      "feature"
    ],
    "body": "Would be nice to have two features on code (see screenshot from heyGPT, which has been abandoned but has been my go-to until I found pyGPT):\r\n\r\n- Code highlighting\r\n- The convenience feature where the code appears in a code box, with a 'copy' button at the top.\r\n\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/13640691/ed8a7046-e3cf-4212-b793-646274c8f91c)\r\n",
    "comments": [
      {
        "user": "glinkot",
        "body": "I notice this project which could help with the syntax highlighting:\r\n\r\nhttps://pygments.org/"
      },
      {
        "user": "szczyglis-dev",
        "body": "Copy to clipboard button added in [2.1.45](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.45). Thanks!\r\n\r\nCode highlighting coming soon."
      },
      {
        "user": "glinkot",
        "body": "Another notable thing - the one I use applies the code highlighting in real time as the text comes through, rather than just once at the end.  That's really useful as you watch it spool out."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 42,
    "title": "new release but where is gpt-4-turbo-2024-04-09 ?",
    "author": "BillionShields",
    "state": "closed",
    "created_at": "2024-04-11T05:07:05Z",
    "updated_at": "2024-11-15T04:49:50Z",
    "labels": [
      "feature"
    ],
    "body": "Missing in action gpt-4-turbo-2024-04-09 model",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Added in [2.1.45](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.45) ;) Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 37,
    "title": "Monospace font",
    "author": "linnflux",
    "state": "closed",
    "created_at": "2024-03-15T00:50:24Z",
    "updated_at": "2024-11-15T04:49:50Z",
    "labels": [
      "feature"
    ],
    "body": "Brilliant program! \n\nCertain use cases require monospace font output. Editing CSS does not yield results for this. \n\nUsing snap version. Thank you! ",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Thanks!\r\n\r\nThe `Space Mono` font has been added in `2.1.33`.\r\n\r\nTo update font in already defined custom CSS:\r\n\r\n```\r\n// markdown.*.css\r\n\r\npre {{\r\n    font-family: 'Space Mono';\r\n}}\r\ncode {{\r\n    font-family: 'Space Mono';\r\n}}\r\n```"
      },
      {
        "user": "linnflux",
        "body": "Thank you! Works perfectly. "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 63,
    "title": "Image/Dall-E dialogue drops prompt",
    "author": "dreamflasher",
    "state": "closed",
    "created_at": "2024-07-10T11:48:21Z",
    "updated_at": "2024-11-15T04:48:36Z",
    "labels": [
      "bug"
    ],
    "body": "Currently, if I input a prompt in the input area and click send, it shows my prompt  until it gets replaced with the response of the model. Rarely, my prompt remains. Please change this behaviour such that the prompt remains always visible.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Bug fixed in v2.2.20"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 17,
    "title": "llama hub loaders",
    "author": "gfsysa",
    "state": "closed",
    "created_at": "2024-02-01T23:11:15Z",
    "updated_at": "2024-11-15T04:48:06Z",
    "labels": [
      "wontfix"
    ],
    "body": "```\r\n[LLAMA-INDEX] Indexing data...\r\n[LLAMA-INDEX] Idx: base, type: db_current, content: 1706767238\r\nlangchain\\tools\\__init__.py:63: LangChainDeprecationWarning: Importing tools from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\r\n\r\n`from langchain_community.tools import __wrapped__`.\r\n\r\nTo install langchain-community run `pip install -U langchain-community`.\r\n```\r\n\r\nJust a warning, not clear on whether it's an issue. But having issues adding llamachain loaders, agents, packages -- still testing, but unclear on mgmt.",
    "comments": [
      {
        "user": "gfsysa",
        "body": "Worked past that one, I think.\r\n\r\nHit this though indexing a few hundred txt files, it's been erroring for a good 15 min -- not sure how to interrupt, batch, or restart from the last point -- just killed it:\r\n\r\n`[LLAMA-INDEX] Reading documents from path: [omit]\r\n[LLAMA-INDEX] Using online loader for: txt\r\npygame 2.5.2 (SDL 2.28.3, Python 3.10.11)\r\nHello from the pygame community. https://www.pygame.org/contribute.html\r\n2024-02-02 04:52:26.4656787 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1983 onnxruntime::python::CreateInferencePybindStateModule] Init provider bridge failed.\r\nusage: pygpt.exe [-h] [-d DEBUG]\r\npygpt.exe: error: unrecognized arguments: -m pip install -r [omit]/requirements.txt\r\nCommand '[omit]', '-m', 'pip', 'install', '-r', '[omit]/requirements.txt']' returned non-zero exit status 2.\r\nError while indexing file: [omit]\r\nType: CalledProcessError, Message: Command '[omit]', '-m', 'pip', 'install', '-r', '[omit]/requirements.txt']' returned non-zero exit status 2.\r\nTraceback:\r\n  File \"llama_index\\readers\\download.py\", line 49, in download_loader\r\n  File \"llama_index\\download\\module.py\", line 229, in download_llama_module\r\n  File \"llama_index\\download\\module.py\", line 173, in download_module_and_reqs\r\n  File \"subprocess.py\", line 369, in check_call\r\n\r\n[LLAMA-INDEX] Reading documents from path: [omit]\r\n[LLAMA-INDEX] Using online loader for: txt\r\npygame 2.5.2 (SDL 2.28.3, Python 3.10.11)\r\nHello from the pygame community. https://www.pygame.org/contribute.html\r\n2024-02-02 04:52:30.2077052 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1983 onnxruntime::python::CreateInferencePybindStateModule] Init provider bridge failed.\r\nusage: pygpt.exe [-h] [-d DEBUG]\r\npygpt.exe: error: unrecognized arguments: -m pip install -r [omit]/requirements.txt\r\nCommand '[omit]', '-m', 'pip', 'install', '-r', '[omit]/requirements.txt']' returned non-zero exit status 2.\r\nError while indexing file: [omit]\r\nType: CalledProcessError, Message: Command '[omit]', '-m', 'pip', 'install', '-r', '[omit]/requirements.txt']' returned non-zero exit status 2.\r\nTraceback:\r\n  File \"llama_index\\readers\\download.py\", line 49, in download_loader\r\n  File \"llama_index\\download\\module.py\", line 229, in download_llama_module\r\n  File \"llama_index\\download\\module.py\", line 173, in download_module_and_reqs\r\n  File \"subprocess.py\", line 369, in check_call\r\n`\r\n\r\nError Executing pygpt.exe with Pip Install Command: The core issue seems to be with executing a command intended to install Python packages from a requirements.txt file. The command is failing because pygpt.exe is being invoked with arguments that it does not recognize or support (-m pip install -r ...). This results in a non-zero exit status, indicating failure.\r\n\r\nError Handling and Reporting: The application catches the error (a CalledProcessError) and logs a detailed message, including the problematic command and the file it was attempting to process when the error occurred. The traceback shows that the error originates from attempting to download and install modules or requirements as part of the document indexing process.\r\n\r\n\r\n\r\n"
      },
      {
        "user": "szczyglis-dev",
        "body": "Are you using the compiled version?\r\n\r\nIn the compiled version (run from .exe), online-loaders downloaded by llama-index on the fly won't work properly - they only work with the version run directly using Python.\r\n\r\nBtw, you don't need to use an online-loader for .txt files, there's a built-in offline version for .txt files."
      },
      {
        "user": "szczyglis-dev",
        "body": "In release 2.0.146, usage of online-loaders from Llama-index has been disabled if a compiled version of the app is detected (internal architecture of these loaders requires that everything be run in a Python environment)."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 27,
    "title": "no word-wrap  in code blocks",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-09T10:28:13Z",
    "updated_at": "2024-11-15T04:46:45Z",
    "labels": [
      "feature"
    ],
    "body": "version: 2.1.14\r\n\r\nThere is no word-wrap for code block content\r\n<image src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/0babbe3f-df05-4efd-a355-60ce78ba5b7e\" width=\"600\"/>\r\n\r\nI can't find in docs if it possible to enable it.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in `2.1.16`. Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 26,
    "title": "new \"input\" line with \"enter\" option enabled can't be created",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-08T09:39:44Z",
    "updated_at": "2024-11-15T04:46:45Z",
    "labels": [
      "feature"
    ],
    "body": "I'm not able to create new \"input\" line with \"Enter\" option enabled. Any combination which includes \"Enter\" (e.g. Alt+Enter, Shift+Enter) as a part of it submits \"input\".\r\n\r\nI'm able to create new line in \"input\" with \"Shift+Enter\" option enabled using \"Enter\". And then send it using \"shift+enter\" combination.\r\n<img src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/e6110b3f-ee30-4d4e-95d3-f56fe1983f42\" width=\"600\">\r\n\r\nIs this a bug or feature?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "No, this is not a bug, that's how it's supposed to work.\r\n\r\nNew lines can be added with \"Enter\" key only when sending with \"Shift+Enter\" is enabled.\r\n\r\n// edit: New line with \"Shift+Enter\" in \"Enter\" mode has been added in `2.1.14`. Thanks for the suggestion!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 24,
    "title": "Language Chinese ",
    "author": "52sanmao",
    "state": "closed",
    "created_at": "2024-03-06T06:28:08Z",
    "updated_at": "2024-11-15T04:46:45Z",
    "labels": [
      "feature"
    ],
    "body": "Language Can Chinese be added?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "OK, added in version: `2.1.10` ;)"
      },
      {
        "user": "52sanmao",
        "body": "> `2.1.10`;)\r\n\r\nI downloaded the latest version and switched the Chinese without any changes"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 21,
    "title": "add \"Custom_url_api\".",
    "author": "yf007",
    "state": "closed",
    "created_at": "2024-02-28T13:29:16Z",
    "updated_at": "2024-11-15T04:46:44Z",
    "labels": [
      "feature"
    ],
    "body": "I think you might want to add an option to \"Custom url api\",\r\n\r\nPlease give us an option to enter\r\nOPENAI_API_BASE_URL=\r\nOPENAI_API_KEY=\r\nwith our own server.",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Added in release `2.1.12`. \r\n\r\nThanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 6,
    "title": "[feat] Create `.desktop` entry",
    "author": "moritztim",
    "state": "closed",
    "created_at": "2024-01-17T12:42:12Z",
    "updated_at": "2024-11-15T04:45:40Z",
    "labels": [
      "feature"
    ],
    "body": "It would be great to get to pygpt from an app launcher",
    "comments": [
      {
        "user": "moritztim",
        "body": "Nevermind, I just had to log out and back in"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 2,
    "title": "Integrate Langchain / Llama-index to query over documents",
    "author": "kaneda2004",
    "state": "closed",
    "created_at": "2023-05-04T01:34:44Z",
    "updated_at": "2024-11-15T04:45:39Z",
    "labels": [
      "feature"
    ],
    "body": "I've been tinkering around with using Langchain / llama-index to vector embed documents and then run OpenAI LLM queries over the vector embeddings.. I think this would be a great addition to PYGPT -- happy to collaborate on it with you if need be -- just checking to see if there's any interest in this on your end?\r\n\r\nhttps://github.com/jerryjliu/llama_index\r\n\r\nhttps://github.com/hwchase17/langchain\r\n\r\nThanks",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Yes, of course, I am very open to collaborate with you on this topic, I thought about it myself, and these options are in the plans for a long time and everything will be implemented, including something that I would like to work like AutoGPT, but be easier to use for people, than AutoGPT. All these options will be done, but a little later, because at the moment, unfortunately, I have a bit of other things on my mind related to everyday life. We'll deal with that, of course we do! ;)\r\n\r\nThanks and best regards!"
      },
      {
        "user": "szczyglis-dev",
        "body": "Langchain is already integrated (from PyGPT version >= 2.0.0).\r\n\r\nVector databases support coming soon ;)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 4,
    "title": "network error at the beginning",
    "author": "2659494286",
    "state": "closed",
    "created_at": "2024-01-15T20:56:52Z",
    "updated_at": "2024-11-15T04:45:21Z",
    "labels": [
      "bug"
    ],
    "body": "File \"/home/joker/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 982, in _retry_request\r\n    return self._request(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/home/joker/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 911, in _request\r\n    return self._retry_request(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/joker/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 982, in _retry_request\r\n    return self._request(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/home/joker/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in _request\r\n    raise APIConnectionError(request=request) from err\r\n\r\nError in GPT custom call: Connection error.\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "This looks like an connection issue on the openai library side.\r\nCould you provide a list of the library versions you have installed?\r\n\r\nPlease include this information:\r\n\r\n- `pip list` output\r\n- PyGPT version"
      },
      {
        "user": "2659494286",
        "body": "![image](https://github.com/szczyglis-dev/py-gpt/assets/15061456/f8cb363d-0131-444b-95d7-5afc9f090b19)\r\npip list:\r\nPackage                                  Version\r\n---------------------------------------- ---------------\r\nabsl-py                                  2.0.0\r\naiobotocore                              2.9.0\r\naiofiles                                 22.1.0\r\naiohttp                                  3.9.1\r\naioitertools                             0.7.1\r\naiosignal                                1.3.1\r\naiosqlite                                0.18.0\r\nalabaster                                0.7.12\r\naltair                                   5.2.0\r\naltgraph                                 0.17.3\r\nanaconda-anon-usage                      0.4.2\r\nanaconda-catalogs                        0.2.0\r\nanaconda-client                          1.12.1\r\nanaconda-cloud-auth                      0.1.3\r\nanaconda-navigator                       2.5.0\r\nanaconda-project                         0.11.1\r\naniso8601                                9.0.1\r\nannotated-types                          0.6.0\r\nanyio                                    3.7.1\r\nappdirs                                  1.4.4\r\nargon2-cffi                              21.3.0\r\nargon2-cffi-bindings                     21.2.0\r\narrow                                    1.2.3\r\nasgiref                                  3.7.2\r\nastroid                                  2.14.2\r\nastropy                                  5.1\r\nasttokens                                2.0.5\r\nastunparse                               1.6.3\r\nasync-timeout                            4.0.2\r\nasyncio                                  3.4.3\r\natomicwrites                             1.4.0\r\nattrs                                    22.2.0\r\nautogen                                  1.0.16\r\nAutomat                                  20.2.0\r\nautopep8                                 1.6.0\r\nazure-cognitiveservices-speech           1.27.0\r\nBabel                                    2.11.0\r\nbackcall                                 0.2.0\r\nbackoff                                  2.2.1\r\nbackports.functools-lru-cache            1.6.4\r\nbackports.tempfile                       1.0\r\nbackports.weakref                        1.0.post1\r\nbayesian-optimization                    1.4.3\r\nbcrypt                                   4.1.2\r\nbeautifulsoup4                           4.12.2\r\nbinaryornot                              0.4.4\r\nblack                                    0.0\r\nbleach                                   6.0.0\r\nbokeh                                    3.2.1\r\nboltons                                  23.0.0\r\nbotocore                                 1.33.13\r\nBottleneck                               1.3.5\r\nbrotlipy                                 0.7.0\r\nbs4                                      0.0.1\r\nbuild                                    0.10.0\r\ncachetools                               5.3.2\r\ncertifi                                  2022.12.7\r\ncffi                                     1.15.1\r\ncftime                                   1.6.3\r\nchardet                                  4.0.0\r\ncharset-normalizer                       3.1.0\r\nchroma-hnswlib                           0.7.2\r\nchromadb                                 0.4.5\r\nclick                                    8.1.7\r\ncloudpickle                              2.2.1\r\nclyent                                   1.2.2\r\ncmake                                    3.28.1\r\ncolorama                                 0.4.6\r\ncolorcet                                 3.0.1\r\ncoloredlogs                              15.0.1\r\ncomm                                     0.1.2\r\nconda                                    23.7.4\r\nconda-build                              3.26.1\r\nconda-content-trust                      0.2.0\r\nconda_index                              0.3.0\r\nconda-libmamba-solver                    23.7.0\r\nconda-pack                               0.6.0\r\nconda-package-handling                   2.2.0\r\nconda_package_streaming                  0.9.0\r\nconda-repo-cli                           1.0.75\r\nconda-token                              0.4.0\r\nconda-verify                             3.4.2\r\nconstantly                               15.1.0\r\ncontourpy                                1.0.5\r\ncookiecutter                             1.7.3\r\ncroniter                                 2.0.1\r\ncryptography                             40.0.1\r\ncssselect                                1.1.0\r\ncycler                                   0.11.0\r\ncytoolz                                  0.12.0\r\ndaal4py                                  2023.1.1\r\ndashscope                                1.13.6\r\ndask                                     2023.6.0\r\ndataclasses-json                         0.6.3\r\ndatasets                                 2.16.1\r\ndatashader                               0.15.2\r\ndatashape                                0.5.4\r\nddgr                                     1.9\r\ndebugpy                                  1.6.7\r\ndecorator                                5.1.1\r\ndecord                                   0.6.0\r\ndefusedxml                               0.7.1\r\nDeprecated                               1.2.14\r\ndiff-match-patch                         20200713\r\ndill                                     0.3.6\r\ndiskcache                                5.6.3\r\ndistributed                              2023.6.0\r\ndistro                                   1.8.0\r\ndocker                                   7.0.0\r\ndocopt                                   0.6.2\r\ndocstring-to-markdown                    0.11\r\ndocutils                                 0.19\r\ndocx2txt                                 0.8\r\nEbookLib                                 0.18\r\nentrypoints                              0.4\r\net-xmlfile                               1.1.0\r\nevdev                                    1.6.1\r\nexceptiongroup                           1.2.0\r\nexecuting                                0.8.3\r\nfaiss-cpu                                1.7.4\r\nfastapi                                  0.99.1\r\nfastjsonschema                           2.16.2\r\nffmpy                                    0.3.1\r\nfilelock                                 3.9.0\r\nfire                                     0.5.0\r\nflake8                                   6.0.0\r\nFLAML                                    2.1.1\r\nFlask                                    2.2.3\r\nFlask-Cors                               3.0.10\r\nFlask-RESTful                            0.3.9\r\nflatbuffers                              23.5.26\r\nfonttools                                4.25.0\r\nfrozenlist                               1.3.3\r\nfsspec                                   2023.12.2\r\nfuture                                   0.18.3\r\ngast                                     0.5.4\r\ngensim                                   4.3.0\r\nglob2                                    0.7\r\ngmpy2                                    2.1.2\r\ngoogle-auth                              2.25.2\r\ngoogle-auth-oauthlib                     1.1.0\r\ngoogle-pasta                             0.2.0\r\ngoogleapis-common-protos                 1.62.0\r\ngradio                                   3.50.2\r\ngradio_client                            0.6.1\r\ngreenlet                                 3.0.1\r\ngrpcio                                   1.60.0\r\nh11                                      0.14.0\r\nh5py                                     3.9.0\r\nHeapDict                                 1.0.1\r\nholoviews                                1.17.1\r\nhtml2text                                2020.1.16\r\nhttpcore                                 1.0.2\r\nhttptools                                0.6.1\r\nhttpx                                    0.25.2\r\nhuggingface-hub                          0.20.2\r\nhumanfriendly                            10.0\r\nhvplot                                   0.8.4\r\nhyperlink                                21.0.0\r\nidna                                     3.4\r\nimagecodecs                              2023.1.23\r\nimageio                                  2.31.1\r\nimagesize                                1.4.1\r\nimbalanced-learn                         0.10.1\r\nimportlib-metadata                       6.3.0\r\nimportlib-resources                      6.1.1\r\nincremental                              21.3.0\r\ninflection                               0.5.1\r\niniconfig                                2.0.0\r\nintake                                   0.6.8\r\nintervaltree                             3.1.0\r\nipykernel                                6.25.0\r\nipython                                  8.15.0\r\nipython-genutils                         0.2.0\r\nipywidgets                               8.0.4\r\nisort                                    5.9.3\r\nitemadapter                              0.3.0\r\nitemloaders                              1.0.4\r\nitsdangerous                             2.0.1\r\njaraco.classes                           3.2.3\r\njedi                                     0.18.1\r\njeepney                                  0.8.0\r\njellyfish                                1.0.1\r\nJinja2                                   3.1.2\r\njinja2-time                              0.2.0\r\njmespath                                 0.10.0\r\njoblib                                   1.3.2\r\njson5                                    0.9.6\r\njsonpatch                                1.33\r\njsonpointer                              2.4\r\njsonschema                               4.17.3\r\njupyter                                  1.0.0\r\njupyter_client                           7.4.9\r\njupyter-console                          6.6.3\r\njupyter_core                             5.3.0\r\njupyter-events                           0.6.3\r\njupyter-server                           1.23.4\r\njupyter_server_fileid                    0.9.0\r\njupyter_server_ydoc                      0.8.0\r\njupyter-ydoc                             0.2.4\r\njupyterlab                               3.6.3\r\njupyterlab-pygments                      0.1.2\r\njupyterlab_server                        2.22.0\r\njupyterlab-widgets                       3.0.5\r\nkaleido                                  0.2.1\r\nkeras                                    2.15.0\r\nkeyring                                  23.13.1\r\nkiwisolver                               1.4.4\r\nkubernetes                               29.0.0\r\nlangchain                                0.1.0\r\nlangchain-community                      0.0.11\r\nlangchain-core                           0.1.10\r\nlangchain-experimental                   0.0.49\r\nlangchain-openai                         0.0.2.post1\r\nlangsmith                                0.0.80\r\nlazy_loader                              0.2\r\nlazy-object-proxy                        1.6.0\r\nlibarchive-c                             2.9\r\nlibclang                                 16.0.6\r\nlibmambapy                               1.5.1\r\nlinkify-it-py                            2.0.0\r\nlit                                      17.0.6\r\nllama-hub                                0.0.69\r\nllama-index                              0.9.29\r\nllvmlite                                 0.40.0\r\nlmdb                                     1.4.1\r\nlocket                                   1.0.0\r\nlxml                                     5.1.0\r\nlz4                                      4.3.2\r\nMarkdown                                 3.5.1\r\nmarkdown-it-py                           2.2.0\r\nMarkupSafe                               2.1.2\r\nmarshmallow                              3.20.1\r\nmatplotlib                               3.7.2\r\nmatplotlib-inline                        0.1.6\r\nmccabe                                   0.7.0\r\nmdit-py-plugins                          0.3.0\r\nmdurl                                    0.1.2\r\nmistune                                  0.8.4\r\nmkl-fft                                  1.3.8\r\nmkl-random                               1.2.4\r\nmkl-service                              2.4.0\r\nml-dtypes                                0.2.0\r\nmmh3                                     4.1.0\r\nmonotonic                                1.6\r\nmore-itertools                           9.1.0\r\nmpmath                                   1.3.0\r\nmsgpack                                  1.0.3\r\nmultidict                                6.0.4\r\nmultipledispatch                         0.6.0\r\nmultiprocess                             0.70.14\r\nmunkres                                  1.1.4\r\nmypy-extensions                          1.0.0\r\nnavigator-updater                        0.4.0\r\nnbclassic                                0.5.5\r\nnbclient                                 0.5.13\r\nnbconvert                                6.5.4\r\nnbformat                                 5.9.2\r\nnest-asyncio                             1.5.8\r\nnetCDF4                                  1.6.5\r\nnetworkx                                 3.2.1\r\nnh3                                      0.2.15\r\nnltk                                     3.8.1\r\nnotebook                                 6.5.4\r\nnotebook_shim                            0.2.2\r\nnumba                                    0.57.1\r\nnumexpr                                  2.8.4\r\nnumpy                                    1.26.2\r\nnumpydoc                                 1.5.0\r\noauthlib                                 3.2.2\r\nonnxruntime                              1.16.3\r\nopenai                                   1.7.2\r\nopencv-python                            4.8.1.78\r\nopencv-python-headless                   4.8.1.78\r\nopenpyxl                                 3.1.2\r\nopentelemetry-api                        1.22.0\r\nopentelemetry-exporter-otlp-proto-common 1.22.0\r\nopentelemetry-exporter-otlp-proto-grpc   1.22.0\r\nopentelemetry-instrumentation            0.43b0\r\nopentelemetry-instrumentation-asgi       0.43b0\r\nopentelemetry-instrumentation-fastapi    0.43b0\r\nopentelemetry-proto                      1.22.0\r\nopentelemetry-sdk                        1.22.0\r\nopentelemetry-semantic-conventions       0.43b0\r\nopentelemetry-util-http                  0.43b0\r\nopt-einsum                               3.3.0\r\norjson                                   3.9.10\r\noverrides                                7.4.0\r\npackaging                                23.2\r\npandas                                   2.1.4\r\npandocfilters                            1.5.0\r\npanel                                    1.2.3\r\nparam                                    1.13.0\r\nparsel                                   1.6.0\r\nparso                                    0.8.3\r\npartd                                    1.4.0\r\npathlib                                  1.0.1\r\npathspec                                 0.10.3\r\npatsy                                    0.5.3\r\npdf2docx                                 0.5.7\r\npep8                                     1.7.1\r\npexpect                                  4.8.0\r\npickleshare                              0.7.5\r\npillow                                   10.2.0\r\npip                                      23.2.1\r\npip-tools                                7.3.0\r\npkce                                     1.0.3\r\npkginfo                                  1.9.6\r\nplatformdirs                             3.10.0\r\nplotly                                   5.9.0\r\npluggy                                   1.3.0\r\nply                                      3.11\r\nposthog                                  3.3.1\r\npoyo                                     0.5.0\r\nprometheus-client                        0.14.1\r\nprompt-toolkit                           3.0.36\r\nProtego                                  0.1.16\r\nprotobuf                                 4.23.4\r\npsutil                                   5.9.7\r\nptyprocess                               0.7.0\r\npulsar-client                            3.4.0\r\npure-eval                                0.2.2\r\npy-cpuinfo                               8.0.0\r\npyaml                                    23.12.0\r\npyarrow                                  11.0.0\r\npyarrow-hotfix                           0.6\r\npyasn1                                   0.4.8\r\npyasn1-modules                           0.2.8\r\nPyAudio                                  0.2.14\r\npyautogen                                0.2.4\r\npycodestyle                              2.10.0\r\npycosat                                  0.6.4\r\npycparser                                2.21\r\npyct                                     0.5.0\r\npycurl                                   7.45.2\r\npydantic                                 2.5.2\r\npydantic_core                            2.14.5\r\nPyDispatcher                             2.0.5\r\npydocstyle                               6.3.0\r\npydub                                    0.25.1\r\npyerfa                                   2.0.0\r\npyflakes                                 3.0.1\r\npygame                                   2.5.2\r\nPygments                                 2.15.0\r\npygpt-net                                2.0.106\r\npyinstaller                              5.13.2\r\npyinstaller-hooks-contrib                2023.12\r\nPyJWT                                    2.4.0\r\npylint                                   2.16.2\r\npylint-venv                              2.3.0\r\npyls-spyder                              0.4.0\r\nPyMuPDF                                  1.23.8\r\nPyMuPDFb                                 1.23.7\r\npynput                                   1.7.6\r\npyodbc                                   4.0.34\r\npyOpenSSL                                23.2.0\r\npyparsing                                3.0.9\r\npypdf                                    3.17.4\r\nPyPika                                   0.48.9\r\npyproject_hooks                          1.0.0\r\nPyQt5-sip                                12.11.0\r\npyrsistent                               0.18.0\r\nPySide6                                  6.6.1\r\nPySide6-Addons                           6.6.1\r\nPySide6-Essentials                       6.6.1\r\nPySocks                                  1.7.1\r\npytesseract                              0.3.10\r\npytest                                   7.4.3\r\npython-dateutil                          2.8.2\r\npython-docx                              0.8.11\r\npython-dotenv                            1.0.0\r\npython-json-logger                       2.0.7\r\npython-lsp-black                         1.2.1\r\npython-lsp-jsonrpc                       1.0.0\r\npython-lsp-server                        1.7.2\r\npython-multipart                         0.0.6\r\npython-slugify                           5.0.2\r\npython-snappy                            0.6.1\r\npython-telegram-bot                      20.3\r\npython-xlib                              0.33\r\npytoolconfig                             1.2.5\r\npytorch-triton-rocm                      2.1.0\r\npytube                                   15.0.0\r\npytz                                     2023.3.post1\r\npyviz-comms                              2.3.0\r\nPyWavelets                               1.4.1\r\npyxdg                                    0.28\r\nPyYAML                                   6.0.1\r\npyzmq                                    23.2.0\r\nQDarkStyle                               3.0.2\r\nqstylizer                                0.2.2\r\nqt-material                              2.14\r\nQtAwesome                                1.2.2\r\nqtconsole                                5.4.2\r\nQtPy                                     2.2.0\r\nqueuelib                                 1.5.0\r\nreadme-renderer                          37.3\r\nregex                                    2023.3.23\r\nrequests                                 2.31.0\r\nrequests-file                            1.5.1\r\nrequests-oauthlib                        1.3.1\r\nrequests-toolbelt                        0.10.1\r\nresponses                                0.13.3\r\nretrying                                 1.3.4\r\nrfc3339-validator                        0.1.4\r\nrfc3986                                  2.0.0\r\nrfc3986-validator                        0.1.1\r\nrich                                     13.3.4\r\nrope                                     1.7.0\r\nrsa                                      4.9\r\nRtree                                    1.0.1\r\nruamel.yaml                              0.17.21\r\nruamel-yaml-conda                        0.17.21\r\ns3fs                                     2023.12.2\r\nsafetensors                              0.3.2\r\nscikit-image                             0.20.0\r\nscikit-learn                             1.3.0\r\nscikit-learn-intelex                     20230426.111612\r\nscipy                                    1.11.1\r\nScrapy                                   2.8.0\r\nseaborn                                  0.12.2\r\nSecretStorage                            3.3.3\r\nsemantic-version                         2.10.0\r\nSend2Trash                               1.8.0\r\nservice-identity                         18.1.0\r\nsetuptools                               68.0.0\r\nshiboken6                                6.6.1\r\nshow-in-file-manager                     1.1.4\r\nsip                                      6.6.2\r\nsix                                      1.16.0\r\nsmart-open                               5.2.1\r\nsniffio                                  1.3.0\r\nsnowballstemmer                          2.2.0\r\nsortedcontainers                         2.4.0\r\nsoupsieve                                2.4\r\nspark-parser                             1.8.9\r\nSpeechRecognition                        3.10.0\r\nSphinx                                   5.0.2\r\nsphinxcontrib-applehelp                  1.0.2\r\nsphinxcontrib-devhelp                    1.0.2\r\nsphinxcontrib-htmlhelp                   2.0.0\r\nsphinxcontrib-jsmath                     1.0.1\r\nsphinxcontrib-qthelp                     1.0.3\r\nsphinxcontrib-serializinghtml            1.1.5\r\nspyder                                   5.4.3\r\nspyder-kernels                           2.4.4\r\nSQLAlchemy                               2.0.23\r\nstack-data                               0.2.0\r\nstarlette                                0.27.0\r\nstatsmodels                              0.14.0\r\nsupervision                              0.17.1\r\nsympy                                    1.11.1\r\ntables                                   3.8.0\r\ntabulate                                 0.8.10\r\nTBB                                      0.2\r\ntblib                                    1.7.0\r\ntenacity                                 8.2.3\r\ntensorboard                              2.15.1\r\ntensorboard-data-server                  0.7.2\r\ntensorflow                               2.15.0.post1\r\ntensorflow-estimator                     2.15.0\r\ntensorflow-io-gcs-filesystem             0.34.0\r\ntermcolor                                2.4.0\r\nterminado                                0.17.1\r\ntext-unidecode                           1.3\r\ntextdistance                             4.2.1\r\nthreadpoolctl                            2.2.0\r\nthree-merge                              0.1.1\r\ntifffile                                 2023.4.12\r\ntiktoken                                 0.5.2\r\ntinycss2                                 1.2.1\r\ntldextract                               3.2.0\r\ntokenizers                               0.15.0\r\ntoml                                     0.10.2\r\ntomli                                    2.0.1\r\ntomlkit                                  0.11.1\r\ntoolz                                    0.12.0\r\ntorch                                    2.1.2+rocm5.6\r\ntorchaudio                               2.1.2+rocm5.6\r\ntorchvision                              0.16.2+rocm5.6\r\ntornado                                  6.3.2\r\ntqdm                                     4.65.0\r\ntraitlets                                5.7.1\r\ntransformers                             4.36.2\r\ntwine                                    4.0.2\r\nTwisted                                  22.10.0\r\ntyper                                    0.9.0\r\ntyping_extensions                        4.8.0\r\ntyping-inspect                           0.9.0\r\ntzdata                                   2023.4\r\nuc-micro-py                              1.0.1\r\nujson                                    5.4.0\r\nuncompyle6                               3.7.4\r\nUnidecode                                1.2.0\r\nurllib3                                  1.26.15\r\nuvicorn                                  0.25.0\r\nuvloop                                   0.19.0\r\nw3lib                                    1.21.0\r\nwatchdog                                 2.1.6\r\nwatchfiles                               0.21.0\r\nwcwidth                                  0.2.5\r\nwebencodings                             0.5.1\r\nwebsocket-client                         0.58.0\r\nwebsockets                               11.0.3\r\nWerkzeug                                 2.2.3\r\nwhatthepatch                             1.0.2\r\nwheel                                    0.38.4\r\nwidgetsnbextension                       4.0.5\r\nwikipedia                                1.4.0\r\nwrapt                                    1.16.0\r\nwurlitzer                                3.0.2\r\nxarray                                   2023.6.0\r\nxdis                                     5.0.13\r\nxlrd                                     2.0.1\r\nxxhash                                   2.0.2\r\nxyzservices                              2022.9.0\r\ny-py                                     0.5.9\r\nyapf                                     0.31.0\r\nyarl                                     1.8.2\r\nypy-websocket                            0.8.2\r\nzict                                     2.2.0\r\nzipp                                     3.15.0\r\nzope.interface                           5.4.0\r\nzstandard                                0.19.0\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nIt maybe because of the network proxy software.Pygpt works well on the Windows system with clash.I dont find a useful proxy software on ubuntu.I use qv2ray,but it doesnt work well.Do you have some prxoy softwares to use on ubuntu to recommend? "
      },
      {
        "user": "szczyglis-dev",
        "body": "I'm afraid I can't recommend a one best proxy for Ubuntu.\r\nThe proxy might be the cause, but unfortunately, I can't help in this matter, as the issue of the network connection itself is beyond the scope of PyGPT."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 3,
    "title": "No settings option in plugins. (PyGPT v0.9.6 | build 2023.04.16)",
    "author": "soccerwithag",
    "state": "closed",
    "created_at": "2023-09-18T02:57:21Z",
    "updated_at": "2024-11-15T04:45:21Z",
    "labels": [
      "bug"
    ],
    "body": "As title states, there is no place to configure the settings for plugins (such as api keys). \r\n\r\nRunning on MacOS, installed in venv from source.\r\n\r\nOtherwise working fine.\r\n\r\n<img width=\"516\" alt=\"image\" src=\"https://github.com/szczyglis-dev/py-gpt/assets/93694026/33398f17-ee4e-41b3-895e-43febd72fe0a\">\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, is this issue still exists in newest version (2.0.1) ?"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 73,
    "title": "version 2.4.9 fail after upgrade",
    "author": "proitservices",
    "state": "closed",
    "created_at": "2024-11-12T15:42:45Z",
    "updated_at": "2024-11-15T04:44:47Z",
    "labels": [
      "bug"
    ],
    "body": "Hi, \r\n\r\nJust updated via snap to 2.4.9\r\ncommands:\r\n  - pygpt\r\nsnap-id:      c0Brljab75R0J5x0Gq5IdzPcD69IPzCF\r\ntracking:     latest/stable\r\nrefresh-date: today at 15:12 GMT\r\nchannels:\r\n  latest/stable:    2.4.9 2024-11-12 (276) 969MB -\r\n  latest/candidate:                             \r\n  latest/beta:                                  \r\n  latest/edge:                                  \r\ninstalled:          2.4.9            (276) 969MB -\r\n\r\nThe application worked few minutes ago on 2.4.8 but this version is no longer available.\r\n\r\n\r\nOS release\r\nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\r\nNAME=\"Ubuntu\"\r\nVERSION_ID=\"24.04\"\r\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\r\n\r\npackages\r\napt show python3-dev\r\nPackage: python3-dev\r\nVersion: 3.12.3-0ubuntu2\r\n\r\napt show python3-tk\r\nPackage: python3-tk\r\nVersion: 3.12.3-0ubuntu1\r\n\r\npython3-tk is already the newest version (3.12.3-0ubuntu1).\r\npython3-dev is already the newest version (3.12.3-0ubuntu2).\r\n\r\n\r\nIssues I see from logs:\r\njournalctl\r\n\r\nNov 12 15:40:32 piotr-HP-ProBook-430-G7 systemd[1991]: Started snap.pygpt.pygpt-b56ed575-502d-419a-8de7-d7fa1e2c73c0.scope.\r\nNov 12 15:40:32 piotr-HP-ProBook-430-G7 kernel: audit: type=1400 audit(1731426032.369:849): apparmor=\"DENIED\" operation=\"open\" class=\"file\" profile=\"snap-update-ns.pygpt\" name=\"/proc/15043/maps\" pid=15043 comm=\"5\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=0\r\nNov 12 15:40:32 piotr-HP-ProBook-430-G7 kernel: audit: type=1400 audit(1731426032.689:850): apparmor=\"DENIED\" operation=\"open\" class=\"file\" profile=\"snap.pygpt.pygpt\" name=\"/snap/core22/1663/usr/lib/x86_64-linux-gnu/libpcre.so.3.13.3\" pid=15091 comm=\"python3\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=0\r\nNov 12 15:40:35 piotr-HP-ProBook-430-G7 pygpt_pygpt.desktop[15091]: NOTE: You must install tkinter on Linux to use MouseInfo. Run the following: sudo apt-get install python3-tk python3-dev\r\nNov 12 15:40:35 piotr-HP-ProBook-430-G7 systemd[1991]: snap.pygpt.pygpt-b56ed575-502d-419a-8de7-d7fa1e2c73c0.scope: Consumed 4.041s CPU time.\r\n\r\nCan you please advise?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, this is already fixed in: `2.4.10`"
      },
      {
        "user": "proitservices",
        "body": "Great, thank you for the quick turn around. Weill keep you posted."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 66,
    "title": "Trying to index files continues even after a rate limit error",
    "author": "helsingi",
    "state": "closed",
    "created_at": "2024-07-12T21:07:07Z",
    "updated_at": "2024-11-15T04:44:46Z",
    "labels": [
      "bug"
    ],
    "body": "App version 2.2.19 running on Windows 11\r\n\r\n**Issue:**\r\nAfter uploading files and pressing \"INDEX ALL\" the code attempts to index each and every file regardless of the error received from openai about the quota exceeded. Then of course the error keeps appearing for all the files and I need to wait for the process (attempting to index each file) to finish to see which files were successfully indexed before the rate limit being hit. After the wait, a pop-up window appears with all the errors regarding each file.\r\n\r\n**Error Message:**\r\n`Error while indexing file: filepath.pdf\r\nType: RateLimitErrorMessage: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}`\r\n\r\n**Suggestion:**\r\nTo stop the process of trying to index files once an error occurs that data limit has been reached or quota exceeded.\r\n\r\n\r\nThanks for the great app!",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In version `2.2.22`:\r\n\r\n- Added a new option in Config -> Indexes (llama-index) -> Indexing -> **Stop indexing on error.** \r\nIf enabled, indexing will stop whenever an error occurs. Default: True"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 62,
    "title": "cannot import name 'FileSystemReaderMixin'",
    "author": "sk9la",
    "state": "closed",
    "created_at": "2024-07-08T16:30:40Z",
    "updated_at": "2024-11-15T04:44:46Z",
    "labels": [
      "bug"
    ],
    "body": "Hi,\r\n\r\nAfter install pygpt from pypi using pipx\r\n`pipx install pygpt-net` I had this error\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/pygpt\", line 5, in <module>\r\n    from pygpt_net.app import run\r\n  File \"/usr/local/lib/python3/venv/pygpt-net/lib/python3.11/site-packages/pygpt_net/app.py\", line 73, in <module>\r\n    from pygpt_net.provider.loaders.web_microsoft_onedrive import Loader as MicrosoftOneDriveLoader\r\n  File \"/usr/local/lib/python3/venv/pygpt-net/lib/python3.11/site-packages/pygpt_net/provider/loaders/web_microsoft_onedrive.py\", line 16, in <module>\r\n    from llama_index.readers.microsoft_onedrive.base import OneDriveReader\r\n  File \"/usr/local/lib/python3/venv/pygpt-net/lib/python3.11/site-packages/llama_index/readers/microsoft_onedrive/__init__.py\", line 1, in <module>\r\n    from llama_index.readers.microsoft_onedrive.base import OneDriveReader\r\n  File \"/usr/local/lib/python3/venv/pygpt-net/lib/python3.11/site-packages/llama_index/readers/microsoft_onedrive/base.py\", line 15, in <module>\r\n    from llama_index.core.readers import FileSystemReaderMixin\r\nImportError: cannot import name 'FileSystemReaderMixin' from 'llama_index.core.readers' (/usr/local/lib/python3/venv/pygpt-net/lib/python3.11/site-packages/llama_index/core/readers/__init__.py)\r\n```\r\nI'm using pipx with python3.11.9\r\n\r\nAny ideas ?\r\n",
    "comments": [
      {
        "user": "astrojerms",
        "body": "Seems to be related to this issue from llama:\r\nhttps://github.com/run-llama/llama_index/issues/11336\r\n\r\nI was able to resolve it by upgrading two llama libraries:\r\npip install -U llama-index-vector-stores-chroma\r\npip install -U llama-index-readers-file\r\n"
      },
      {
        "user": "sk9la",
        "body": "Thanks, it works now :smile: \r\n\r\nOnly `llama-index-readers-file` got updated to 0.1.30"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 51,
    "title": "Exception: No existing llama_index.core.vector_stores ",
    "author": "mikeybob",
    "state": "closed",
    "created_at": "2024-04-25T20:14:54Z",
    "updated_at": "2024-11-15T04:44:46Z",
    "labels": [
      "bug"
    ],
    "body": "I've started receiving this error in version 76, and it has popped up again in 78. This happens anytime the ai starts to look something up online.\r\n\r\n\r\n```\r\nException: No existing llama_index.core.vector_stores.simple found at /home/mike/.config/pygpt-net/idx/base/vector_store.json, skipping load.\r\nType: ValueErrorMessage: No existing llama_index.core.vector_stores.simple found at /home/mike/.config/pygpt-net/idx/base/vector_store.json, skipping load.\r\nTraceback:   File \"/home/mike/.cache/pypoetry/virtualenvs/pygpt-net-sJoELmaO-py3.10/lib/python3.10/site-packages/llama_index/core/storage/storage_context.py\", line 122, in from_defaults\r\n    vector_stores = SimpleVectorStore.from_namespaced_persist_dir(\r\n  File \"/home/mike/.cache/pypoetry/virtualenvs/pygpt-net-sJoELmaO-py3.10/lib/python3.10/site-packages/llama_index/core/vector_stores/simple.py\", line 160, in from_namespaced_persist_dir\r\n    vector_stores[DEFAULT_VECTOR_STORE] = cls.from_persist_dir(\r\n  File \"/home/mike/.cache/pypoetry/virtualenvs/pygpt-net-sJoELmaO-py3.10/lib/python3.10/site-packages/llama_index/core/vector_stores/simple.py\", line 125, in from_persist_dir\r\n    return cls.from_persist_path(persist_path, fs=fs)\r\n  File \"/home/mike/.cache/pypoetry/virtualenvs/pygpt-net-sJoELmaO-py3.10/lib/python3.10/site-packages/llama_index/core/vector_stores/simple.py\", line 305, in from_persist_path\r\n    raise ValueError(\r\n```\r\n\r\nI'm on Fedora 40 x86_64. I run the app using a clone of the repository and use poetry to setup and run.\r\n\r\n",
    "comments": [
      {
        "user": "mikeybob",
        "body": "If i'm understanding the documentation correctly, this vector is internal, and nothing needs to be passed to it."
      },
      {
        "user": "szczyglis-dev",
        "body": "Did you changed any parameters such as the embedding model or other custom arguments in `Config -> Llama-index` after creating the index? Maybe try to recreate the index by clearing the `./config/pygpt-net/idx/base` directory (after deleting all files or entire `base` directory, the index should re-create itself).\r\n\r\nFrom Llama-index documentation:\r\n\r\n> Important: if you had initialized your index with a custom transformations, embed_model, etc., you will need to pass in the same options during load_index_from_storage, or have it set as the global settings.\r\n\r\nhttps://docs.llamaindex.ai/en/stable/understanding/storing/storing/"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 50,
    "title": "Indexing Fails",
    "author": "kantic",
    "state": "closed",
    "created_at": "2024-04-23T11:25:52Z",
    "updated_at": "2024-11-15T04:44:45Z",
    "labels": [
      "bug"
    ],
    "body": "The indexing of files doesn't work and throws an error.\r\n\r\nMy setup is the following:\r\nI've installed pygpt version 2.1.71 via snapd on a fresh VM with Ubuntu-22.04.\r\n\r\nWhen I try to index my files, I get the following error message:\r\n```\r\nException: 'type'\r\nType: KeyErrorMessage: 'type'\r\nTraceback:   File \"/data/home/user/Software/pygpt/venv/lib/python3.11/site-packages/pygpt_net/core/idx/llm.py\", line 94, in get_embeddings_provider\r\n    return self.window.core.llm.llms[provider].get_embeddings_model(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/home/user/Software/pygpt/venv/lib/python3.11/site-packages/pygpt_net/provider/llms/openai.py\", line 76, in get_embeddings_model\r\n    args = self.parse_args({\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"/data/home/user/Software/pygpt/venv/lib/python3.11/site-packages/pygpt_net/provider/llms/base.py\", line 77, in parse_args\r\n    args = parse_args(options['args'])\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/home/user/Software/pygpt/venv/lib/python3.11/site-packages/pygpt_net/utils.py\", line 114, in parse_args\r\n    type = item['type']\r\n           ~~~~^^^^^^^^\r\n```",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in [2.1.73](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.73)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 41,
    "title": "Datasource validation error on first launch",
    "author": "bradleman",
    "state": "closed",
    "created_at": "2024-04-04T14:06:51Z",
    "updated_at": "2024-11-15T04:44:45Z",
    "labels": [
      "bug"
    ],
    "body": "New install of pygpt on Debian 12 errors when I try to launch it:\r\n         \r\nTraceback (most recent call last):\r\n  File \"/root/pygpt-env/bin/pygpt\", line 5, in <module>\r\n    from pygpt_net.app import run\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/app.py\", line 12, in <module>\r\n    from pygpt_net.launcher import Launcher\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/launcher.py\", line 22, in <module>\r\n    from pygpt_net.ui.main import MainWindow\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/ui/main.py\", line 16, in <module>\r\n    from pygpt_net.container import Container\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/container.py\", line 25, in <module>\r\n    from pygpt_net.core.idx import Idx\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/core/idx/__init__.py\", line 19, in <module>\r\n    from pygpt_net.provider.vector_stores import Storage\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pygpt_net/provider/vector_stores/__init__.py\", line 14, in <module>\r\n    from llama_index.core.indices.base import BaseIndex\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/__init__.py\", line 19, in <module>\r\n    from llama_index.core.indices import (\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/indices/__init__.py\", line 4, in <module>\r\n    from llama_index.core.indices.composability.graph import ComposableGraph\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/indices/composability/__init__.py\", line 4, in <module>\r\n    from llama_index.core.indices.composability.graph import ComposableGraph\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/indices/composability/graph.py\", line 7, in <module>\r\n    from llama_index.core.indices.base import BaseIndex\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/indices/base.py\", line 12, in <module>\r\n    from llama_index.core.ingestion import run_transformations\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/ingestion/__init__.py\", line 2, in <module>\r\n    from llama_index.core.ingestion.pipeline import (\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/ingestion/pipeline.py\", line 31, in <module>\r\n    from llama_index.core.ingestion.api_utils import get_client\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/ingestion/api_utils.py\", line 20, in <module>\r\n    from llama_index.core.ingestion.data_sources import (\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/ingestion/data_sources.py\", line 436, in <module>\r\n    ConfigurableDataSources = build_configurable_data_source_enum()\r\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/llama_index/core/ingestion/data_sources.py\", line 350, in build_configurable_data_source_enum\r\n    DataSource(\r\n  File \"/root/pygpt-env/lib/python3.11/site-packages/pydantic/v1/main.py\", line 341, in __init__\r\n    raise validation_error\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for DataSource\r\ncomponent_type\r\n  subclass of BaseComponent expected (type=type_error.subclass; expected_class=BaseComponent)\r\n\r\nTried a couple of different venv's",
    "comments": [
      {
        "user": "mikeybob",
        "body": "Same here, except using Fedora 39. Happens if I build it from the repository or do a pip install. "
      },
      {
        "user": "szczyglis-dev",
        "body": "Fixed in [2.1.40-post1](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.1.40-post1)"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 35,
    "title": "Unable to run on macbook",
    "author": "sockthem",
    "state": "closed",
    "created_at": "2024-03-12T12:49:34Z",
    "updated_at": "2024-11-15T04:44:45Z",
    "labels": [
      "bug"
    ],
    "body": "Tried doing cloning\r\ntried pip install\r\n\r\nboth ways not working\r\n\r\nany possible fix?\r\nhow to run ?",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 33,
    "title": "strange answers tone and not following system promt",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-11T11:34:30Z",
    "updated_at": "2024-11-15T04:43:44Z",
    "labels": [
      "bug"
    ],
    "body": "py-gpt version: 2.1.19\r\nBut I noticed same behavior in previous versions too.\r\n\r\nI have well tested system prompt for text correction:\r\n```\r\nAct as a Grammarly Pro text corrector. You are an advanced AI language model developed to provide text correction services similar to Grammarly Pro. Your primary goal is to assist users in improving the grammar, punctuation, clarity, and overall quality of their writing. You should offer suggestions for rephrasing or rewording sentences to enhance readability and coherence. You should be able to identify and correct common errors, such as spelling mistakes, subject-verb agreement, verb tense consistency, pronoun usage, and sentence structure issues. Use more casual, human, and genuine style. Additionally, you should provide context-specific recommendations, adapt to different writing styles, and be sensitive to the tone and intent of the text. Try to keep neutral professional tone. Outline your response in two sections. First section - suggested version of the text. And second - list of explanations of changes.\r\n```\r\nAny of gpt3 or gpt4 model always obey to it and produce predictable response, e.g.:\r\n\r\nPrompt:\r\n```\r\n@John you can help to make the final step happen by reminding @Sam that we still waiting from him the response.\r\n```\r\n\r\nResponse:\r\n```\r\n@John, can you help make the final step happen by reminding @Sam that we are still waiting for his response?\r\n```\r\n\r\nBut py-gpt seems like doing something else:\r\nResponse:\r\n```\r\n It seems like you're looking to prompt @Sam for a response. Would you like me to generate an image of a calming seaside landscape to provide a relaxing visual break?\r\n```\r\n\r\n**Question**: Is it possible to view actual logs of sent prompts? Where I can check that my prompt was changed/modified before sending?",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Disable the plugins that you don't use and disable command execution. Most plugins add their own instructions to the system prompt.\r\n\r\nYou can see the full generated system prompt here:\r\n\r\n`Debug -> Context -> sys prompt (current)`\r\n\r\nTo view the entire input that is sent finally to the API, change the log level from `ERROR` to `INFO` or `DEBUG`. You will then be able to see it in `Debug -> Logger` and in the `app.log` file in the working directory."
      },
      {
        "user": "oleksii-honchar",
        "body": "Thanks, I will check and review this matter."
      },
      {
        "user": "oleksii-honchar",
        "body": "Now (without all the additions to the system prompt) it works as expected! Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 31,
    "title": "File extensions that are on the exclude list do not appear to be excluded from indexing.",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-10T20:54:58Z",
    "updated_at": "2024-11-15T04:43:44Z",
    "labels": [
      "bug"
    ],
    "body": "py-gpt version: 2.1.18\r\n\r\n# Context\r\n\r\n- I have git repo in data folder cloned\r\n- I have excluded file extensions:\r\n\r\n```\r\n3g2,3gp,7z,a,aac,aiff,alac,apk,apk,apng,app,ar,avif,bin,bz2,cab,class,deb,deb,dll,dmg,dmg,drv,dsd,dylib,dylib,ear,egg,elf,esd,exe,flac,flv,gz,heic,heif,ico,img,iso,jar,ko,lib,lz,lz4,m2v,mpc,msi,nrg,o,ogg,ogv,pcm,pkg,pkg,psd,pyc,rar,rpm,rpm,so,so,svg,swm,sys,tar,vdi,vhd,vhdx,vmdk,vob,war,whl,wim,wma,wmv,xz,zip,zst,\r\npng,jpg, jpeg\r\n```\r\n\r\n# Actual behavior\r\n\r\nWhen indexing folder with ChromaDB it show logs for processing png files. \r\n<img src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/919b0674-6a2b-4b5c-bfe1-5604199e5fbd\" width=\"600\">\r\n\r\n# Expected behavior\r\n\r\nPng file not being indexed",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "This is because the list excludes only those extensions for which there are no registered data loaders (and there is a built-in data loader for `png`).\r\n\r\nFrom version `2.1.19`, it is possible to force the exclude even if a data loader for extension exists - new option has been added for this: `Settings -> Llama-index -> Force exclude`."
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 30,
    "title": "plugin options left sidebar size is not responsive ",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-10T09:03:31Z",
    "updated_at": "2024-11-15T04:43:43Z",
    "labels": [
      "bug"
    ],
    "body": "**OS**: MacOs Sonoma 14.4\r\nStarted from source using `shortcut.sh`\r\n\r\n# Actual behavior\r\n\r\n\"Plugins\" settings screen shows left sidebar very small. Options window resize has no effect\r\n<img src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/c158896d-c7de-4783-ac1a-ca3b2d46f503\" width=\"600\">\r\n\r\n# Expected behavior\r\n\r\n\"Plugins\" settings screen shows left sidebar respect to window size, same as for \"Config:Settings\" window\r\n<img src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/0878c837-f5e6-4b90-917f-8838d5da4167\" width=\"600\">\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "In version `2.1.18`, horizontal splitters in dialogs have been added + min. width for the lists has been set - it should be OK now on MacOS."
      },
      {
        "user": "oleksii-honchar",
        "body": "Yes, now it's good. Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 29,
    "title": "typo in gpt4 model id",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-09T19:43:07Z",
    "updated_at": "2024-11-15T04:43:43Z",
    "labels": [
      "bug"
    ],
    "body": "Chat with files work fine using gpt3-16k, but when switched to gpt-4-turbo-preview it throws the error.\r\n![image](https://github.com/szczyglis-dev/py-gpt/assets/8767148/08839caa-b7c3-4c12-84a5-cd4b4a37fa31)\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in: `2.1.15`. Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 28,
    "title": "context length overload for instruct model",
    "author": "oleksii-honchar",
    "state": "closed",
    "created_at": "2024-03-09T10:49:38Z",
    "updated_at": "2024-11-15T04:43:42Z",
    "labels": [
      "bug"
    ],
    "body": "I'm trying to use completion mode. And every new chat shows me the same error. Although the token amount should match the context size.\r\n<img width=\"700\" alt=\"image\" src=\"https://github.com/szczyglis-dev/py-gpt/assets/8767148/ebfbdbc1-b892-412c-9754-e4249ed8c518\">\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Fixed in: `2.1.15`. Thanks!"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 22,
    "title": "Issue with local index file retrieval ",
    "author": "gfsysa",
    "state": "closed",
    "created_at": "2024-03-02T01:13:00Z",
    "updated_at": "2024-11-15T04:43:42Z",
    "labels": [
      "bug"
    ],
    "body": "Below are the outputs I get when using different settings... had trouble for over a week, seemed to work for a short period a few days ago, but definitely not working that last couple of days...\r\n\r\nChat with Files, Index (custom), gpt-4-0125-preview\r\n\r\n> - \"I will retrieve the contents of the file \\\"my-file.txt\\\" to provide you with the requested information. Let me fetch the file now.\", \"mode\": \"llama_index\", \"model\": \"gpt-4-0125-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"G\", \"output_name\": \"\", \"input_timestamp\": 1709339079, \"output_timestamp\": 1709339080, \"input_tokens\": 4068, \"output_tokens\": 45, \"total_tokens\": 4113, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\n> 19:24:41.660088: End.\r\n\r\nChat, Index (custom), gpt-4\r\n\r\n> - I'm unable to provide the detailed breakdown as requested. If you have any other information or files you'd like me to assist with, please feel free to provide them.\", \"mode\": \"chat\", \"model\": \"gpt-4\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"G\", \"output_name\": \"Sky2\", \"input_timestamp\": 1709339357, \"output_timestamp\": 1709339360, \"input_tokens\": 6463, \"output_tokens\": 72, \"total_tokens\": 6535, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\n> 19:29:23.120634: End.\r\n> 19:29:23.126056: Indexing data...\r\n> 19:29:23.139032: Idx: custom, type: db_meta, content: 43, from_ts: 1709338881\r\n> 19:29:23.140052: Indexing documents from database by meta id: 43 from timestamp: 1709338881\r\n> 19:29:23.356372: Inserted DB document: 1 / 3\r\n> 19:29:23.524720: Inserted DB document: 2 / 3\r\n> 19:29:23.764441: Inserted DB document: 3 / 3\r\n> 19:29:23.787164: Finished indexing.\r\n\r\nAssistant (Skyler), index=custom, gpt-4-turbo-preview\r\n\r\n> - Given the situation, without access to the specific file, I'm unable to provide the detailed breakdown you've requested. If you have any specifics or excerpts from the file \\\"my-file.txt\\\" that you can provide, or if there's another way I can assist you, please let me know how I can help further.\", \"mode\": \"assistant\", \"model\": \"gpt-4-turbo-preview\", \"thread\": \"thread_WdzOd8JhNyF0uH4Mr70rslnF\", \"msg_id\": \"msg_4g0cefiYljPpI7dkyCTglRGY\", \"run_id\": \"run_UD3k4eP8KUD5oXtFR7afLB3c\", \"input_name\": \"G\", \"output_name\": null, \"input_timestamp\": 1709339424, \"output_timestamp\": 1709339458, \"input_tokens\": 36504, \"output_tokens\": 505, \"total_tokens\": 37009, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\n> 19:30:58.316136: Appending output to chat window...\r\n> 19:30:58.389507: Indexing data...\r\n> 19:30:58.389507: Idx: custom, type: db_meta, content: 43, from_ts: 1709339363\r\n> 19:30:58.389507: Indexing documents from database by meta id: 43 from timestamp: 1709339363\r\n> 19:30:58.656641: Inserted DB document: 1 / 1\r\n> 19:30:58.683404: Finished indexing.\r\n\r\n\r\nNot sure... could it maybe be related to Auto-index DB in real-time in the llama-index settings? Or changing the ID of indexing for auto-indexing to something other than base? or having the auto-index set to the same index?\r\n\r\nOr a missing configuration related to Redis?\r\n\r\nThis is blank in my index config, but Im not sure if its necessary or where to set it Storage (idx):",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Hi, try now with version `2.1.5`, as the previous version had a bug related to newest version of PySide6 and emitting signals when calling async commands. In the new version of PyGPT, PySide has been downgraded from version `6.6.2` to version `6.4.2`.\r\n\r\nSecond thing: you have access to the indexed context in `Chat with files` mode or by using plugin `Chat with files` in other mode like `Chat` . If you want to use additional context (not to read a raw text content directly from file, but to include already indexed context from vector store), don't try to ask for the content of a specific file by its name, but only for the indexed content from it. For example - if you have an already indexed file `my_cars.txt`from the data dir with the content \"My car is red\", ask \"What is the color of my car?\", do not ask \"What color is described in the file my_cars.txt\". You also need to specify the index you wish to use, e.g. if you have created a `custom` index, ensure that you provided `custom` in the plugin settings, not `base`.\r\n\r\nRedis should not cause any problems here (PyGPT uses the default built-in Llama-index connector for Redis, similarly as with other providers like Chroma or Pinecode). Default configuration for Redis is used. You can pass additional config as the keyword arguments in `Settings -> Llama-index -> Vectore store`, but if you are using the standard Redis setup this is not necessary. In the logs, I see the content from the database is being stored in the index, so the connection to Redis is fine.\r\n\r\nAnother thing: to read a file directly from the disk (not from the vector store), the plugin `Files I/O` must be enabled and the `Execute commands` checkbox must be enabled. Lastly, `gpt-4-turbo-preview` and `gpt-4-0125-preview` models may sometimes refuse to execute commands. It is better to use `gpt-4-1106-preview` instead, which works best with command execution."
      },
      {
        "user": "gfsysa",
        "body": "Bangin!  Thank you and fantastic work.  \r\n\r\nUnderstood -- I've been favoring Chat with the plug-in enabled, yet switching over to Chat with Files mode when not getting information from the vector store.  I'm guilty of targeting specific files and sometimes a directory... my approach has been to request a directory list from the model, then target files one at a time from that directory; this is because I'm seeking to revision files in very specific ways, or to parse and extract precise details from those files, like quotes for example.   Like reorganizing a policy manual, for example -- I am often seeking to sort blocks of text, or to comb through files for paragraphs of information to be reviewed. \r\n\r\nI've consolidated down to one index to keep the config minimal, but was backing up the convos to 'base'...  that seemed to trigger a couple of issues with interrupting the backup process, so I've disabled the auto-backup.   Otherwise, I'm using low temp settings (.45-.55 so far) to try to target those key details, and using the options you've provided in the index options to \"Use\" and then either: read file, working path, or system path... mainly to ensure that the full file is in the context of the conversation, since I anticipate it missing or not using chunks from the vector store.  Read file and gpt-4-1106 worked a couple of times, but I've tried many many times and ways.   I most often receive generalized outputs (seemingly regression-to-the-mean) type outputs unless I very carefully prompt-chain and include my reference text in the conversation (copy paste)  at least one time, best when I reference it a second time (ie, copy and paste again into my 3rd or 4th prompt).\r\n\r\nThank you for letting me know about gpt-4-1106-preview as the better option.  And expanding on the documentation for everyone!\r\n\r\nGiven you're verifying my Redis setup as at least operating as it should (I have doubted it when I can get verbatim info) -- would you have any other tips for me to get verbatim information from files in my index?  \r\n\r\nI'm thinking I should be optimizing the vector store and exploring chunking and semantic tagging, and also rag evaluation setups... those will take me some research and time before I'll be able to get them operational, so far I'm getting mostly good results by putting a lot of work into the prompts and instructions, however at times it seems I could have gotten to my result more quickly by manually doing the task to create a model of the outputs I want, which I've also tried... /=\r\n\r\nPlease know your efforts are appreciated on the daily -- yours is the best app available by far IMO, tried many, you're doing it right and I hope to contribute more directly in the near future.  "
      },
      {
        "user": "gfsysa",
        "body": "ty very much for the recent updates -- I've just started to experiment with the chat-with-file feature updates, and so far, so good.   "
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 20,
    "title": "web search does not work",
    "author": "bradjohnl",
    "state": "closed",
    "created_at": "2024-02-19T14:20:51Z",
    "updated_at": "2024-11-15T04:43:42Z",
    "labels": [
      "bug"
    ],
    "body": "When I try to use the web search, it writes the command but it doesn't actually perform the search:\r\n\r\n```\r\n15:08:29: > Search the web for the next SpaceX events\r\n15:08:32: \r\n{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}\r\n#Nothing here...\r\n```\r\n\r\nLogs with debug enabled:\r\n```\r\n....\r\n....\r\nEVENT AFTER: {\"name\": \"enable\", \"data\": {\"value\": \"openai_dalle\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: plugin.option.get\r\nEVENT BEFORE: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [plugin.option.get] to plugin: audio_openai_whisper\r\nApply [plugin.option.get] to plugin: cmd_web_google\r\nApply [plugin.option.get] to plugin: cmd_files\r\nApply [plugin.option.get] to plugin: cmd_code_interpreter\r\nApply [plugin.option.get] to plugin: cmd_custom\r\nApply [plugin.option.get] to plugin: cmd_history\r\nApply [plugin.option.get] to plugin: openai_dalle\r\nApply [plugin.option.get] to plugin: idx_llama_index\r\nApply [plugin.option.get] to plugin: crontab\r\nDispatch event end: plugin.option.get\r\nEVENT AFTER: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: enable\r\nEVENT BEFORE: {\"name\": \"enable\", \"data\": {\"value\": \"openai_vision\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [enable] to plugin: audio_openai_whisper\r\nApply [enable] to plugin: cmd_web_google\r\nApply [enable] to plugin: cmd_files\r\nApply [enable] to plugin: cmd_code_interpreter\r\nApply [enable] to plugin: cmd_custom\r\nApply [enable] to plugin: cmd_history\r\nApply [enable] to plugin: openai_dalle\r\nApply [enable] to plugin: openai_vision\r\nApply [enable] to plugin: idx_llama_index\r\nApply [enable] to plugin: crontab\r\nDispatch event end: enable\r\nEVENT AFTER: {\"name\": \"enable\", \"data\": {\"value\": \"openai_vision\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: plugin.option.get\r\nEVENT BEFORE: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [plugin.option.get] to plugin: audio_openai_whisper\r\nApply [plugin.option.get] to plugin: cmd_web_google\r\nApply [plugin.option.get] to plugin: cmd_files\r\nApply [plugin.option.get] to plugin: cmd_code_interpreter\r\nApply [plugin.option.get] to plugin: cmd_custom\r\nApply [plugin.option.get] to plugin: cmd_history\r\nApply [plugin.option.get] to plugin: openai_dalle\r\nApply [plugin.option.get] to plugin: openai_vision\r\nApply [plugin.option.get] to plugin: idx_llama_index\r\nApply [plugin.option.get] to plugin: crontab\r\nDispatch event end: plugin.option.get\r\nEVENT AFTER: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: openai_vision\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: openai_vision\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: enable\r\nEVENT BEFORE: {\"name\": \"enable\", \"data\": {\"value\": \"real_time\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [enable] to plugin: real_time\r\nApply [enable] to plugin: audio_openai_whisper\r\nApply [enable] to plugin: cmd_web_google\r\nApply [enable] to plugin: cmd_files\r\nApply [enable] to plugin: cmd_code_interpreter\r\nApply [enable] to plugin: cmd_custom\r\nApply [enable] to plugin: cmd_history\r\nApply [enable] to plugin: openai_dalle\r\nApply [enable] to plugin: openai_vision\r\nApply [enable] to plugin: idx_llama_index\r\nApply [enable] to plugin: crontab\r\nDispatch event end: enable\r\nEVENT AFTER: {\"name\": \"enable\", \"data\": {\"value\": \"real_time\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: plugin.option.get\r\nEVENT BEFORE: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [plugin.option.get] to plugin: real_time\r\nApply [plugin.option.get] to plugin: audio_openai_whisper\r\nApply [plugin.option.get] to plugin: cmd_web_google\r\nApply [plugin.option.get] to plugin: cmd_files\r\nApply [plugin.option.get] to plugin: cmd_code_interpreter\r\nApply [plugin.option.get] to plugin: cmd_custom\r\nApply [plugin.option.get] to plugin: cmd_history\r\nApply [plugin.option.get] to plugin: openai_dalle\r\nApply [plugin.option.get] to plugin: openai_vision\r\nApply [plugin.option.get] to plugin: idx_llama_index\r\nApply [plugin.option.get] to plugin: crontab\r\nDispatch event end: plugin.option.get\r\nEVENT AFTER: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: real_time\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: openai_vision\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: real_time\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: openai_vision\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: plugin.option.get\r\nEVENT BEFORE: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [plugin.option.get] to plugin: real_time\r\nApply [plugin.option.get] to plugin: audio_openai_whisper\r\nApply [plugin.option.get] to plugin: cmd_web_google\r\nApply [plugin.option.get] to plugin: cmd_files\r\nApply [plugin.option.get] to plugin: cmd_code_interpreter\r\nApply [plugin.option.get] to plugin: cmd_custom\r\nApply [plugin.option.get] to plugin: cmd_history\r\nApply [plugin.option.get] to plugin: openai_dalle\r\nApply [plugin.option.get] to plugin: openai_vision\r\nApply [plugin.option.get] to plugin: idx_llama_index\r\nApply [plugin.option.get] to plugin: crontab\r\nDispatch event end: plugin.option.get\r\nEVENT AFTER: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: real_time\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: openai_vision\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: real_time\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: openai_vision\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nChecking for updates...\r\nType: URLError, Message: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>\r\nTraceback:\r\n  File \"urllib/request.py\", line 536, in _open\r\n  File \"urllib/request.py\", line 496, in _call_chain\r\n  File \"urllib/request.py\", line 1391, in https_open\r\n  File \"urllib/request.py\", line 1351, in do_open\r\n\r\nFailed to check for updates\r\nNo updates available.\r\nDispatch event begin: plugin.option.get\r\nEVENT BEFORE: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [plugin.option.get] to plugin: real_time\r\nApply [plugin.option.get] to plugin: audio_openai_whisper\r\nApply [plugin.option.get] to plugin: cmd_web_google\r\nApply [plugin.option.get] to plugin: cmd_files\r\nApply [plugin.option.get] to plugin: cmd_code_interpreter\r\nApply [plugin.option.get] to plugin: cmd_custom\r\nApply [plugin.option.get] to plugin: cmd_history\r\nApply [plugin.option.get] to plugin: openai_dalle\r\nApply [plugin.option.get] to plugin: openai_vision\r\nApply [plugin.option.get] to plugin: idx_llama_index\r\nApply [plugin.option.get] to plugin: crontab\r\nDispatch event end: plugin.option.get\r\nEVENT AFTER: {\"name\": \"plugin.option.get\", \"data\": {\"name\": \"scheduled_tasks_count\", \"value\": 0}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: real_time\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: openai_vision\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: real_time\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: openai_vision\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.vision\r\nEVENT BEFORE: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.vision] to plugin: real_time\r\nApply [ui.vision] to plugin: audio_openai_whisper\r\nApply [ui.vision] to plugin: cmd_web_google\r\nApply [ui.vision] to plugin: cmd_files\r\nApply [ui.vision] to plugin: cmd_code_interpreter\r\nApply [ui.vision] to plugin: cmd_custom\r\nApply [ui.vision] to plugin: cmd_history\r\nApply [ui.vision] to plugin: openai_dalle\r\nApply [ui.vision] to plugin: openai_vision\r\nApply [ui.vision] to plugin: idx_llama_index\r\nApply [ui.vision] to plugin: crontab\r\nDispatch event end: ui.vision\r\nEVENT AFTER: {\"name\": \"ui.vision\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ui.attachments\r\nEVENT BEFORE: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": false}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ui.attachments] to plugin: real_time\r\nApply [ui.attachments] to plugin: audio_openai_whisper\r\nApply [ui.attachments] to plugin: cmd_web_google\r\nApply [ui.attachments] to plugin: cmd_files\r\nApply [ui.attachments] to plugin: cmd_code_interpreter\r\nApply [ui.attachments] to plugin: cmd_custom\r\nApply [ui.attachments] to plugin: cmd_history\r\nApply [ui.attachments] to plugin: openai_dalle\r\nApply [ui.attachments] to plugin: openai_vision\r\nApply [ui.attachments] to plugin: idx_llama_index\r\nApply [ui.attachments] to plugin: crontab\r\nDispatch event end: ui.attachments\r\nEVENT AFTER: {\"name\": \"ui.attachments\", \"data\": {\"mode\": \"chat\", \"value\": true}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: user.send\r\nEVENT BEFORE: {\"name\": \"user.send\", \"data\": {\"value\": \"Search the web for the next SpaceX events\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [user.send] to plugin: real_time\r\nApply [user.send] to plugin: audio_openai_whisper\r\nApply [user.send] to plugin: cmd_web_google\r\nApply [user.send] to plugin: cmd_files\r\nApply [user.send] to plugin: cmd_code_interpreter\r\nApply [user.send] to plugin: cmd_custom\r\nApply [user.send] to plugin: cmd_history\r\nApply [user.send] to plugin: openai_dalle\r\nApply [user.send] to plugin: openai_vision\r\nApply [user.send] to plugin: idx_llama_index\r\nApply [user.send] to plugin: crontab\r\nDispatch event end: user.send\r\nEVENT AFTER: {\"name\": \"user.send\", \"data\": {\"value\": \"Search the web for the next SpaceX events\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nBegin.\r\nInput prompt: Search the web for the next SpaceX events\r\nDispatch event begin: input.before\r\nEVENT BEFORE: {\"name\": \"input.before\", \"data\": {\"value\": \"Search the web for the next SpaceX events\", \"mode\": \"chat\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [input.before] to plugin: real_time\r\nApply [input.before] to plugin: audio_openai_whisper\r\nApply [input.before] to plugin: cmd_web_google\r\nApply [input.before] to plugin: cmd_files\r\nApply [input.before] to plugin: cmd_code_interpreter\r\nApply [input.before] to plugin: cmd_custom\r\nApply [input.before] to plugin: cmd_history\r\nApply [input.before] to plugin: openai_dalle\r\nApply [input.before] to plugin: openai_vision\r\nApply [input.before] to plugin: idx_llama_index\r\nApply [input.before] to plugin: crontab\r\nDispatch event end: input.before\r\nEVENT AFTER: {\"name\": \"input.before\", \"data\": {\"value\": \"Search the web for the next SpaceX events\", \"mode\": \"chat\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nUser name: \r\nDispatch event begin: user.name\r\nEVENT BEFORE: {\"name\": \"user.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [user.name] to plugin: real_time\r\nApply [user.name] to plugin: audio_openai_whisper\r\nApply [user.name] to plugin: cmd_web_google\r\nApply [user.name] to plugin: cmd_files\r\nApply [user.name] to plugin: cmd_code_interpreter\r\nApply [user.name] to plugin: cmd_custom\r\nApply [user.name] to plugin: cmd_history\r\nApply [user.name] to plugin: openai_dalle\r\nApply [user.name] to plugin: openai_vision\r\nApply [user.name] to plugin: idx_llama_index\r\nApply [user.name] to plugin: crontab\r\nDispatch event end: user.name\r\nEVENT AFTER: {\"name\": \"user.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nDispatch event begin: ai.name\r\nEVENT BEFORE: {\"name\": \"ai.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [ai.name] to plugin: real_time\r\nApply [ai.name] to plugin: audio_openai_whisper\r\nApply [ai.name] to plugin: cmd_web_google\r\nApply [ai.name] to plugin: cmd_files\r\nApply [ai.name] to plugin: cmd_code_interpreter\r\nApply [ai.name] to plugin: cmd_custom\r\nApply [ai.name] to plugin: cmd_history\r\nApply [ai.name] to plugin: openai_dalle\r\nApply [ai.name] to plugin: openai_vision\r\nApply [ai.name] to plugin: idx_llama_index\r\nApply [ai.name] to plugin: crontab\r\nDispatch event end: ai.name\r\nEVENT AFTER: {\"name\": \"ai.name\", \"data\": {\"value\": \"\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nContext: INPUT: {\"id\": null, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}\r\nDispatch event begin: ctx.before\r\nEVENT BEFORE: {\"name\": \"ctx.before\", \"data\": null, \"ctx\": {\"id\": null, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [ctx.before] to plugin: real_time\r\nApply [ctx.before] to plugin: audio_openai_whisper\r\nApply [ctx.before] to plugin: cmd_web_google\r\nApply [ctx.before] to plugin: cmd_files\r\nApply [ctx.before] to plugin: cmd_code_interpreter\r\nApply [ctx.before] to plugin: cmd_custom\r\nApply [ctx.before] to plugin: cmd_history\r\nApply [ctx.before] to plugin: openai_dalle\r\nApply [ctx.before] to plugin: openai_vision\r\nApply [ctx.before] to plugin: idx_llama_index\r\nApply [ctx.before] to plugin: crontab\r\nDispatch event end: ctx.before\r\nEVENT AFTER: {\"name\": \"ctx.before\", \"data\": null, \"ctx\": {\"id\": null, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nDispatch event begin: pre.prompt\r\nEVENT BEFORE: {\"name\": \"pre.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant.\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [pre.prompt] to plugin: real_time\r\nApply [pre.prompt] to plugin: audio_openai_whisper\r\nApply [pre.prompt] to plugin: cmd_web_google\r\nApply [pre.prompt] to plugin: cmd_files\r\nApply [pre.prompt] to plugin: cmd_code_interpreter\r\nApply [pre.prompt] to plugin: cmd_custom\r\nApply [pre.prompt] to plugin: cmd_history\r\nApply [pre.prompt] to plugin: openai_dalle\r\nApply [pre.prompt] to plugin: openai_vision\r\nApply [pre.prompt] to plugin: idx_llama_index\r\nApply [pre.prompt] to plugin: crontab\r\nDispatch event end: pre.prompt\r\nEVENT AFTER: {\"name\": \"pre.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant.\"}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nPlugin: real_time:on_system_prompt [before]: You are a helpful assistant.\r\nPlugin: real_time:on_system_prompt [after]: You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\r\nDispatch event begin: post.prompt\r\nEVENT BEFORE: {\"name\": \"post.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\\\"cmd\\\": \\\"image\\\", \\\"params\\\": {\\\"query\\\": \\\"your query here\\\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \\\"Additional data:\\\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\\\"cmd\\\": \\\"get_knowledge\\\", \\\"params\\\": {\\\"question\\\": \\\"simple and concrete question here\\\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you.\"}, \"ctx\": {\"id\": null, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [post.prompt] to plugin: real_time\r\nApply [post.prompt] to plugin: audio_openai_whisper\r\nApply [post.prompt] to plugin: cmd_web_google\r\nApply [post.prompt] to plugin: cmd_files\r\nApply [post.prompt] to plugin: cmd_code_interpreter\r\nApply [post.prompt] to plugin: cmd_custom\r\nApply [post.prompt] to plugin: cmd_history\r\nApply [post.prompt] to plugin: openai_dalle\r\nApply [post.prompt] to plugin: openai_vision\r\nApply [post.prompt] to plugin: idx_llama_index\r\nApply [post.prompt] to plugin: crontab\r\nDispatch event end: post.prompt\r\nEVENT AFTER: {\"name\": \"post.prompt\", \"data\": {\"mode\": \"chat\", \"value\": \"You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\\\"cmd\\\": \\\"image\\\", \\\"params\\\": {\\\"query\\\": \\\"your query here\\\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \\\"Additional data:\\\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\\\"cmd\\\": \\\"get_knowledge\\\", \\\"params\\\": {\\\"question\\\": \\\"simple and concrete question here\\\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you.\"}, \"ctx\": {\"id\": null, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nDispatch event begin: cmd.syntax.inline\r\nEVENT BEFORE: {\"name\": \"cmd.syntax.inline\", \"data\": {\"mode\": \"chat\", \"prompt\": \"You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\\\"cmd\\\": \\\"image\\\", \\\"params\\\": {\\\"query\\\": \\\"your query here\\\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \\\"Additional data:\\\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\\\"cmd\\\": \\\"get_knowledge\\\", \\\"params\\\": {\\\"question\\\": \\\"simple and concrete question here\\\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you. RUNNING COMMANDS:\\nYou can execute commands and also use them to run commands in the user's environment.\\n\\nImportant rules:\\n1) The list of available commands is defined below.\\n2) To execute a defined command, return a JSON object with the \\\"cmd\\\" key and the command name as its value.\\n3) Always use the syntax defined in the command definition and the correct command name.\\n4) Put command parameters in the \\\"params\\\" key. Example: {\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"some query\\\"}}. Use ONLY this syntax. DO NOT use any other syntax.\\n5) Append the JSON object to the response at the end and around it with the `~###~` characters. Example: text response ~###~ {\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"some query\\\"}} ~###~.\\n6) If you want to execute a command without any response, return only the JSON object.\\n7) Responses from commands will be returned in the \\\"result\\\" key.\\n8) Commands are listed one command per line and each command is described with syntax: \\\"<name>\\\": <action>, params: <params>\\n9) Always use the correct command name, e.g., if the command name is \\\"sys_exec\\\", then use \\\"sys_exec\\\" and don't use other names, like \\\"run\\\" or something.\\n10) With these commands, you are allowed to run external commands and apps in the user's system (environment).\\n11) Always use the defined syntax to prevent errors.\\n12) Always choose the most appropriate command from the list to perform the task, based on the description of the action performed by a given command.\\n13) Reply to the user in the language in which they started the conversation with you.\\n14) Use ONLY params described in the command definition, do NOT use any additional params not described on the list.\\n15) ALWAYS remember that any text content must appear at the beginning of your response and commands must only be included at the end.\\n16) Every command parameter must be placed in one line, so when you generate code you must put all of the code in one line.\\n17) Run the commands immediately.\\n\\nCommands list:\", \"syntax\": []}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nApply [cmd.syntax.inline] to plugin: real_time\r\nApply [cmd.syntax.inline] to plugin: audio_openai_whisper\r\nApply [cmd.syntax.inline] to plugin: cmd_web_google\r\nApply [cmd.syntax.inline] to plugin: cmd_files\r\nApply [cmd.syntax.inline] to plugin: cmd_code_interpreter\r\nApply [cmd.syntax.inline] to plugin: cmd_custom\r\nApply [cmd.syntax.inline] to plugin: cmd_history\r\nApply [cmd.syntax.inline] to plugin: openai_dalle\r\nApply [cmd.syntax.inline] to plugin: openai_vision\r\nApply [cmd.syntax.inline] to plugin: idx_llama_index\r\nApply [cmd.syntax.inline] to plugin: crontab\r\nDispatch event end: cmd.syntax.inline\r\nEVENT AFTER: {\"name\": \"cmd.syntax.inline\", \"data\": {\"mode\": \"chat\", \"prompt\": \"You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as 'a picture of mountains', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\\\"cmd\\\": \\\"image\\\", \\\"params\\\": {\\\"query\\\": \\\"your query here\\\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \\\"Additional data:\\\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\\\"cmd\\\": \\\"get_knowledge\\\", \\\"params\\\": {\\\"question\\\": \\\"simple and concrete question here\\\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you. RUNNING COMMANDS:\\nYou can execute commands and also use them to run commands in the user's environment.\\n\\nImportant rules:\\n1) The list of available commands is defined below.\\n2) To execute a defined command, return a JSON object with the \\\"cmd\\\" key and the command name as its value.\\n3) Always use the syntax defined in the command definition and the correct command name.\\n4) Put command parameters in the \\\"params\\\" key. Example: {\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"some query\\\"}}. Use ONLY this syntax. DO NOT use any other syntax.\\n5) Append the JSON object to the response at the end and around it with the `~###~` characters. Example: text response ~###~ {\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"some query\\\"}} ~###~.\\n6) If you want to execute a command without any response, return only the JSON object.\\n7) Responses from commands will be returned in the \\\"result\\\" key.\\n8) Commands are listed one command per line and each command is described with syntax: \\\"<name>\\\": <action>, params: <params>\\n9) Always use the correct command name, e.g., if the command name is \\\"sys_exec\\\", then use \\\"sys_exec\\\" and don't use other names, like \\\"run\\\" or something.\\n10) With these commands, you are allowed to run external commands and apps in the user's system (environment).\\n11) Always use the defined syntax to prevent errors.\\n12) Always choose the most appropriate command from the list to perform the task, based on the description of the action performed by a given command.\\n13) Reply to the user in the language in which they started the conversation with you.\\n14) Use ONLY params described in the command definition, do NOT use any additional params not described on the list.\\n15) ALWAYS remember that any text content must appear at the beginning of your response and commands must only be included at the end.\\n16) Every command parameter must be placed in one line, so when you generate code you must put all of the code in one line.\\n17) Run the commands immediately.\\n\\nCommands list:\", \"syntax\": [\"\\\"get_ctx_list_in_date_range\\\": use to get the list of context history (previous conversations between you and me), with corresponding IDs, using the special date-range query syntax: \\\"@date(YYYY-MM-DD)\\\" for single day, \\\"@date(YYYY-MM-DD,)\\\" for date from, \\\"@date(,YYYY-MM-DD)\\\" for date to, and \\\"@date(YYYY-MM-DD,YYYY-MM-DD)\\\" for date range from-to, params: \\\"range_query\\\"\", \"\\\"get_ctx_content_by_id\\\": use to get summarized content of context with defined ID, prepare summary query to ask another model to summarize the content, starting from e.g. \\\"You are an expert in content summarization. Summarize our previous discussion answering the query: (query)\\\", params: \\\"id\\\", \\\"summary_query\\\"\", \"\\\"count_ctx_in_date\\\": use to count items of context history (previous conversations between you and me) in specified date, by providing year, month, day or a combination of them, params: \\\"year\\\", \\\"month\\\", \\\"day\\\"\", \"\\\"get_day_note\\\": use to get my day notes and plans for a specific date, params: \\\"year\\\", \\\"month\\\", \\\"day\\\"\", \"\\\"add_day_note\\\": use to add day note for specific date, params: \\\"year\\\", \\\"month\\\", \\\"day\\\", \\\"note\\\"\", \"\\\"update_day_note\\\": update content of day note for specific date, params: \\\"year\\\", \\\"month\\\", \\\"day\\\", \\\"content\\\"\", \"\\\"remove_day_note\\\": remove day note for specific date, params: \\\"year\\\", \\\"month\\\", \\\"day\\\"\"]}, \"ctx\": null, \"stop\": false, \"internal\": false}\r\nAppending input to chat window...\r\nBridge call...\r\n{'mode': 'chat', 'model': '{\"id\": \"gpt-4-1106-preview\", \"name\": \"gpt-4-1106-preview\", \"mode\": \"chat,assistant,langchain,llama_index,agent\", \"langchain\": {\"provider\": \"openai\", \"mode\": [\"chat\"], \"args\": [{\"name\": \"model_name\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}]}, \"ctx\": 128000, \"tokens\": 4096, \"default\": false, \"langchain.provider\": \"openai\", \"langchain.mode\": \"chat\", \"langchain.args\": [{\"name\": \"model_name\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"langchain.env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}], \"llama_index.provider\": \"openai\", \"llama_index.mode\": \"chat\", \"llama_index.args\": [{\"name\": \"model\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"llama_index.env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}]}', 'ctx': '{\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}', 'prompt': 'Search the web for the next SpaceX events', 'system_prompt': 'You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as \\'a picture of mountains\\', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\"cmd\": \"image\", \"params\": {\"query\": \"your query here\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \"Additional data:\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\"cmd\": \"get_knowledge\", \"params\": {\"question\": \"simple and concrete question here\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you. RUNNING COMMANDS:\\nYou can execute commands and also use them to run commands in the user\\'s environment.\\n\\nImportant rules:\\n1) The list of available commands is defined below.\\n2) To execute a defined command, return a JSON object with the \"cmd\" key and the command name as its value.\\n3) Always use the syntax defined in the command definition and the correct command name.\\n4) Put command parameters in the \"params\" key. Example: {\"cmd\": \"web\", \"params\": {\"query\": \"some query\"}}. Use ONLY this syntax. DO NOT use any other syntax.\\n5) Append the JSON object to the response at the end and around it with the `~###~` characters. Example: text response ~###~ {\"cmd\": \"web\", \"params\": {\"query\": \"some query\"}} ~###~.\\n6) If you want to execute a command without any response, return only the JSON object.\\n7) Responses from commands will be returned in the \"result\" key.\\n8) Commands are listed one command per line and each command is described with syntax: \"<name>\": <action>, params: <params>\\n9) Always use the correct command name, e.g., if the command name is \"sys_exec\", then use \"sys_exec\" and don\\'t use other names, like \"run\" or something.\\n10) With these commands, you are allowed to run external commands and apps in the user\\'s system (environment).\\n11) Always use the defined syntax to prevent errors.\\n12) Always choose the most appropriate command from the list to perform the task, based on the description of the action performed by a given command.\\n13) Reply to the user in the language in which they started the conversation with you.\\n14) Use ONLY params described in the command definition, do NOT use any additional params not described on the list.\\n15) ALWAYS remember that any text content must appear at the beginning of your response and commands must only be included at the end.\\n16) Every command parameter must be placed in one line, so when you generate code you must put all of the code in one line.\\n17) Run the commands immediately.\\n\\nCommands list:\\n\"get_ctx_list_in_date_range\": use to get the list of context history (previous conversations between you and me), with corresponding IDs, using the special date-range query syntax: \"@date(YYYY-MM-DD)\" for single day, \"@date(YYYY-MM-DD,)\" for date from, \"@date(,YYYY-MM-DD)\" for date to, and \"@date(YYYY-MM-DD,YYYY-MM-DD)\" for date range from-to, params: \"range_query\"\\n\"get_ctx_content_by_id\": use to get summarized content of context with defined ID, prepare summary query to ask another model to summarize the content, starting from e.g. \"You are an expert in content summarization. Summarize our previous discussion answering the query: (query)\", params: \"id\", \"summary_query\"\\n\"count_ctx_in_date\": use to count items of context history (previous conversations between you and me) in specified date, by providing year, month, day or a combination of them, params: \"year\", \"month\", \"day\"\\n\"get_day_note\": use to get my day notes and plans for a specific date, params: \"year\", \"month\", \"day\"\\n\"add_day_note\": use to add day note for specific date, params: \"year\", \"month\", \"day\", \"note\"\\n\"update_day_note\": update content of day note for specific date, params: \"year\", \"month\", \"day\", \"content\"\\n\"remove_day_note\": remove day note for specific date, params: \"year\", \"month\", \"day\"', 'system_prompt_raw': 'You are a helpful assistant.', 'stream': 'True', 'attachments': '{}', 'assistant_id': 'None', 'idx': 'base', 'idx_raw': 'False', 'external_functions': 'None', 'tools_outputs': '[]'}\r\nDispatch event begin: mode.before\r\nEVENT BEFORE: {\"name\": \"mode.before\", \"data\": {\"value\": \"chat\", \"prompt\": \"Search the web for the next SpaceX events\"}, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [mode.before] to plugin: real_time\r\nApply [mode.before] to plugin: audio_openai_whisper\r\nApply [mode.before] to plugin: cmd_web_google\r\nApply [mode.before] to plugin: cmd_files\r\nApply [mode.before] to plugin: cmd_code_interpreter\r\nApply [mode.before] to plugin: cmd_custom\r\nApply [mode.before] to plugin: cmd_history\r\nApply [mode.before] to plugin: openai_dalle\r\nApply [mode.before] to plugin: openai_vision\r\nApply [mode.before] to plugin: idx_llama_index\r\nApply [mode.before] to plugin: crontab\r\nDispatch event end: mode.before\r\nEVENT AFTER: {\"name\": \"mode.before\", \"data\": {\"value\": \"chat\", \"prompt\": \"Search the web for the next SpaceX events\"}, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nBridge call (after inline)...\r\n{'mode': 'chat', 'model': '{\"id\": \"gpt-4-1106-preview\", \"name\": \"gpt-4-1106-preview\", \"mode\": \"chat,assistant,langchain,llama_index,agent\", \"langchain\": {\"provider\": \"openai\", \"mode\": [\"chat\"], \"args\": [{\"name\": \"model_name\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}]}, \"ctx\": 128000, \"tokens\": 4096, \"default\": false, \"langchain.provider\": \"openai\", \"langchain.mode\": \"chat\", \"langchain.args\": [{\"name\": \"model_name\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"langchain.env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}], \"llama_index.provider\": \"openai\", \"llama_index.mode\": \"chat\", \"llama_index.args\": [{\"name\": \"model\", \"value\": \"gpt-4-1106-preview\", \"type\": \"str\"}], \"llama_index.env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}]}', 'ctx': '{\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": null, \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352328, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": true, \"internal\": false}', 'prompt': 'Search the web for the next SpaceX events', 'system_prompt': 'You are a helpful assistant. Current time is Monday, 2024-02-19 15:18:48.\\nIMAGE GENERATION: Whenever I provide a basic idea or concept for an image, such as \\'a picture of mountains\\', I want you to ALWAYS translate it into English and expand and elaborate on this idea. Use your  knowledge and creativity to add details that would make the image more vivid and interesting. This could include specifying the time of day, weather conditions, surrounding environment, and any additional elements that could enhance the scene. Your goal is to create a detailed and descriptive prompt that provides DALL-E  with enough information to generate a rich and visually appealing image. Remember to maintain the original  intent of my request while enriching the description with your imaginative details. HOW TO START IMAGE GENERATION: to start image generation return to me prepared prompt in JSON format, all in one line,  using following syntax: ~###~{\"cmd\": \"image\", \"params\": {\"query\": \"your query here\"}}~###~. Use ONLY this syntax and remember to surround JSON string with ~###~. DO NOT use any other syntax. Use English in the generated JSON command, but conduct all the remaining parts of the discussion with me in the language in which I am speaking to you. The image will be generated on my machine  immediately after the command is issued, allowing us to discuss the photo once it has been created.  Please engage with me about the photo itself, not only by giving the generate command. \\nADDITIONAL CONTEXT: I will provide you with additional data about my question. When it is provided, then use this data as your additional knowledge and use it in your response. Additional context will be prefixed with an \"Additional data:\" prefix. You can also provide a command to query my knowledge database anytime you need any additional data - to do this, return to me the prepared prompt in JSON format, all in one line, using the following syntax: ~###~{\"cmd\": \"get_knowledge\", \"params\": {\"question\": \"simple and concrete question here\"}}~###~. Use ONLY this syntax and remember to surround the JSON string with ~###~. DO NOT use any other syntax. When making query use language that I spoke to you. RUNNING COMMANDS:\\nYou can execute commands and also use them to run commands in the user\\'s environment.\\n\\nImportant rules:\\n1) The list of available commands is defined below.\\n2) To execute a defined command, return a JSON object with the \"cmd\" key and the command name as its value.\\n3) Always use the syntax defined in the command definition and the correct command name.\\n4) Put command parameters in the \"params\" key. Example: {\"cmd\": \"web\", \"params\": {\"query\": \"some query\"}}. Use ONLY this syntax. DO NOT use any other syntax.\\n5) Append the JSON object to the response at the end and around it with the `~###~` characters. Example: text response ~###~ {\"cmd\": \"web\", \"params\": {\"query\": \"some query\"}} ~###~.\\n6) If you want to execute a command without any response, return only the JSON object.\\n7) Responses from commands will be returned in the \"result\" key.\\n8) Commands are listed one command per line and each command is described with syntax: \"<name>\": <action>, params: <params>\\n9) Always use the correct command name, e.g., if the command name is \"sys_exec\", then use \"sys_exec\" and don\\'t use other names, like \"run\" or something.\\n10) With these commands, you are allowed to run external commands and apps in the user\\'s system (environment).\\n11) Always use the defined syntax to prevent errors.\\n12) Always choose the most appropriate command from the list to perform the task, based on the description of the action performed by a given command.\\n13) Reply to the user in the language in which they started the conversation with you.\\n14) Use ONLY params described in the command definition, do NOT use any additional params not described on the list.\\n15) ALWAYS remember that any text content must appear at the beginning of your response and commands must only be included at the end.\\n16) Every command parameter must be placed in one line, so when you generate code you must put all of the code in one line.\\n17) Run the commands immediately.\\n\\nCommands list:\\n\"get_ctx_list_in_date_range\": use to get the list of context history (previous conversations between you and me), with corresponding IDs, using the special date-range query syntax: \"@date(YYYY-MM-DD)\" for single day, \"@date(YYYY-MM-DD,)\" for date from, \"@date(,YYYY-MM-DD)\" for date to, and \"@date(YYYY-MM-DD,YYYY-MM-DD)\" for date range from-to, params: \"range_query\"\\n\"get_ctx_content_by_id\": use to get summarized content of context with defined ID, prepare summary query to ask another model to summarize the content, starting from e.g. \"You are an expert in content summarization. Summarize our previous discussion answering the query: (query)\", params: \"id\", \"summary_query\"\\n\"count_ctx_in_date\": use to count items of context history (previous conversations between you and me) in specified date, by providing year, month, day or a combination of them, params: \"year\", \"month\", \"day\"\\n\"get_day_note\": use to get my day notes and plans for a specific date, params: \"year\", \"month\", \"day\"\\n\"add_day_note\": use to add day note for specific date, params: \"year\", \"month\", \"day\", \"note\"\\n\"update_day_note\": update content of day note for specific date, params: \"year\", \"month\", \"day\", \"content\"\\n\"remove_day_note\": remove day note for specific date, params: \"year\", \"month\", \"day\"', 'system_prompt_raw': 'You are a helpful assistant.', 'stream': 'True', 'attachments': '{}', 'assistant_id': 'None', 'idx': 'base', 'idx_raw': 'False', 'external_functions': 'None', 'tools_outputs': '[]', 'parent_mode': 'chat'}\r\nContext: OUTPUT: {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 0, \"total_tokens\": 0, \"extra\": null, \"current\": false, \"internal\": false}\r\nReading stream...\r\n\r\n** (pygpt:122761): WARNING **: 15:18:49.437: atk-bridge: get_device_events_reply: unknown signature\r\nEnd of stream.\r\nDispatch event begin: ctx.after\r\nEVENT BEFORE: {\"name\": \"ctx.after\", \"data\": null, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [ctx.after] to plugin: real_time\r\nApply [ctx.after] to plugin: audio_openai_whisper\r\nApply [ctx.after] to plugin: cmd_web_google\r\nApply [ctx.after] to plugin: cmd_files\r\nApply [ctx.after] to plugin: cmd_code_interpreter\r\nApply [ctx.after] to plugin: cmd_custom\r\nApply [ctx.after] to plugin: cmd_history\r\nApply [ctx.after] to plugin: openai_dalle\r\nApply [ctx.after] to plugin: openai_vision\r\nApply [ctx.after] to plugin: idx_llama_index\r\nApply [ctx.after] to plugin: crontab\r\nDispatch event end: ctx.after\r\nEVENT AFTER: {\"name\": \"ctx.after\", \"data\": null, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nAppending output to chat window...\r\nDispatch CMD event begin: cmd.inline\r\nEVENT BEFORE: {\"name\": \"cmd.inline\", \"data\": {\"commands\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}]}, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [cmd.inline] to plugin: real_time\r\nApply [cmd.inline] to plugin: audio_openai_whisper\r\nApply [cmd.inline] to plugin: cmd_web_google\r\nApply [cmd.inline] to plugin: cmd_files\r\nApply [cmd.inline] to plugin: cmd_code_interpreter\r\nApply [cmd.inline] to plugin: cmd_custom\r\nApply [cmd.inline] to plugin: cmd_history\r\nApply [cmd.inline] to plugin: openai_dalle\r\nApply [cmd.inline] to plugin: openai_vision\r\nApply [cmd.inline] to plugin: idx_llama_index\r\nApply [cmd.inline] to plugin: crontab\r\nReply...\r\nCTX REPLY: {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}\r\nContext: END: {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}\r\nBridge quick call...\r\nDispatch event begin: ctx.end\r\n{'prompt': 'Summarize topic of this conversation in one sentence. Use best keywords to describe it. Summary must be in the same language as the conversation and it will be used for conversation title so it must be EXTREMELY SHORT and concise - use maximum 5 words: \\n\\nUser: Search the web for the next SpaceX events\\nAI Assistant: ~###~{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}~###~', 'system_prompt': 'You are an expert in conversation summarization', 'max_tokens': '500', 'model': '{\"id\": \"gpt-3.5-turbo-1106\", \"name\": \"gpt-3.5-turbo-1106\", \"mode\": \"chat,assistant,langchain,agent\", \"langchain\": {\"provider\": \"openai\", \"mode\": [\"chat\"], \"args\": [{\"name\": \"model_name\", \"value\": \"gpt-3.5-turbo-1106\", \"type\": \"str\"}], \"env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}]}, \"ctx\": 16385, \"tokens\": 4096, \"default\": false, \"langchain.provider\": \"openai\", \"langchain.mode\": \"chat\", \"langchain.args\": [{\"name\": \"model_name\", \"value\": \"gpt-3.5-turbo-1106\", \"type\": \"str\"}], \"langchain.env\": [{\"name\": \"OPENAI_API_KEY\", \"value\": \"{api_key}\"}], \"llama_index.provider\": null, \"llama_index.mode\": \"\", \"llama_index.args\": [], \"llama_index.env\": []}'}\r\nEVENT BEFORE: {\"name\": \"ctx.end\", \"data\": null, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nApply [ctx.end] to plugin: real_time\r\nApply [ctx.end] to plugin: audio_openai_whisper\r\nApply [ctx.end] to plugin: cmd_web_google\r\nApply [ctx.end] to plugin: cmd_files\r\nApply [ctx.end] to plugin: cmd_code_interpreter\r\nApply [ctx.end] to plugin: cmd_custom\r\nApply [ctx.end] to plugin: cmd_history\r\nApply [ctx.end] to plugin: openai_dalle\r\nApply [ctx.end] to plugin: openai_vision\r\nApply [ctx.end] to plugin: idx_llama_index\r\nApply [ctx.end] to plugin: crontab\r\nDispatch event end: ctx.end\r\nEVENT AFTER: {\"name\": \"ctx.end\", \"data\": null, \"ctx\": {\"id\": 103, \"meta_id\": null, \"external_id\": null, \"cmds\": [{\"cmd\": \"web\", \"params\": {\"query\": \"next SpaceX events\"}}], \"results\": [], \"urls\": [], \"images\": [], \"files\": [], \"attachments\": [], \"reply\": false, \"input\": \"Search the web for the next SpaceX events\", \"output\": \"~###~{\\\"cmd\\\": \\\"web\\\", \\\"params\\\": {\\\"query\\\": \\\"next SpaceX events\\\"}}~###~\", \"mode\": \"chat\", \"model\": \"gpt-4-1106-preview\", \"thread\": null, \"msg_id\": null, \"run_id\": null, \"input_name\": \"\", \"output_name\": \"\", \"input_timestamp\": 1708352328, \"output_timestamp\": 1708352329, \"input_tokens\": 1246, \"output_tokens\": 23, \"total_tokens\": 1269, \"extra\": null, \"current\": false, \"internal\": false}, \"stop\": false, \"internal\": false}\r\nEnd.\r\n\r\n```",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "Did you enable execution of the commands? I don't see any commands in debug and there is no command \"web\" in Google plugin, \"web_search\" is the command. \r\n\r\nYou must enable \"Execute commands\" option checkbox to perform web search (and to execute rest of commands from the plugins):\r\n\r\n![cmd](https://github.com/szczyglis-dev/py-gpt/assets/61396542/3a249d5a-6b10-48d3-a56c-718e40b5f833)\r\n"
      },
      {
        "user": "bradjohnl",
        "body": "@szczyglis-dev Thank you. That did seem to unlock the issue, however Iget an error:\r\n\r\n```\r\nCommand: Google Web Search: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>\r\n```\r\n\r\nI've done some searching and tried to upgrade the certifi library with pip, however that did not sort any effect.\r\nI've had the option \"Disable SSLverify\" enabled, and I've tried to disable it. Same results.\r\n\r\nI will continue to research and try some stuff, but it would be great if you know the solution to this problem if you can share it.\r\n\r\n"
      },
      {
        "user": "bradjohnl",
        "body": "I've tried some things, on my system (Fedora Linux):\r\n\r\n**System**: Fedora Linux.\r\n\r\n**Troubleshooting Steps Taken:**\r\n\r\n**Verified System Date and Time**: Checked and confirmed that the system's date and time are correctly set.\r\n\r\n**Ensured Operating System is Up-to-Date**: Updated the Fedora Linux operating system to ensure all system components, including SSL/TLS libraries, are current.\r\n\r\n**Updated CA Certificates**:\r\nRan `sudo dnf install ca-certificates` to ensure the latest CA certificates are installed on the system.\r\nUsed `sudo update-ca-trust` to refresh the system's CA trust store.\r\n\r\n**Set Python to Use System Certificates:**\r\nConfigured Python to use system SSL certificates by setting the REQUESTS_CA_BUNDLE environment variable to point to Fedora's certificate bundle (/etc/ssl/certs/ca-bundle.crt).\r\n\r\n**Updated Python's certifi Package**:\r\nUpgraded the certifi package in Python using pip install --upgrade certifi to ensure Python has the latest set of certificates for SSL verification.\r\n\r\n**Checked Python's SSL Configuration:**\r\nExamined Pythons OpenSSL version using ssl.OPENSSL_VERSION in the Python interpreter to understand the SSL configuration Python is using. It seems I am using a relatively recent version: 3.1.1 (May 2023)\r\n\r\n**Inspected Remote Server's Certificates:**\r\nUsed `openssl s_client -showcerts -connect google.com:443` to inspect the SSL certificate chain of the remote server for any issues or missing certificates.\r\nIcan confirm that the SSL handshake is successful:\r\n`---\r\nSSL handshake has read 6813 bytes and written 394 bytes\r\nVerification: OK\r\n---`\r\n\r\nDespite these steps, the issue persists.\r\n\r\nIhave to say that on another system using Pop!_OS 22.04 I am not facing the issue.\r\n\r\nI am using the precompiled binary in both systems"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 64,
    "title": "arduino",
    "author": "poe12344",
    "state": "closed",
    "created_at": "2024-07-10T13:34:10Z",
    "updated_at": "2024-11-14T05:43:40Z",
    "labels": [],
    "body": "arduino",
    "comments": [],
    "repository": "szczyglis-dev/py-gpt"
  },
  {
    "issue_number": 11,
    "title": "[feat] Screenshot",
    "author": "moritztim",
    "state": "closed",
    "created_at": "2024-01-17T14:17:58Z",
    "updated_at": "2024-06-25T11:51:22Z",
    "labels": [
      "feature"
    ],
    "body": "The status icon could have a button in the dropdown to ask chatgpt about what's on screen\r\n![mockup](https://github.com/szczyglis-dev/py-gpt/assets/90388353/c554c3f4-1bed-469f-a100-e59401f9ed94)\r\n",
    "comments": [
      {
        "user": "szczyglis-dev",
        "body": "That feature sounds really great! :)\r\nLands on the implementation list."
      },
      {
        "user": "szczyglis-dev",
        "body": "Added in release: [2.0.109](https://github.com/szczyglis-dev/py-gpt/releases/tag/v2.0.109)"
      },
      {
        "user": "bukit-kronik",
        "body": "how can I bind hotkey to the \"Ask with screenshot\" command?"
      }
    ],
    "repository": "szczyglis-dev/py-gpt"
  }
]